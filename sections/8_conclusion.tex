\section{Conclusion}
\label{s_Conclusion}

Dynamic graphs and \glspl{tgnn} recently garnered attention. Despite the opaque nature of most of the models that are used on dynamic graphs, the explainability of these black-box models remains less explored. Specifically, counterfactual explanations have not been extensively investigated for such models until now. Counterfactual explanations seek to uncover the elements of the input that are necessary for the explained prediction. In comparison, the more common factual explanations seek to uncover the parts of the input that are sufficient for the explained prediction.

This thesis takes an event-based view of dynamic graphs. A dynamic graph is fully described by an ordered list of timestamped events that add, remove, or update nodes and edges in the dynamic graph.

Taking a counterfactual perspective into explanations for the predictions of black-box models on dynamic graphs, this thesis proposes \gls{greedycf} and \gls{cftgnn}, two novel explanation methods that provide counterfactual explanations. The explanation problem is framed as a search task where the search space consists of all possible combinations of past events. Removing any of these combinations from the original input may change the prediction. If the removal changes the classification of the prediction, it makes that perturbation a counterfactual example that is necessary to the explained prediction.

The search space is constrained in terms of its spatial and temporal extent, and it is structured into a search tree such that it aligns with the objectives of maximizing discoveries of counterfactual examples while minimizing the complexity of the explanation. \gls{greedycf} is proposed as a capable baseline approach for searching for counterfactual explanations in this setting. It leverages a greedy search approach to find counterfactual examples within the search space quickly. As a more sophisticated approach, \gls{cftgnn} is introduced. \gls{cftgnn} adapts a search algorithm based on the Monte Carlo tree search algorithm to efficiently explore different potentially counterfactual input perturbations. In the absence of sufficient information on the importance of past information to the explained prediction, both search approaches leverage heuristic selection strategies to guide the search.

An extensive evaluation shows that \gls{cftgnn} provides counterfactual examples more frequently and with lower complexity than \gls{greedycf} or other contemporary explanation approaches while keeping time complexity acceptable. The experiments also uncover that the heuristic selection strategy has a large effect on explanatory performance. The results show that selecting promising events to include in the input perturbation by considering spatio-temporal aspects and local gradients is preferable over random selection.

%To find such counterfactual explanations, the explanation problem is framed as a search task. In this framework, the search space is defined as the set of all possible combinations of past events. Each of these combinations represents a perturbation of the original input in which the included events are removed from the input. Changing the input in this way may change the prediction, making the perturbation a counterfactual example. Temporal and spatial constraints are imposed on the search space, and the search space is structured into a search tree such that it aligns with the objectives of maximizing discoveries of counterfactual examples while minimizing the complexity of the explanation. \gls{greedycf} is proposed as a capable baseline approach for searching for counterfactual explanations in this setting. It leverages a greedy search approach to find counterfactual examples within the search space quickly. As a more sophisticated approach, \gls{cftgnn} is introduced. \gls{cftgnn} adapts a search algorithm based on the Monte Carlo tree search algorithm to efficiently explore different potentially counterfactual perturbations. In the absence of sufficient information on the importance of past events to the explained prediction, both search approaches leverage heuristic selection strategies to guide the search. An extensive evaluation shows that \gls{cftgnn} can provide counterfactual examples more frequently and with lower complexity than \gls{greedycf} or other contemporary explanation approaches while keeping time complexity acceptable. It also uncovers that the heuristic selection strategy has a large effect on the explanatory performance. The results show that selecting events for the input pertubation by recency and ?? is preferable over random selection or selection by spatial distance.


\subsection{Limitations}
\label{s_Conclusion_Limitations}

Despite the contribution this work makes, certain conceptual and practical limitations warrant consideration.

Conceptually, the very definition of the explanation problem undertaken in Section \ref{s_ProblemFormulation} limits counterfactual examples to perturbations that remove a set of past events from the input. While this limitation is essential for establishing a clear framework for the search process, it also imposes restrictions. Counterfactual examples do not have to be limited to the omission of information but could also encompass adding events to the input, changing the features associated with the nodes and edges in past events, or changing the timing of events. However, incorporating these dimensions would inevitably result in a substantial expansion of the search space, necessitating the development of novel methods to effectively navigate and address these complex circumstances.

On a practical level, the applicability of \gls{cftgnn} faces two noteworthy constraints. Firstly, the relatively long explanation times and substantial resources required for explaining a single prediction confine the practical use of \gls{cftgnn} to cases where sufficient time is available. \gls{cftgnn} proves impractical for explaining large volumes of predictions within a reasonable timeframe. The main contributing factor to these temporal and resource requirements is the (in-)efficiency of the targeted model. Targeting better-optimized models would thus directly alleviate these concerns. Secondly, the fact that the proposed methods are not guaranteed to find a counterfactual example limits their usefulness. 

% Conceptual
% - Only deletion of past events
% - 

% Evaluation
% - Only one target model
% - Only similar graphs
% - 

% Practical
% - Explicit search approach has long inference times -> unpractical; much energy used
% - Not always an explanation -> Cannot explain every prediction
% - 


\subsection{Future Work}
\label{s_Conclusion_FutureWork}

Future work may address the limitations of this work. Further, it can explore avenues that build upon the presented findings and deepen the understanding of counterfactual explanations in the context of dynamic graphs. 

The evaluation could be expanded by other target models. While \gls{tgn} provides a framework that generalizes many approaches for \glspl{tgnn}, it would be interesting to see if the results gathered in this work generalize to other target models. Assessing the explainers on a more diverse array of datasets could further establish the robustness and applicability of the developed approaches.

Improvements in the performance of the proposed methods could be achieved through systematic hyperparameter tuning, employing techniques such as grid search to optimize the balance between exploration and exploitation in \gls{cftgnn}. 
Additionally, relaxing constraints on explanations, such as allowing the addition of events in perturbations instead of only removal, holds the potential for performance enhancement. However, this would come with the caveats discussed in Section \ref{s_Conclusion_Limitations}.

Additionally, future work could apply and investigate \gls{greedycf} and \gls{cftgnn} to explain other tasks than future link prediction. For example, the explanation methods could be employed to explain the task of node classification. The main adaptation necessary for this application would be to update the $\Delta$-function (see Equation \ref{e_delta_function}) to quantify how much the certainty for the original node classification is shifted by a given perturbation set.

%Lastly, an area that remains to be explored is integrating counterfactual explanation methods with factual ones into a hybrid approach in the dynamic graph context. In doing so, the aspects of necessity and sufficiency would be combined into a single framework.

Lastly, another avenue for future exploration involves integrating counterfactual explanation methods with factual ones in the dynamic graph context, blending aspects of necessity and sufficiency into a unified framework. Such a hybrid approach holds the potential for a more comprehensive understanding of the underlying graph dynamics.


% - Tuning Hyperparameter
% - Combine CF perspective with F perspective


\iffalse
% !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
% \subsection{CoDy for Generic Graph Tasks}
% Like SubgraphX: How to adapt CoDy to other tasks like classification.
% !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
This thesis presents \gls{cftgnn} to explain predictions in the future link prediction context. However, \gls{cftgnn} is easily generalizable to explain graph models applied to diverse tasks, including but not limited to node classification or graph classification.

In node classification, the explanation target is no longer an explained event but the classification $y_{i, t}$ of a node $n_i$ in graph $\mathcal{G}$ at time $t$. The main adaptation is replacing the link prediction function $f$ with a binary prediction function $c(\cdot)$ that provides a prediction of whether the node $n_i$ is of the same class $y_{i, t}$ as initially classified, given a perturbation of the past events. With this replacement \gls{cftgnn} can operate the same way as in the link prediction setting.

For graph classification, the link prediction function must also be replaced by a binary prediction function, which predicts whether the graph is classified into the same class as it was initially or not. Additionally, the spatial constraints on the search space introduced in Section \ref{s_Methodology_SearchSpace_Constraints} cannot be applied and are thus lifted so that the search space is only constrained in the temporal dimension.

\fi