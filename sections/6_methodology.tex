\section{Methodology}
\label{s_Methodology}

This chapter addresses the explanation problem defined in Section \ref{s_ProblemFormulation} using two explanation approaches. As the basis for these approaches, the task of explaining predictions of future link prediction models on \glspl{ctdg} is framed as a search task. Section \ref{s_Methodology_SearchSpace} defines the search space and explores the question of how to structure it in accordance with the objectives defined for explainers. Next, Section \ref{s_Methodology_SelectionStrategies} introduces so-called selection strategies, which provide a heuristic approach to guiding the explainers during the search. Following that, Section \ref{s_Methodology_GreedyCF} presents \gls{greedycf}, which is a low-complexity approach that uses a greedy heuristic for identifying counterfactual explanations. The subsequent section (Section \ref{s_Methodology_CoDy}) introduces \gls{cftgnn}, which is a sophisticated search approach that builds upon past findings in reinforcement learning and factual explanation methods.

%To solve the problem defined in Section \ref{s_ProblemFormulation}, this chapter introduces two novel search-based explanation approaches. First, 
%As there are not yet any explanation approaches for models on dynamic graphs, Section \ref{s_Methodology_GreedyBaseline} outlines a simple approach for finding counterfactual examples that serves as a capable baseline in this thesis and for future methods. The subsequent section introduces \acrfull{cftgnn}, which leverages counterfactual examples to provide intuitive and understandable explanations in the context of future link prediction on \glspl{ctdg}


%To solve the problem defined in Section \ref{s_ProblemFormulation}, this chapter introduces \acrfull{cftgnn}, a novel search-based explanation approach developed in this thesis. \gls{cftgnn} leverages counterfactual examples to provide intuitive and understandable explanations in the context of future link prediction on \glspl{ctdg}. This chapter presents the details of \gls{cftgnn}'s design, its components, the rationale behind its development, and how it addresses the previously set objectives.
%Section \ref{s_Methodology_Overview} provides an overview of the foundations of the explanation framework, exploring the search space for counterfactual examples and detailing how \gls{cftgnn} employs a search strategy to find such counterfactual examples. Subsequently, Section \ref{s_Methodology_Search} delves into the inner workings of \gls{cftgnn}, explaining the search algorithm in detail. The search algorithm is supplemented with a so-called selection strategy, which provides a heuristic approach for informing the exploration of the search tree (Section \ref{s_Methodology_Selection}). Finally, Section \ref{s_Methodology_GenericGraphTasks} covers how \gls{cftgnn} is generalized to explain other graph tasks.

\subsection{Search Space}
\label{s_Methodology_SearchSpace}


%\subsection{Overview}
%\label{s_Methodology_Overview}

As outlined in Section \ref{s_ProblemFormulation_Objectives}, a counterfactual example $\mathcal{X}_{\varepsilon_i}$ that explains the prediction $y_{\varepsilon_i}$ for the occurence of a potential future link $\varepsilon_i$ in the dynamic graph $\mathcal{G}$ could be any combination of past events $\mathcal{X}_{\varepsilon_i} \subseteq (\mathcal{G}(t_i) \setminus \varepsilon_i)$. Let $S_{\varepsilon_i}$ denote the set containing all possible combinations of past events\footnote{following the notation of \cite{stanley_enumerative_1986}}:

\begin{equation}
    S_{\varepsilon_i} = \bigcup_{k = 0}^{|(\mathcal{G}(t_i) \setminus \varepsilon_i)|} {(\mathcal{G}(t_i) \setminus \varepsilon_i) \choose k}
\end{equation}

Following the binomial theorem, for the $n = |(\mathcal{G}(t_i) \setminus \varepsilon_i)|$ past events, the complexity of enumerating over all combinations by brute force is $O(2^n)$, making a brute force approach highly computationally expensive, even at small $n$. Thus, the search space for possible counterfactual examples needs to be explored by more efficient means. As a first step towards making the search space more manageable, spatial and temporal constraints on the search space are introduced. 
%\gls{cftgnn} achieves this with two measures: Spatial and temporal constraints on the explored space and an efficient search strategy adapted from reinforcement learning.

\subsubsection{Constraints on the Search Space}
\label{s_Methodology_SearchSpace_Constraints}
A spatial and a temporal constraint are applied to limit the size of the search space. The spatial constraint restricts the past events considered in the search to those in a temporal $k$-hop-neighborhood $N_k(\varepsilon_i)$ of the explained event $\varepsilon_i$. If the link prediction function $f$ is a \gls{tgnn}, $k$ is set to the number of layers in the \gls{tgnn} since contemporary \glspl{tgnn} predominantly aggregate information from events that occurred within the temporal $k$-hop-neighborhood \cite{yuan_explainability_2021}. As a temporal constraint, only the $m_{max}$ most recent events that fulfill the spatial requirements are considered in the search. Formally, let $C(\mathcal{G}, \varepsilon_i, k, m_{max})$ be the set of past events considered for the search, for which the spatial and temporal constraints mentioned above hold, then the constrained search space $\hat{S}_{\varepsilon_i}$ is given by:

\begin{equation}
    \hat{S}_{\varepsilon_i} = \bigcup_{l = 0}^{|C(\mathcal{G}, \varepsilon_i, k, m_{max})|} {C(\mathcal{G}, \varepsilon_i, k, m_{max}) \choose l}
\end{equation}

While these constraints can reduce the search space substantially, the complexity remains exponential at $O(2^{m_{max}})$, but with a fixed upper bound in $m_{max}$. This means that even if only a moderate amount of $m_{max} = 32$ past events would be considered, more than four billion unique combinations of events remain. Thus, the search space is structured in a way that enables the discovery of counterfactual explanations in line with the objectives of the explainer (see Section \ref{s_ProblemFormulation_Objectives}).

%Thus, \gls{cftgnn} leverages a search strategy to maximize the potential of finding a counterfactual example, while partially exploring the search space.

\subsubsection{Structuring the Search Space}
\label{s_Methodology_SearchSpace_Structure}

%\subsubsection{Search Framework}
%\label{s_Methodology_Overview_Search}
%The search performed by \gls{cftgnn} successively builds a partial search tree $T$.
Since traversing the full search space is infeasible, search algorithms are employed to search for counterfactual examples by successively building a partial search tree $P$. The partial search tree builds upon a complete tree structure described as search tree $T$. The search tree $T$ and the partial search tree $P$ are described as a set of nodes. A search tree node is denoted as $n_i \in T$ or $n_i \in P$ to avoid confusion with the unrelated nodes $v_i \in V$ in the graph. The search tree structures the search space in a way that facilitates finding simple counterfactual examples close to the root node of the search tree. Each node in the search tree is associated with a so-called perturbation set consisting of one of the combination of past events from the search space $\hat{S}_{\varepsilon_i}$. Formally, the search tree $T$ describes a set of nodes, where each node $n_j \in T$ in this search tree is characterized by an associated perturbation set $s_j \in \hat{S}_{\varepsilon_i}$ from the search space. A node in the search tree represents the omission of the events in the perturbation $s_j$ from the set of past events $\mathcal{G}(t_i)$. For a concise representation of the search tree, each node $n_j$ is represented as a tuple of associated attributes:

%\begin{equation}
%    n_j = (s_j, prediction_j, parent_j, children_j, selections_j, score_j, selectable_j)
%\end{equation}

\begin{equation}
    \label{e_search_tree_simple}
    n_j = (s_j, prediction_j, parent_j, children_j)
\end{equation}

When a node is first initialized, some of these attributes may not yet have a value. To accommodate this, an absence of a value is denoted by the symbol $null$. The attributes denote different aspects of the node that are essential for the search:

%In this representation as a tuple, a node $n_j$ is associated with several attributes. The attributes denote different aspects of the node that are essential for the search:

\begin{itemize}
    \item \textbf{Perturbation set $s_j$}: $s_j \in \hat{S}_{\varepsilon_i}$ denotes the set of perturbations associated with node $n_j$. The set of perturbations consists of a set of past events that are removed from the original input for the prediction $prediction_j$ associated with node $n_j$.

    \item \textbf{Prediction result $prediction_j$}: The prediction result $prediction_j \in (\mathbb{R} \cup \{null\})$ represents the prediction value that results from applying the link prediction function $prediction_j = f((\mathcal{G}(t_i) \setminus s_j), \varepsilon_i)$ for the explained event $\varepsilon_i$ with the perturbed input $(\mathcal{G}(t_i) \setminus s_j)$.

    \item \textbf{Parent $parent_j$}: The parent attribute $parent_j \in (T \cup \{null\})$ establishes a connection between node $n_j$ and the node from which it is derived. If $n_j$ is the root node, the attribute is set to $null$.

    \item \textbf{Children $children_j$}: The set of child nodes $children_j \subset T$ contains all nodes directly connected to $n_j$ and positioned one level below in the search tree.

    %\item \textbf{Selections $selections_j$}: The number of times this particular node has been selected in the search is denoted by $selections_j \in \mathbb{N} \cup \{null\}$.

    %\item \textbf{Score $score_j$}: The attribute $score_j \in \mathbb{R} \cup \{null\}$ is used as a means to describe how promising node $n_j$ is to lead to a counterfactual example.

    %\item \textbf{Selectable $selectable_j$}: $selectable_j$ is a binary flag that determines whether node $n_j$ can be chosen for further exploration. It is a boolean value defined as $selectable_j \in \{0, 1\}$, where $1$ signifies that $n_j$ is selectable, and $0$ that it is not.
\end{itemize}

% $s_j \in \hat{S}_{\varepsilon_i}$ denotes the set of perturbations associated with node $n_j$. The prediction result $prediction_j \in \mathbb{R} \cup \{null\}$ represents the prediction value that results from applying the link prediction function $f(\mathcal{G}(t_i) \setminus s_j, \varepsilon_i) = prediction_j$ for the explained event $\varepsilon_i$ to the perturbed input $\mathcal{G}(t_i) \setminus s_j$. The tuple also encompasses the parent node $parent_j \in T$, as well as a set of child nodes $children_j \subset T$. Additionally, it contains attributes that are updated throughout the search. The number of times this particular node has been selected in the search is denoted by $selections_j \in \mathbb{N} \cup \{null\}$. The attribute $score_j \in \mathbb{R} \cup \{null\}$ is used as a means to describe how promising node $n_j$ is to lead to a counterfactual example. Finally, the $selectable_j$ attribute is a binary flag that determines whether node $n_j$ can be chosen for further exploration. It is a boolean value defined as $selectable_j \in \{0, 1\}$, where $1$ signifies that $n_j$ is selectable, and $0$ that it is not.

As a starting point for the search, the root node $n_{root}$ is initialized with the identity perturbation $s_{root} = \varnothing$. Since no perturbations are applied to the input at this stage, the root node is linked to the original prediction for the occurrence of the future link $\varepsilon_i$.
%This root node is linked to the original prediction for the occurrence of the future link $\varepsilon_i$, as no perturbations are applied to the input at this stage. 
%During the search, the partial search tree $P$ is iteratively expanded, starting from the root node. Expansion refers to the addition of a new node to the partial search tree.
The root node has a set of children, which themselves have their own children. The perturbation set associated with children nodes expands the perturbation set associated with their parent. Formally, for a for a parent node $n_{parent} \in T$ in the search tree, each child node $n_{child} \in children_{parent}$ is associated with a perturbation $s_{child} \in \hat{S}_{\varepsilon_i}$ that satisfies the following conditions:

\begin{equation}
    \label{e_child_1}
    s_{child} \in \hat{S}_{\varepsilon_i}
\end{equation}

\begin{equation}
    \label{e_child_2}
    s_{parent} \subset s_{child}
\end{equation}

\begin{equation}
    \label{e_child_3}
    |s_{child}| = |s_{parent}| + 1
\end{equation}

This means that the perturbation set $s_{child}$ associated with the child node $n_{child}$ has to be part of the search space (Equation \ref{e_child_1}). Additionally, the perturbation set $s_{child}$ has to contain all the events that are part of the perturbation set of the parent node $s_{parent}$ (Equation \ref{e_child_2}) and contain exactly one more event than $s_{parent}$ (Equation \ref{e_child_3}).

%Formally, for a parent node $n_{parent} \in T$ in the search tree, each child node $n_{child} \in children_{parent}$ is associated with a perturbation $s_{child} \in \hat{S}_{\varepsilon_i}$ that contains all the perturbations of their parent $s_{parent} \subset s_{child}$ and one additional event so that $|s_{child}| = |s_{parent}| + 1$. 

This definition implies that the perturbations of the children represent an extension of their parent's perturbation set by one more event. Following a direct path from the root node to any node in the search tree can be interpreted as consecutively pruning one more event from the original input at each node along this path through the search tree. The depth of a node in the search tree, i.e., the length of the unique path from the root node to that node, corresponds to the number of events included in its associated perturbation.

\vspace{0.5cm}

Figure \ref{f_SearchTree_Example} illustrates a search tree. Following the leftmost path in the tree can be interpreted as initially removing event $\varepsilon_1$ from the past events and subsequently removing event $\varepsilon_2$. The figure visually represents the increasing size of perturbation sets associated with nodes at greater depths in the tree. Furthermore, it demonstrates how excluding the events in the perturbation sets from the input graph influences the prediction score. Generally, the set of all nodes in the search tree at depth $k$ encompasses nodes linked to all possible candidate perturbations in the search space of size $k$.
%It also shows how omitting the events in the perturbations from the past events affects the prediction score. In general, the fully expanded search tree at depth $k$ contains nodes associated with all candidate perturbations in the search space of size $k$.


%This means the node represents what happens to the model prediction when the events in the perturbation are omitted from the set of past events. A node in the search tree $n_j$ is thus characterized as a pair:


\begin{figure} [ht]
    \centering
    \include{figures/search_tree_example}
    \caption{Example of a partial search tree for the explained event $\varepsilon_i$. Without loss of generality, it is assumed that the candidate events $C(\mathcal{G}, \varepsilon_i, k, m_{max})$ are denominated by $\varepsilon_1, \varepsilon_2, ..., \varepsilon_{l - 1}, \varepsilon_{l}$.}
    \label{f_SearchTree_Example}
\end{figure}

Organizing the search tree in this manner reflects the objectives of the explainer (Section \ref{s_ProblemFormulation_Objectives}). The increasing size of the associated candidate perturbations with increasing depth is tethered to minimizing the complexity of the encountered counterfactual examples. It allows the exploration of low-complexity explanation candidates without expanding and traversing the partial search tree to large depths. The complexity of potential counterfactual explanations increases with the distance to the root node. The goal of maximizing discoveries is pursued in the consecutive pruning approach. This allows a search algorithm to follow paths on the search tree that are promising for leading to a counterfactual example.

\gls{greedycf} and \gls{cftgnn} build upon this search tree. Like the search space, the complete search tree $T$ is too large to construct fully. Thus, the search approaches only construct a partial search tree $P$. During the search, the partial search tree $P$ is iteratively expanded, starting from the root node. Expansion refers to the addition of a new node to the partial search tree. While both explainers share this framework for structuring the search space, the search strategies they employ vary significantly.

%\gls{cftgnn} builds upon this search tree. It combines two main components: A search algorithm that balances exploration, venturing into unexplored areas of the search space \cite{browne_survey_2012}, with exploitation, looking into promising areas of the search space \cite{browne_survey_2012}. The search algorithm is tasked with selecting a node to expand in each iteration of the search and a selection strategy that guides the search algorithms on selecting yet unexplored nodes.

\FloatBarrier
\subsection{Selection Strategies}
\label{s_Methodology_SelectionStrategies}
% Detail the different selection strategies, how they work and what the reasoning behind them is

When a search algorithm traverses the partial search tree $P$, it may have to select between several previously unexplored child nodes as direction for growing the partial search tree. In this case, a so-called selection strategy is employed to guide the selection of the unexplored nodes. 
%In addition to the structured search space, the proposed explanation methods share a mechanism used to inform the selection of events for the explanation. This mechanism is referred to as the selection strategy, and it is used when a selection has to be made between previously unexplored paths in the partial search tree. For example, when a node is expanded by a new child node. 
The selection strategies aim to improve the search performance by exploring promising alternatives first. Since there have not been any prior works on this, four different selection strategies are proposed and compared. Let $A = {n_1,...,n_k}$ be the set of alternative nodes in the search tree that could be selected and that have not yet been associated with a prediction score, meaning they are unexplored. The sets of perturbations associated with each of these nodes differ by exactly one event. Let $\varepsilon_1, ..., \varepsilon_k$ be the single events that differ between the respective nodes. The selection strategies provide a ranking of the alternative nodes $A$ based on these differing events. The higher a node is ranked, the more it is prioritized in the selection process.

\begin{itemize}
    \item \textbf{Random}: The \textit{random} selection strategy serves as the baseline strategy. It selects a node $n_j \in A$ at random.
    %\item \textbf{Closest}: The closest selection strategy bases its selection on the differing events. It ranks the events based on their spatial distance to the explained event $\varepsilon_i$. Lower distances are rated higher than larger distances. It ranks each event $\varepsilon_j$ by the length of the shortest walk between any of the nodes in $\varepsilon_j$ and any of those in $\varepsilon_i$. If there is more than one event with the same spatial distance, these events are ranked by their timestamp in decreasing order.
    %\item \textbf{Recent}: The recent selection strategy also bases its selection on the differing events. It ranks the events by their recency. The most recent event is rated the highest, and the oldest event is rated the lowest.
    \item \textbf{Temporal}: The \textit{temporal} selection strategy ranks the events by their recency. The most recent event is rated the highest, and the oldest event is rated the lowest.
    \item \textbf{Spatio-Temporal}: The \textit{spatio-temporal} selection strategy ranks the events based on their spatial distance to the explained event $\varepsilon_i$. Lower distances are rated higher than larger distances. It ranks each event $\varepsilon_j$ by the length of the shortest walk between any of the nodes involved in $\varepsilon_j$ and any of those involved in $\varepsilon_i$. Events with the same spatial distance are ranked by their recency, just like in the \textit{temporal} strategy. The \textit{spatio-temporal} selection strategy thus represents an extension of the \textit{temporal} selection strategy.
    \item \textbf{local-gradient}: The \textit{local-gradient} selection strategy also operates on the events that differ between the perturbation sets. However, it does not use the spatio-temporal structure of the graph as basis for the ranking. Instead, it compiles a ranking of all alternative events $A$, based on the local gradient of the differing events. The local gradient of an event refers to the change in prediction that is achieved when omitting that single event from the original input graph. To get a ranking, the local gradient is calculated once for all candidate events  $C(\mathcal{G}, \varepsilon_i, k, m_{max})$ before the first search iteration. To get the local gradient for the ranking, the link prediction function $f$ is used to calculate a separate prediction $pred_j$ for each of the candidate events $\varepsilon_j \in C(\mathcal{G}, \varepsilon_i, k, m_{max})$ as:
    \begin{equation}
        pred_j = f((\mathcal{G}(t_i) \setminus \{\varepsilon_j\}), \varepsilon_i)
    \end{equation}
    The prediction $pred_j$ is the prediction for the explained instance when event $\varepsilon_j$ is omitted from the input. These predictions are then fed into the so-called $\Delta$-function (see Equation \ref{e_delta_function}), ranking the candidate events in decreasing order by how much the prediction is shifted.
    
    %in the search $C(\mathcal{G}, \varepsilon_i, k, m_{max})$ before the first search iteration. For this ranking, it uses the link prediction function to calculate a separate prediction $pred_j$ for each of the candidate events $\varepsilon_j \in C(\mathcal{G}, \varepsilon_i, k, m_{max})$ as:
    %\begin{equation}
    %    pred_j = f(\mathcal{G} \setminus \{\varepsilon_j\}, \varepsilon_i)
    %\end{equation}
    %The prediction $pred_j$ is the prediction for the explained instance when event $\varepsilon_j$ is omitted from the input. These predictions are then fed into the $\Delta$-function, ranking the candidate events in decreasing order by how much the prediction is shifted.
\end{itemize}

The different selection strategies represent separate heuristic perspectives on the task of ranking alternative directions in the search tree. The \textit{temporal} and \textit{spatio-temporal} selection strategies leverage structural information. They are based on the intuition that events that are spatially and temporally close to the explained event are more important to the original prediction and, thus, more likely to be part of a counterfactual explanation. In comparison, the \textit{local-gradient} strategy leverages the isolated impact of removing events separately for the ranking.

The $\Delta$-function $\Delta(prediction_{orig}, prediction_j)$ that is used in the \textit{local-gradient} selection strategy determines how much a prediction $prediction_j$ is shifted towards being classified differently from the original prediction $prediction_{orig}$. Recalling the definition of the classification of a prediction from Section \ref{s_ProblemFormulation_Task}, predictions that are classified differently from another have opposing signs, i.e., a positive and a negative prediction are classified differently. The higher the result of the $\Delta$-function, the more the prediction $prediction_j$ suggests a different outcome in the link prediction task.

\begin{equation}
\label{e_delta_function}
    \Delta(prediction_{orig}, prediction_j) = 
    \begin{cases}
        prediction_{orig} - prediction_j,  &\text{if } prediction_{orig} \geq 0 \\
        prediction_j - prediction_{orig},  &\text{else}
    \end{cases}
\end{equation}


\subsection{Greedy Counterfactual Explainer for Models on Dynamic Graphs}
\label{s_Methodology_GreedyCF}

\acrfull{greedycf} provides an uncomplicated approach for searching for counterfactual examples in the search space. It aims to keep computations to a minimum in order to quickly conclude. The search approach revolves around a greedy strategy for traversing the search space.

The algorithm greedily follows the most promising path through the search tree, starting with the root node $n_{root}$. It iteratively expands the search tree along the nodes in the search tree, associated with the largest shift in predictions toward changing signs. This is in line with the iterative pruning logic underlying the structure of the search tree. The algorithm for \gls{greedycf} is depicted in Algorithm \ref{a_GreedyCF}. It takes the link prediction function $f$, the input graph $\mathcal{G}$, the explained event $\varepsilon_i$, a selection strategy $\delta$, and an adjustable sampling parameter $l \in \mathbb{N}$ as inputs. The sampling parameter $l$ determines how many nodes of the search tree \gls{greedycf} samples in each iteration. Before the first iteration, the original prediction is determined (line \ref{a_GreedyCF_pred_orig}), the root node is initialized with the prediction attribute $prediction_{root}$ set to the original prediction $prediction_{orig}$ and without children (line \ref{a_GreedyCF_root_init}), and the best node yet encountered $n_{best}$ is set to the root node (line \ref{a_GreedyCF_set_root_best}). Each iteration has three main steps: Sampling multiple child nodes (line \ref{a_GreedyCF_sample_children}), selecting the best child node from the sample (line \ref{a_GreedyCF_select_best_child}), and checking how the selection affects the prediction (lines \ref{a_GreedyCF_check_pred_start}-\ref{a_GreedyCF_check_pred_end}). 


{
\setlength{\algomargin}{1.25em}
\small
\begin{algorithm}[ht]
\caption{\gls{greedycf} search algorithm for counterfactual examples.}
\label{a_GreedyCF}
    \KwIn{Link prediction function $f$, input graph $\mathcal{G}$, explained event $\varepsilon_i$, selection strategy $\delta$, number of nodes to sample in each iteration $l$}
    \KwOut{best explanation found $\mathcal{X}$}
    $prediction_{orig} \gets f(\mathcal{G}(t_i), \varepsilon_i)$\; \label{a_GreedyCF_pred_orig}
    $n_{root} \gets (\varnothing, prediction_{orig}, null, \varnothing)$\; \label{a_GreedyCF_root_init}

    $n_{best} \gets n_{root}$; \label{a_GreedyCF_set_root_best}

    \While{$s_{best}$ $\mathrm{does\ not\ include\ all\ candidate\ events}$
    $C(\mathcal{G}, \varepsilon_i, k, m_{max})$}{
        $children_{best} \gets$ set of $l$ child node with highest rank according to $\delta$, each child $n_{child}$ initialized with prediction $prediction_{child} = f((\mathcal{G}(t_i) \setminus s_{child}), \varepsilon_i)$\; \label{a_GreedyCF_sample_children}
        $n_{best\_child} \gets \argmax_{n_j \in children_{best}} \Delta(prediction_{orig}, prediction_j)$\; \label{a_GreedyCF_select_best_child}
        \uIf{$\Delta(prediction_{best}, prediction_{best\_child}) > 0$ \label{a_GreedyCF_check_pred_start}}{
            \tcc{$n_{best\_child}$ shifts the prediction further towards the opposite sign of the original prediction}
            $n_{best} \gets n_{best\_child}$\;
            \If{$\Delta(prediction_{orig}, prediction_{best}) > |prediction_{orig}|$}{
                \tcc{$s_{best}$ is a counterfactual example}
                \Break\;
            }
        }\Else{
            \Break\;
        } \label{a_GreedyCF_check_pred_end}
    }
    \KwRet{$s_{best}$}
\end{algorithm}
}


A total of $l$ child nodes are sampled in each iteration. The sampling process is guided by the selection strategy $\delta$. From all possible child nodes, only the $l$ that rank the highest according to $\delta$ are sampled. When sampling the child nodes, they are directly associated with their corresponding prediction attribute. 

Next, out of the sampled children $children_{best}$, the child that shifts the prediction most towards changing signs is selected and assigned as best child node $n_{best\_child}$. To infer how much each of the children shifts the prediction, the $\Delta$-function that has been introduced in Section \ref{s_Methodology_SelectionStrategies} is used. Formally, the best child node is determined as:

\begin{equation}
    n_{best\_child} \gets \argmax_{n_j \in children_{best}} \Delta(prediction_{orig}, prediction_j)
\end{equation}

To check how the selection affects the prediction, it is first checked whether the selected child node $n_{best\_child}$ shifts the prediction further than the best node found before $n_{best}$ (Algorithm \ref{a_GreedyCF} line $7$). If it does not, the search concludes because no direct improvement is possible. If it does shift the prediction further, then $n_{best\_child}$ becomes the new best node $n_{best}$. If the best child node constitutes a counterfactual example (Algorithm \ref{a_GreedyCF} line $9$), the search concludes since it found a necessary counterfactual explanation.

In the end, the algorithm returns the perturbation set associated with the best node in the search tree $n_{best}$ that has been encountered. This is either a counterfactual example or the perturbation set that results in the greatest non-counterfactual shift out of all perturbation sets that are associated with a node in the partial search tree.

\FloatBarrier
\begin{figure}[ht]
    \centering
    \include{figures/methodology/greedy_baseline_example}
    \caption{Example for the operation of the \gls{greedycf} approach.}
    \label{f_GreedyBaseline}
\end{figure}


Figure \ref{f_GreedyBaseline} shows a simplified schema for how \gls{greedycf} operates. In the figure, each iteration consists of sampling $l = 3$ past events using some selection strategy $\delta$. After initializing the root node and the original prediction, node $n_2$ is selected in the first iteration as the new best node $n_{best}$ from the sample. It is associated with the perturbation set $s_2 = \{\varepsilon_2\}$, resulting in a prediction of $prediction_2 = 1.996$. Throughout the search procedure, the prediction associated with the best node gets lower with each iteration until it reaches a negative value in the third iteration. When this negative prediction is reached, the search concludes, returning the counterfactual example $\mathcal{X} = s_9 = \{\varepsilon_2, \varepsilon_1, \varepsilon_5\}$.


\FloatBarrier
\subsection{Counterfactual Explanations for Deep Graph Models on Dynamic Graphs}
\label{s_Methodology_CoDy}
% Add discussion of the complexity to follow up on the previous sections
\acrfull{cftgnn} used a search algorithm that is mainly adapted from \gls{mcts} \cite{kocsis_bandit_2006, silver_mastering_2017}. The \gls{mcts} algorithm has been successfully applied to playing games \cite{silver_mastering_2017} and planning problems \cite{browne_survey_2012}. Recently, it has also been used for factual explanations on static \glspl{gnn} \cite{yuan_explainability_2021, zhang_gstarx_2022} and \glspl{tgnn} \cite{xia_explaining_2023}. 

To accommodate the requirements of \gls{cftgnn}, the definition of the nodes in the search tree is extended by further attributes. Definition \ref{e_search_tree_cody} replaces the initial Definition \ref{e_search_tree_simple} of the tuple-representation for nodes in the search tree.

\begin{equation}
    \label{e_search_tree_cody}
    n_j = (s_j, prediction_j, parent_j, children_j, selections_j, score_j, selectable_j)
\end{equation}

This extension adds the attributes $selections_j$, $score_j$, and $selectable_j$. The meaning of these attributes is as follows:

\begin{itemize}
    \item \textbf{Selections $selections_j$}: The number of times this particular node has been selected in the search is denoted by $selections_j \in (\mathbb{N} \cup \{null\})$.

    \item \textbf{Score $score_j$}: The attribute $score_j \in (\mathbb{R} \cup \{null\})$ is used as a means to describe how promising node $n_j$ is to lead to a counterfactual example.

    \item \textbf{Selectable $selectable_j$}: $selectable_j$ is a binary flag that determines whether node $n_j$ can be chosen for further exploration. It is a boolean value defined as $selectable_j \in \{0, 1\}$, where $1$ signifies that $n_j$ is selectable, and $0$ that it is not.
\end{itemize}


Analogously to \gls{mcts}, the search algorithm of \gls{cftgnn} iteratively explores and expands the search tree using the results of past explorations and expansions as a guide on what to explore next \cite{browne_survey_2012}. The search operates in iterations, each iteration growing the search tree by one more node. It concludes after a predefined number of maximum iterations $it_{max}$ or when the entire search tree has been explored. At the end of the search, the algorithm selects the node associated with the minimal counterfactual example or a fallback option if no counterfactual example has been found. This fallback is introduced in Section \ref{s_Methodology_CoDy_Fallback}. One search iteration consists of the same steps as the search iterations in \gls{mcts} \cite{browne_survey_2012}: Selection, Simulation, Expansion, and Backpropagation. However, the exact implementation of these steps differs from their \gls{mcts} counterparts.

{
\setlength{\algomargin}{1.25em}
\small
\begin{algorithm}[ht]
\caption{Search algorithm used by \gls{cftgnn}.}
\label{a_CoDy}
    \KwIn{Link prediction function $f$, input graph $\mathcal{G}$, explained event $\varepsilon_i$, selection strategy $\delta$, maximum number of iterations $it_{max}$}
    %\KwIn{$f, \hspace{1.5mm} \mathcal{G}, \hspace{1.5mm} \varepsilon_i, \hspace{1.5mm} it_{max}, \hspace{1.5mm} \delta$}
    \KwOut{best explanation found}
    $prediction_{orig} \gets f(\mathcal{G}(t_i), \varepsilon_i)$\;
    $n_{root} \gets (\varnothing, null, null, \varnothing, 0, null, 1)$\;
    $it \gets 0$\;
    \While{$it < it_{max}$ and $n_{root}$ is selectable \label{a_CoDy_l_while_start}}{
        $n_{selected} \gets \mathrm{\textbf{select}}(n_{root}, \delta)$\; \label{a_CoDy_l_selection}
        $\mathrm{\textbf{simulate}}(n_{selected}, f, \mathcal{G}, \varepsilon_i)$\; \label{a_CoDy_l_simulation}
        $\mathrm{\textbf{expand}}(n_{selected}, prediction_{orig})$\; \label{a_CoDy_l_expansion}
        $\mathrm{\textbf{backpropagate}}(parent_{selected})$\;\label{a_CoDy_l_backpropagation}
        $it \gets it + 1$\;
    }\label{a_CoDy_l_while_end}
    $n_{best} \gets \mathrm{\textbf{select\_best}}(n_{root})$\; \label{a_CoDy_l_select_best}
    \KwRet{$s_{best}$}
\end{algorithm}
}

Algorithm \ref{a_CoDy} provides a high-level overview of the \gls{cftgnn} search algorithm. The algorithm takes the link prediction function $f$, the dynamic graph $\mathcal{G}$, a potential future edge addition event $\varepsilon_i$, and a selection strategy $\delta$ as input. Additionally, the algorithm is provided with a maximum number of iterations $it_{max}$. The algorithm first computes the original prediction $prediction_{orig}$ and initializes the root node $n_{root}$ of the search tree. The main search logic happens in iterations, illustrated by the while loop (lines \ref{a_CoDy_l_while_start}-\ref{a_CoDy_l_while_end}). This loop concludes after $it_{max}$ iterations or when the search tree is fully explored. A fully explored search tree is identified when the root node $n_{root}$ is not selectable anymore. This may be the case when it is not possible to find new counterfactual examples. Each iteration starts with a selection process (line \ref{a_CoDy_l_selection}). This selection process traverses the partial search tree starting at the root node. This traversal ends when a node that is not yet expanded is encountered. This node is then returned and selected. Next, the prediction associated with the perturbation of the selected node is computed (line \ref{a_CoDy_l_simulation}). Subsequently, the node is expanded (line \ref{a_CoDy_l_expansion}), and finally, the results are propagated upwards through the search tree (line \ref{a_CoDy_l_backpropagation}). The search concludes by selecting the input perturbation that provides the best counterfactual explanation of the prediction that has been found (line \ref{a_CoDy_l_select_best}). The inner workings of these steps are the subject of the following sections.

\FloatBarrier
\subsubsection{Selection}
\label{s_Methodology_CoDy_Selection}
% The selection process starts at the root node and then recursively applies a child selection policy to traverse the tree until an expandable node is reached. A node is expandable if it has not yet undergone expansion, meaning that it does not have any child nodes and has yet to be associated with a prediction score.
The first step in each search iteration is the selection of a new node to expand. The selection procedure initiates from the root node and subsequently employs a recursive child selection policy to traverse the partial search tree until encountering a node suitable for expansion. A node $n_j \in P$ in the partial search tree qualifies for expansion if it has not yet undergone the expansion process, implying that it is not yet associated with child nodes ($children_j = \varnothing$) and it is not yet affiliated with a prediction score ($prediction_j = null$).

The child selection algorithm aims to balance the exploration of the search tree with the exploitation of already-known promising paths through the search tree. Given a node in the search tree $n_j$ that has already been expanded, the selection procedure selects one of its child nodes. The selection hinges on a score $selection\_score(n_k)$ that is calculated for all selectable children $n_k \in selectable\_children(n_j)$ of $n_j$:

\begin{equation}
    selectable\_children(n_j) = \{n_k: n_k \in children_j, \hspace{1.5mm} selectable_k = 1\}
\end{equation}

The child node $n_k$ out of the selectable children that has the highest score $selection\_score(n_k)$ is selected.

\begin{equation}
    \argmax_{n_k \in selectable\_children(n_j)} selection\_score(n_k)
\end{equation}

The selection score combines the exploitation score $score_k$ associated with the node $n_k$ with an exploration score $score_{exploration}(n_k)$, which is calculated based on the node's level of past exploration.

\begin{equation}
    selection\_score(n_k) = \alpha * score_k + \beta * score_{exploration}(n_k)
\end{equation}

Here, $\alpha$ and $\beta$ are tunable hyperparameters that adjust the balance between the two terms. The exploitation term $\alpha * score(n_j)$ encourages selecting nodes already associated with a high exploitation score. In contrast, the exploration term $\beta * score_{exploration}(n_j)$ promotes the exploration of nodes with little past selections.

The exploration score is adapted from the 'Upper Confidence Bound 1' introduced by \cite{auer_finite-time_2002}, which is popular across various \gls{mcts} implementations \cite{kocsis_bandit_2006, browne_survey_2012}. For a node $n_k$ with parent $n_j = parent_k$, the score is defined as:

\begin{equation}
    score_{exploration}(n_k) = \sqrt{\frac{ln(selections_j)}{selections_k}}
\end{equation}

This score $score_{exploration}(n_k)$ quantifies the uncertainty about selecting node $n_k$ \cite{auer_finite-time_2002, browne_survey_2012}. A higher exploration score means that less is known about the potential impact on the prediction that follows from selecting this node.

In contrast to the exploration score, the exploitation score $score_k$ is not calculated during the selection step. Rather, this attribute is set at the expansion step of the \gls{cftgnn} search algorithm (see Section \ref{s_Methodology_CoDy_Expansion}) and updated in the backpropagation (see Section \ref{s_Methodology_CoDy_Backpropagation}).

If more than one child node has the same score, a selection strategy $\delta$ is used to select a child. This selection strategy can be any of the selection strategies introduced in Section \ref{s_Methodology_SelectionStrategies}. For example, the selection strategy is used when none of the children of a node have been expanded yet and are thus associated with the same score. The complete selection process is described in Algorithm \ref{a_MCTS_Select}, which recursively explores the search tree following the outlined procedure. The recursion ends when a node is encountered that has not yet been expanded (line \ref{a_CoDy_Select_recursion}). If multiple child nodes share the same highest selection score (line \ref{a_CoDy_Select_multiple}), the selection strategy $\delta$ is used to make the selection between the highest-ranking children.

{
\setlength{\algomargin}{1.25em}
\small
\begin{algorithm}[ht]
\caption{Recursive selection algorithm.}
\label{a_MCTS_Select}
    \Fn{\textbf{select}($n_j, \hspace{1.5mm} \delta$)}{
    \If{$n_j$ is not yet expanded \label{a_CoDy_Select_recursion}}{
        return $n_j$;
    }
    %\If{$selectable\_children(n_i)$ is empty}{
    %    return $n_i$;
    %}
    $n_{best} \gets \argmax_{n_k \in \hspace{1mm} selectable\_children(n_j)} selection\_score(n_k)$\;
    \If{there is more than one child with the highest selection score \label{a_CoDy_Select_multiple}}{
        $n_{best} \gets$ highest ranking child node according to selection strategy $\delta$\;
    }
    return $\textbf{select}(n_{best})$\;
    }
\end{algorithm}
}

\FloatBarrier
\subsubsection{Simulation}
\label{s_Methodology_CoDy_Simulation}
The next step after selecting a node $n_j$ is referred to as simulation. This step consists of making a call to the link prediction function $f$ to infer the prediction associated with the node. The prediction $prediction_j$ associated with the selected node $n_j$ is calculated as the prediction for the explained event $\varepsilon_i$ when the events in the perturbation set $s_j$ associated with node $n_j$ are removed from the set of past events $\mathcal{G}(t_i)$ in the original input. 

\begin{equation}
    prediction_j = f(\mathcal{G}(t_i) \setminus s_j, \varepsilon_i)
\end{equation}

This procedure is outlined in Algorithm \ref{a_MCTS_Simulate}. It shows that the simulate function infers the score associated with the selected node. %This is different from traditional \gls{mcts}, where the simulation step consists of simulating the outcome of a game from that position in the search tree by randomly taking actions until the game finishes \cite{kocsis_bandit_2006}. The idea behind this simulation is to gauge how likely it is to win the game from this position \cite{kocsis_bandit_2006}. Since it is possible to infer the prediction score for the input perturbation associated with any 

{
\setlength{\algomargin}{1.25em}
\small
\begin{algorithm}[ht]
\caption{Algorithm for simulating the link prediction on the selected node.}
\label{a_MCTS_Simulate}
    \Fn{\textbf{simulate}($n_j$, $f$, $\mathcal{G}$, $\varepsilon_i$)}{
    $prediction_j \gets f(\mathcal{G}(t_i) \setminus s_j, \varepsilon_i)$\;
    return $prediction_j$\;
    }
\end{algorithm}
}

\FloatBarrier
\subsubsection{Expansion}
\label{s_Methodology_CoDy_Expansion}

Following the simulation step, the expansion step involves updating the attributes of the selected node $n_j$. The exploitation score $score_j$ is initialized as the relative magnitude of the shift between the original prediction score $prediction_{orig}$ and the prediction score linked to the expanded node $prediction_j$. If this value is negative, the exploitation score is set to $0$. 

\begin{equation}
    \label{e_MCTS_score}
    score_j \gets \max\left(0, \frac{\Delta(prediction_{orig}, prediction_j)}{|prediction_{orig}|}\right)
\end{equation}

The $\Delta$-function introduced in Section \ref{s_Methodology_SelectionStrategies} is reused here. If the score defined in \ref{e_MCTS_score} is greater than $1$, that signifies that the link prediction associated with node $n_j$ is classified differently from the original link prediction, making $s_j$ a counterfactual example.

In addition to calculating the exploitation score, the expansion step also adds a set of children to the selected node, which expands the partial search tree. As discussed in Section \ref{s_Methodology_SearchSpace}, all child nodes $n_k$ of the expanded node $n_j$ have to satisfy the conditions described in Equations \ref{e_child_1}, \ref{e_child_2}, and \ref{e_child_3}. That is, the perturbation sets associated with the child nodes have to extend the perturbation set associated with the expanded node by exactly one event. Thus, the set of child nodes to the expanded node $n_j$ is given as:

%each node $n_j \in T$ is primarily defined by its associated set of perturbations $s_j$. 

%Let $n_k$ be a node in the search tree, associated with the perturbations $s_k$. Then, each input perturbation $s_k$ that satisfies the following constraints serves as the basis for a valid child node to $n_k$:

%\begin{equation}
%    \label{e_child_1}
%    s_k \in \hat{S}_{\varepsilon_i}
%\end{equation}

%\begin{equation}
%    \label{e_child_2}
%    s_j \subset s_k
%\end{equation}

%\begin{equation}
%    \label{e_child_3}
%    |s_k| = |s_j| + 1
%\end{equation}

%This means that any child node $n_k$ to a parent node $n_j$ has to be associated with an input perturbation $s_k$ that is part of the search space (Equation \ref{e_child_1}), that includes all the events in the input perturbation $s_k$ associated with its parent (Equation \ref{e_child_2}), and that includes one more event than $s_k$ (Equation \ref{e_child_3}). New child nodes are initialized for each of the input perturbations that satisfies these constraints. These new nodes are then associated with their parent node $n_j$:


\begin{equation}
    children_j \gets \{(s_k, null, n_j, \varnothing, 0, null, 1): s_k \in \hat{S}_{\varepsilon_i} \hspace{1.5mm} \mathrm{with} \hspace{1.5mm} |s_k| = |s_j| + 1, s_j \subset s_k\}
\end{equation}

The child nodes are initialized with $null$ values for their prediction and score attributes and an empty set of child nodes. These attributes are only assigned once any of these child nodes are selected and expanded themselves.

The expansion step is summarized in Algorithm \ref{a_MCTS_Expand}. After assigning the initial score to the selected node (line \ref{a_CoDy_Expand_l_initial_score}), the function checks whether the prediction associated with the node is counterfactual to the original prediction (line \ref{a_CoDy_Expand_l_cf}). If so, the algorithm concludes and sets the selectable flag $selectable_j$ to $0$, which prevents future selections of node $n_j$. It would not make sense to select $n_j$ again, as it already constitutes a counterfactual example. Further deepening the search tree from node $n_j$ could only encounter counterfactual examples with higher complexity, violating the objective of minimizing complexity. In the case that the prediction associated with the selected node $n_j$ is not counterfactual to the original prediction, the child nodes $children_j$ are initialized (line \ref{a_CoDy_Expand_l_init_children}).

{
\setlength{\algomargin}{1.25em}
\begin{algorithm}[ht]
\caption{Function for expanding the selected node.}
\small
\label{a_MCTS_Expand}
    \Fn{\textbf{expand}($n_j, \hspace{1.5mm} prediction_{orig}$)}{
        $selections_j \gets 1$\; \label{a_CoDy_Expand_selection_score_set}
        $score_j \gets \max\left(0, \frac{\Delta(prediction_{orig}, prediction_j)}{|prediction_{orig}|}\right)$\;\label{a_CoDy_Expand_l_initial_score}
        
        \uIf{$score_j > 1$ \label{a_CoDy_Expand_l_cf}}{
            $selectable_j \gets 0$\;
            Add $n_j$ to a list of counterfactual examples $cf\_examples$\;
        }\Else{
            $children_j \gets \{(s_k, null, n_j, \varnothing, 0, null, 1): s_k \in \hat{S}_{\varepsilon_j} \hspace{1.5mm} \mathrm{with} \hspace{1.5mm} |s_k| = |s_j| + 1, s_j \subset s_k\}$\; \label{a_CoDy_Expand_l_init_children}
        }
    }
\end{algorithm}
}

\subsubsection{Backpropagation}
\label{s_Methodology_CoDy_Backpropagation}

Backpropagation is the last step in the search iteration. It serves to update information in the search tree starting at the parent $n_p$ of the expanded node $n_j$, recursively traversing backward through the search tree until the root node is reached. The backpropagation increments the number of selections by one, updates the exploitation score, and checks if the node is still selectable.

The exploitation score $score_j$ of a node $n_j$ is updated to estimate the potential for finding a counterfactual example among its descendants. It is thus calculated as the weighted average of the exploitation scores of its children and the initial exploitation score associated with $n_j$ itself. The initial exploitation score results from the expansion step and is calculated according to Equation \ref{e_MCTS_score}. Thus, the update is computed as follows:
%to a weighted average of its initial exploitation score as presented in \ref{e_MCTS_score} and the exploitation scores of its children. The exploitation score of a child $n_k$ is weighted with its number of selections $selections_k$:

\begin{equation}
    score_j \gets \frac{
        \max\left(0, \frac{\Delta(prediction_{orig}, prediction_j)}{|prediction_{orig}|}\right) + \sum_{n_k \in children_j} (score_k * selections_k)
    }{
        selections_j
    }
\end{equation}

To estimate the potential for finding a counterfactual example among the descendants of node $n_j$, the exploitation scores of each child node $n_k$ are weighted with its number of selections $selections_k$. This follows the assumption that the more a node is selected, the more accurate its estimation should become.

Algorithm \ref{a_MCTS_Backpropagation} presents the full backpropagation procedure. For easier readability, the update of the exploitation score is presented over lines \ref{a_CoDy_Backprop_score_update_start}-\ref{a_CoDy_Backprop_score_update_end}. The backpropagation also checks if any of the child nodes is selectable. If no child node is selectable, the partial search tree cannot be expanded from any of the descendant nodes. Thus, the node is marked as not selectable itself. The backpropagation concludes when it reaches the root node (line \ref{a_CoDy_Backprop_return}).

{
\setlength{\algomargin}{1.25em}
\small
\begin{algorithm}[ht]
\caption{Backpropagation function that recursively updates the information of nodes in the search tree.}
\label{a_MCTS_Backpropagation}
    \Fn{\textbf{backpropagate}($n_j$)}{
        \If{$n_j = null$ \label{a_CoDy_Backprop_return}}{
            \KwRet{}\;
        }
        $selections_j \gets selections_j + 1$\;
        $score_j \gets \max\left(0, \frac{\Delta(prediction_{orig}, prediction_j)}{|prediction_{orig}|}\right)$\; \label{a_CoDy_Backprop_score_update_start}
        $score_j \gets score_j + \sum_{n_k \in children_j} (score_k * selections_k)$\;
        $score_j \gets \frac{score_j}{selections_j}$\; \label{a_CoDy_Backprop_score_update_end}
    }
\end{algorithm}
}



\subsubsection{Explanation Selection and Fallback}
\label{s_Methodology_CoDy_Fallback}
After the search iterations have concluded, the node in the search tree associated with the best counterfactual explanation is selected. This is trivial when exactly one counterfactual example has been encountered during the search. If multiple counterfactual examples were encountered, the best of them is selected according to the search objectives. When the search did not find any counterfactual examples, a fallback strategy is invoked that provides the next best explanation.

Selecting the best node associated with a counterfactual example amongst several candidate nodes \(cf\_examples\) involves rating the candidates according to the objective of minimizing complexity. Accordingly, only the examples $n_j \in cf\_examples$ with the least number of associated perturbations $s_j$ are considered:

\begin{equation}
    smallest\_examples = \argmin_{n_j \in cf\_examples} |s_j|
\end{equation}

Since there may be multiple nodes in the set of nodes associated with the smallest examples $smallest\_examples$, a further step has to be made. Thus, the node from the $smallest\_examples$ that has the highest exploitation score is selected. Ordering the nodes in this manner ensures that the selected counterfactual example achieves its counterfactual status with a larger margin than the other smallest examples.

\begin{equation}
    n_{best} = \argmax_{n_j \in smallest\_examples} score_j
\end{equation}

In the case that no counterfactual example could be found during the search, \gls{cftgnn} still provides a fallback explanation. The provided explanation, in this case, is the perturbation associated with the prediction that is shifted the most towards the opposite sign of the original prediction. Formally, the node in the search tree that is associated with the largest shift $n_{best}$ is defined as:

\begin{equation}
    n_{best} = \argmax_{n_j \in T} \Delta(prediction_{orig}, prediction_j)
\end{equation}

These strategies are part of Algorithm \ref{a_MCTS_ResultSelection}, which shows the selection process. If possible, the algorithm selects the node associated with the smallest counterfactual example (lines \ref{a_CoDy_ResultSelection_cf_begin}-\ref{a_CoDy_ResultSelection_cf_end}). If not, it employs the fallback strategy to select a node accordingly (lines \ref{a_CoDy_ResultSelection_fallback_begin}-\ref{a_CoDy_ResultSelection_fallback_end}).

{
\setlength{\algomargin}{1.25em}
\small
\begin{algorithm}[ht]
\caption{Algorithm for selecting the best counterfactual example, or the example that comes closest to being counterfactual.}
\label{a_MCTS_ResultSelection}
    \Fn{\textbf{select\_best}($n_{root}$)}{
        $P \gets$ set of all nodes in the partial search tree starting from root node $n_{root}$\;
        \uIf{the search did find counterfactual examples $cf\_examples$ \label{a_CoDy_ResultSelection_cf_begin}}{
            $smallest\_examples \gets \argmin_{n_j \in cf\_examples} |s_j|$\;
            $n_{best} \gets \argmax_{n_j \in smallest\_examples} score_j$\; \label{a_CoDy_ResultSelection_cf_end}
        }\Else{\label{a_CoDy_ResultSelection_fallback_begin}
            $n_{best} \gets \argmax_{n_j \in P} \Delta(prediction_{orig}, prediction_j)$\;\label{a_CoDy_ResultSelection_fallback_end}
        }
        return $n_{best}$\;
    }
\end{algorithm}
}

\FloatBarrier
\subsubsection{Search Optimizations}
\label{s_Methodology_CoDy_Optimizations}

While the \gls{cftgnn} search strategy, as it is presented in the previous sections, already provides a good basis for searching for counterfactual explanations, the procedure is further optimized. \gls{cftgnn} employs dynamic constraints on the search tree to minimize the complexity of explanations. Additionally, caching is used to minimize redundant computations, and an approximation approach is utilized to significantly speed up the inference time of the link prediction function.
%While the principles behind the search algorithm presented in the previous section provide a good basis for searching for counterfactual examples, the search performance is further optimized. \gls{cftgnn} employs dynamic constraints on the search tree to minimize the complexity of explanations. Additionally, caching is used to minimize redundant computations, and an approximation approach is utilized to significantly speed up the inference time of the link prediction function.

The first optimization leverages the objective of minimizing the complexity of the counterfactual example. When the search algorithm encounters a node $n_j$ for which the associated perturbation set $s_j$ constitutes a counterfactual example, any other node $n_k$ associated with a perturbation set $s_k$ containing more events than $s_j$ would be considered worse than $n_j$. Thus, the search should not explore nodes in the search tree associated with a perturbation set that has a higher complexity than $s_j$. The complexity of a perturbation set $s_j$ is measured by the number of events it contains $|s_j|$. \gls{cftgnn} implements this dynamic constraint on exploring the search tree by modifying the search tree once a node $n_j$ associated with a counterfactual example is expanded. This is done by marking all nodes $n_k \in T$ with $|s_k| = |s_j| + 1$ as not selectable ($selectable_k = 0$) and then updating the selectability attribute of all nodes $n_l$ with lower or equal complexity $|s_l| \leq |s_j|$. To update the selectability attribute of a node $n_l$, the selectability attribute of all its child nodes $children_l$ is checked, and if none of the child nodes remain selectable, the selectability attribute $selectable_j$ of node $n_j$ is set to $0$ itself.
%the same way as in the backpropagation step (see Algorithm \ref{a_MCTS_Backpropagation}). 
Additionally, from thereon, when a node $n_k$ with the same complexity as $n_j$ is selected and expanded, it is marked as non-selectable to prohibit the search algorithm from exploring its children.

The other optimizations do not alter the search algorithm but provide means to speed up the runtime of the search significantly. Making calls to the link prediction function can be costly since models on dynamic graphs, like \glspl{tgnn}, tend to have a high computational cost. That is because they need to process all past events to make a prediction. Thus, the optimizations aim to prevent redundant calls to such models and speed up inference when calling the link prediction function.

By design, the search tree can have multiple nodes that are associated with the same set of perturbations. For instance, the perturbation set $s_j = \{\varepsilon_3, \varepsilon_5\}$ can be encountered when first selecting $\varepsilon_3$ and then selection $\varepsilon_5$, or the other way around. While this results in two distinct nodes in the search tree, the prediction associated with both of them is the same. Thus, \gls{cftgnn} caches the prediction results associated with a perturbation the first time a node with that perturbation is expanded. When another node that shares the same perturbation set is expanded in a later iteration, it is associated with the cached prediction instead of calling the link prediction function again.

The last optimization concerns the calls to the link prediction function. For many of the state-of-the-art \gls{tgnn} models operating on \glspl{ctdg} \cite{rossi_temporal_2020, souza_provably_2022}, the runtime for predicting a potential future link $\varepsilon_i$ is dependent on the how many past events $\mathcal{G}(t_i)$ there are. Thus, reducing the number of past events also reduces the runtime of such a link prediction function. To harness this potential, \gls{cftgnn} employs a two-stage approximation-confirmation approach that improves runtimes while maintaining accurate predictions. When the link prediction function is called to get a prediction for the occurrence of a potential future link $\varepsilon_i$ with input perturbations $s_j$, not all events are used for the initial inference of the prediction. The reduced set of past events for inferring the prediction with an input perturbation $s_j$ consists of two parts: First, all events that happen prior to the earliest candidate event $\varepsilon_{min}$ that is considered for the explanation. Second, all candidate events $C(\mathcal{G}, \varepsilon_i, k, m_{max})$ that are not part of the input perturbation $s_j$.

The events prior to the earliest candidate event are included for an accurate basis of the dynamic graph. From the oldest candidate event onwards, only the candidate events are included because the candidate events are chosen in a way that aims to select all the recent events that can significantly influence the prediction, as outlined in Section \ref{s_Methodology_SearchSpace_Constraints}. Thus, it can be assumed that the other events that take place after $\varepsilon_{min}$ are of insignificant importance to the prediction. Hence, the omission of these events has only a minor effect on the output of the link prediction function.

Formally, the oldest candidate event $\varepsilon_{min} \in C(\mathcal{G}, \varepsilon_i, k, m_{max})$ is defined as:

\begin{equation}
    \varepsilon_{min} = \argmin_{\varepsilon_j \in C(\mathcal{G}, \varepsilon_i, k, m_{max})} t_j
\end{equation}

Thus, the approximated prediction $prediction_l^{approximation}$ for the occurrence of the future link $\varepsilon_i$ with input perturbation $s_j$ is calculated as: 

\begin{equation}
    prediction_l^{approximation} = f((\mathcal{G}(t_{min - 1}) \cup C(\mathcal{G}, \varepsilon_i, k, m_{max})) \setminus s_l, \varepsilon_i)
\end{equation}

The confirmation stage is for the prediction is only invoked if the approximated prediction suggests that the input perturbation $s_l$ constitutes a counterfactual example. In such cases, the prediction is confirmed by computing the exact score, using all past events besides the input perturbation for the prediction:

\begin{equation}
    prediction_l^{confirmation} = f(\mathcal{G}(t_i) \setminus s_l, \varepsilon_i)
\end{equation}

This two-stage approach substantially speeds up the search process while keeping the results accurate by confirming potential counterfactuals.

\FloatBarrier
\subsubsection{Example of the Search Algorithm}
\label{s_Methodology_CoDy_Example}

Figure \ref{f_search_example} exemplifies the operations of the search algorithm. It depicts how the \gls{cftgnn} search algorithm operates and constructs the partial search tree. In the depicted case the candidate events ${C(\mathcal{G}, \varepsilon_i, k, m_{max})}$ only consist of three past events $\varepsilon_1, \varepsilon_2, \varepsilon_3$. Following along the search algorithm, in the first iteration the root node is selected. 

\begin{figure}[ht!]
    \centering
    \include{figures/methodology/search_example}
    \caption{Schematic depiction of the iterative expansion of the partial search tree.}
    \label{f_search_example}
\end{figure}

Simulating on the root node produces the original prediction score, which is $3.179$ in this case. This score means that the potential future edge addition event $\varepsilon_i$ is classified to occur. The expansion step in the first iteration adds new child nodes to the root, one for each of the candidate events. Let $s_1 = \{\varepsilon_1\}, s_2 = \{\varepsilon_2\}, s_3 = \{\varepsilon_3\}$. Since none of the child nodes of the root have been explored to this point, the second iteration employs the selection strategy $\delta$ to select node $n_2$. After simulation, this node is expanded, adding two child nodes associated with the input perturbations $s_4 = \{\varepsilon_1, \varepsilon_2\}$, and $s_5 = \{\varepsilon_2, \varepsilon_3\}$. Iteration $3$ selects node $n_5$. The expansion only adds a single child node associated with $s_6 = \{\varepsilon_1, \varepsilon_2, \varepsilon_3\}$. In iteration $4$, the newly added child node $n_6$ is selected. Since it has no children, backpropagation marks the node as no longer selectable. The same applies to its parent node $n_5$. In iteration $5$, the exploration score associated with the unexplored children of the root node is large enough so that $n_2$ is no longer selected over the unexplored alternatives. Thus, $\delta$ is applied, resulting in the selection of node $n_1$. The simulation of $n_1$ yields a negative score, meaning that its associated perturbation constitutes a counterfactual example. Following the optimization of dynamic constraints on the search space, all nodes associated with a perturbation set that contains more than one element are marked as no longer selectable. In this instance, this applies to node $n_4$. Marking node $n_4$ as not selectable also makes node $n_2$ no longer selectable since none of its children remain selectable. Thus, in the final iteration, node $n_3$ is selected as the only option. After this iteration, none of the nodes remain selectable, meaning that the search tree is fully explored and the search can conclude. As node $n_1$ is the only node associated with a counterfactual example, it is selected as the best node, and the input perturbation $s_1 = \{\varepsilon_1\}$ is returned as the minimal counterfactual example.


