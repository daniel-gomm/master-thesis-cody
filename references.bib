
@article{wellawatte_model_2022,
	title = {Model agnostic generation of counterfactual explanations for molecules},
	volume = {13},
	issn = {2041-6539},
	url = {https://pubs.rsc.org/en/content/articlelanding/2022/sc/d1sc05259d},
	doi = {10.1039/D1SC05259D},
	abstract = {An outstanding challenge in deep learning in chemistry is its lack of interpretability. The inability of explaining why a neural network makes a prediction is a major barrier to deployment of AI models. This not only dissuades chemists from using deep learning predictions, but also has led to neural networks learning spurious correlations that are difficult to notice. Counterfactuals are a category of explanations that provide a rationale behind a model prediction with satisfying properties like providing chemical structure insights. Yet, counterfactuals have been previously limited to specific model architectures or required reinforcement learning as a separate process. In this work, we show a universal model-agnostic approach that can explain any black-box model prediction. We demonstrate this method on random forest models, sequence models, and graph neural networks in both classification and regression.},
	language = {en},
	number = {13},
	urldate = {2023-12-06},
	journal = {Chemical Science},
	author = {Wellawatte, Geemi P. and Seshadri, Aditi and White, Andrew D.},
	month = mar,
	year = {2022},
	note = {Publisher: The Royal Society of Chemistry},
	pages = {3697--3705},
}

@article{huang_graphlime_2023,
	title = {{GraphLIME}: {Local} {Interpretable} {Model} {Explanations} for {Graph} {Neural} {Networks}},
	volume = {35},
	issn = {1558-2191},
	shorttitle = {{GraphLIME}},
	url = {https://ieeexplore.ieee.org/document/9811416},
	doi = {10.1109/TKDE.2022.3187455},
	abstract = {Recently, graph neural networks (GNN) were shown to be successful in effectively representing graph structured data because of their good performance and generalization ability. However, explaining the effectiveness of GNN models is a challenging task because of the complex nonlinear transformations made over the iterations. In this paper, we propose GraphLIME, a local interpretable model explanation for graphs using the Hilbert-Schmidt Independence Criterion (HSIC) Lasso, which is a nonlinear feature selection method. GraphLIME is a generic GNN-model explanation framework that learns a nonlinear interpretable model locally in the subgraph of the node being explained. Through experiments on two real-world datasets, the explanations of GraphLIME are found to be of extraordinary degree and more descriptive in comparison to the existing explanation methods.},
	number = {7},
	urldate = {2023-12-06},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Huang, Qiang and Yamada, Makoto and Tian, Yuan and Singh, Dinesh and Chang, Yi},
	month = jul,
	year = {2023},
	note = {Conference Name: IEEE Transactions on Knowledge and Data Engineering},
	pages = {6968--6972},
}

@article{schnake_higher-order_2022,
	title = {Higher-{Order} {Explanations} of {Graph} {Neural} {Networks} via {Relevant} {Walks}},
	volume = {44},
	issn = {0162-8828, 2160-9292, 1939-3539},
	url = {https://ieeexplore.ieee.org/document/9547794/},
	doi = {10.1109/TPAMI.2021.3115452},
	abstract = {Graph Neural Networks (GNNs) are a popular approach for predicting graph structured data. As GNNs tightly entangle the input graph into the neural network structure, common explainable AI approaches are not applicable. To a large extent, GNNs have remained black-boxes for the user so far. In this paper, we show that GNNs can in fact be naturally explained using higher-order expansions, i.e., by identifying groups of edges that jointly contribute to the prediction. Practically, we ﬁnd that such explanations can be extracted using a nested attribution scheme, where existing techniques such as layer-wise relevance propagation (LRP) can be applied at each step. The output is a collection of walks into the input graph that are relevant for the prediction. Our novel explanation method, which we denote by GNN-LRP, is applicable to a broad range of graph neural networks and lets us extract practically relevant insights on sentiment analysis of text data, structure-property relationships in quantum chemistry, and image classiﬁcation.},
	language = {en},
	number = {11},
	urldate = {2023-12-06},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Schnake, Thomas and Eberle, Oliver and Lederer, Jonas and Nakajima, Shinichi and Schutt, Kristof T. and Muller, Klaus-Robert and Montavon, Gregoire},
	month = nov,
	year = {2022},
	pages = {7581--7596},
}

@misc{noauthor_higher-order_nodate,
	title = {Higher-{Order} {Explanations} of {Graph} {Neural} {Networks} via {Relevant} {Walks}},
	url = {https://www.computer.org/csdl/journal/tp/2022/11/09547794/1x9Tw52fo0o},
	urldate = {2023-12-06},
}

@inproceedings{baldassarre_explainability_2019,
	title = {Explainability {Techniques} for {Graph} {Convolutional} {Networks}},
	url = {https://www.semanticscholar.org/paper/Explainability-Techniques-for-Graph-Convolutional-Baldassarre-Azizpour/8fb202cdcfec3b0e7ba0e3f88949d6d923b48b2d},
	abstract = {Graph Networks are used to make decisions in potentially complex scenarios but it is usually not obvious how or why they made them. In this work, we study the explainability of Graph Network decisions using two main classes of techniques, gradient-based and decomposition-based, on a toy dataset and a chemistry task. Our study sets the ground for future development as well as application to real-world problems.},
	urldate = {2023-12-06},
	booktitle = {International {Conference} on {Machine} {Learning}},
	author = {Baldassarre, Federico and Azizpour, Hossein},
	month = may,
	year = {2019},
}

@article{byrne_counterfactuals_2019,
	title = {Counterfactuals in {Explainable} {Artificial} {Intelligence} ({XAI}): {Evidence} from {Human} {Reasoning}},
	shorttitle = {Counterfactuals in {Explainable} {Artificial} {Intelligence} ({XAI})},
	url = {https://www.ijcai.org/proceedings/2019/876},
	abstract = {Electronic proceedings of IJCAI 2019},
	urldate = {2023-12-05},
	author = {Byrne, Ruth M. J.},
	year = {2019},
	pages = {6276--6282},
}

@article{jaccard_distribution_1912,
	title = {The {Distribution} of the {Flora} in the {Alpine} {Zone}.1},
	volume = {11},
	issn = {1469-8137},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1469-8137.1912.tb05611.x},
	doi = {10.1111/j.1469-8137.1912.tb05611.x},
	language = {en},
	number = {2},
	urldate = {2023-12-05},
	journal = {New Phytologist},
	author = {Jaccard, Paul},
	year = {1912},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1469-8137.1912.tb05611.x},
	pages = {37--50},
}

@inproceedings{amara_graphframex_2022,
	title = {{GraphFramEx}: {Towards} {Systematic} {Evaluation} of {Explainability} {Methods} for {Graph} {Neural} {Networks}},
	shorttitle = {{GraphFramEx}},
	url = {http://arxiv.org/abs/2206.09677},
	abstract = {As one of the most popular machine learning models today, graph neural networks (GNNs) have attracted intense interest recently, and so does their explainability. Users are increasingly interested in a better understanding of GNN models and their outcomes. Unfortunately, today’s evaluation frameworks for GNN explainability often rely on few inadequate synthetic datasets, leading to conclusions of limited scope due to a lack of complexity in the problem instances. As GNN models are deployed to more mission-critical applications, we are in dire need for a common evaluation protocol of explainability methods of GNNs. In this paper, we propose, to our best knowledge, the ﬁrst systematic evaluation framework for GNN explainability, considering explainability on three different “user needs”. We propose a unique metric that combines the ﬁdelity measures and classiﬁes explanations based on their quality of being sufﬁcient or necessary. We scope ourselves to node classiﬁcation tasks and compare the most representative techniques in the ﬁeld of input-level explainability for GNNs. For the inadequate but widely used synthetic benchmarks, surprisingly shallow techniques such as personalized PageRank have the best performance for a minimum computation time. But when the graph structure is more complex and nodes have meaningful features, gradientbased methods are the best according to our evaluation criteria. However, none dominates the others on all evaluation dimensions and there is always a trade-off. We further apply our evaluation protocol in a case study for frauds explanation on eBay transaction graphs to reﬂect the production environment.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {The {First} {Learning} on {Graphs} {Conference}},
	publisher = {arXiv},
	author = {Amara, Kenza and Ying, Rex and Zhang, Zitao and Han, Zhihao and Shan, Yinan and Brandes, Ulrik and Schemm, Sebastian and Zhang, Ce},
	month = oct,
	year = {2022},
	note = {arXiv:2206.09677 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Impact 2*, Relevance 4*},
}

@misc{chen_tempme_2023,
	title = {{TempME}: {Towards} the {Explainability} of {Temporal} {Graph} {Neural} {Networks} via {Motif} {Discovery}},
	shorttitle = {{TempME}},
	url = {http://arxiv.org/abs/2310.19324},
	abstract = {Temporal graphs are widely used to model dynamic systems with time-varying interactions. In real-world scenarios, the underlying mechanisms of generating future interactions in dynamic systems are typically governed by a set of recurring substructures within the graph, known as temporal motifs. Despite the success and prevalence of current temporal graph neural networks (TGNN), it remains uncertain which temporal motifs are recognized as the significant indications that trigger a certain prediction from the model, which is a critical challenge for advancing the explainability and trustworthiness of current TGNNs. To address this challenge, we propose a novel approach, called Temporal Motifs Explainer (TempME), which uncovers the most pivotal temporal motifs guiding the prediction of TGNNs. Derived from the information bottleneck principle, TempME extracts the most interaction-related motifs while minimizing the amount of contained information to preserve the sparsity and succinctness of the explanation. Events in the explanations generated by TempME are verified to be more spatiotemporally correlated than those of existing approaches, providing more understandable insights. Extensive experiments validate the superiority of TempME, with up to 8.21\% increase in terms of explanation accuracy across six real-world datasets and up to 22.96\% increase in boosting the prediction Average Precision of current TGNNs.},
	language = {en},
	urldate = {2023-11-30},
	publisher = {arXiv},
	author = {Chen, Jialin and Ying, Rex},
	month = oct,
	year = {2023},
	note = {arXiv:2310.19324 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@misc{european_parliament_proposal_2021,
	title = {Proposal for a regulation of the european parliament and of the council laying down harmonised rules on artificial intelligence (artificial intelligence act) and amending certain union legislative acts},
	url = {https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:52021PC0206},
	language = {en},
	urldate = {2023-11-27},
	author = {European Parliament},
	year = {2021},
}

@article{noauthor_artificial_nodate,
	title = {Artificial intelligence act},
	language = {en},
}

@misc{lam_graphcast_2023,
	title = {{GraphCast}: {Learning} skillful medium-range global weather forecasting},
	shorttitle = {{GraphCast}},
	url = {http://arxiv.org/abs/2212.12794},
	doi = {10.48550/arXiv.2212.12794},
	abstract = {Global medium-range weather forecasting is critical to decision-making across many social and economic domains. Traditional numerical weather prediction uses increased compute resources to improve forecast accuracy, but cannot directly use historical weather data to improve the underlying model. We introduce a machine learning-based method called "GraphCast", which can be trained directly from reanalysis data. It predicts hundreds of weather variables, over 10 days at 0.25 degree resolution globally, in under one minute. We show that GraphCast significantly outperforms the most accurate operational deterministic systems on 90\% of 1380 verification targets, and its forecasts support better severe event prediction, including tropical cyclones, atmospheric rivers, and extreme temperatures. GraphCast is a key advance in accurate and efficient weather forecasting, and helps realize the promise of machine learning for modeling complex dynamical systems.},
	urldate = {2023-11-27},
	publisher = {arXiv},
	author = {Lam, Remi and Sanchez-Gonzalez, Alvaro and Willson, Matthew and Wirnsberger, Peter and Fortunato, Meire and Alet, Ferran and Ravuri, Suman and Ewalds, Timo and Eaton-Rosen, Zach and Hu, Weihua and Merose, Alexander and Hoyer, Stephan and Holland, George and Vinyals, Oriol and Stott, Jacklynn and Pritzel, Alexander and Mohamed, Shakir and Battaglia, Peter},
	month = aug,
	year = {2023},
	note = {arXiv:2212.12794 [physics]},
	keywords = {Computer Science - Machine Learning, Physics - Atmospheric and Oceanic Physics},
}

@article{jumper_highly_2021,
	title = {Highly accurate protein structure prediction with {AlphaFold}},
	volume = {596},
	copyright = {2021 The Author(s)},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-03819-2},
	doi = {10.1038/s41586-021-03819-2},
	abstract = {Proteins are essential to life, and understanding their structure can facilitate a mechanistic understanding of their function. Through an enormous experimental effort1–4, the structures of around 100,000 unique proteins have been determined5, but this represents a small fraction of the billions of known protein sequences6,7. Structural coverage is bottlenecked by the months to years of painstaking effort required to determine a single protein structure. Accurate computational approaches are needed to address this gap and to enable large-scale structural bioinformatics. Predicting the three-dimensional structure that a protein will adopt based solely on its amino acid sequence—the structure prediction component of the ‘protein folding problem’8—has been an important open research problem for more than 50 years9. Despite recent progress10–14, existing methods fall far short of atomic accuracy, especially when no homologous structure is available. Here we provide the first computational method that can regularly predict protein structures with atomic accuracy even in cases in which no similar structure is known. We validated an entirely redesigned version of our neural network-based model, AlphaFold, in the challenging 14th Critical Assessment of protein Structure Prediction (CASP14)15, demonstrating accuracy competitive with experimental structures in a majority of cases and greatly outperforming other methods. Underpinning the latest version of AlphaFold is a novel machine learning approach that incorporates physical and biological knowledge about protein structure, leveraging multi-sequence alignments, into the design of the deep learning algorithm.},
	language = {en},
	number = {7873},
	urldate = {2023-11-27},
	journal = {Nature},
	author = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and Žídek, Augustin and Potapenko, Anna and Bridgland, Alex and Meyer, Clemens and Kohl, Simon A. A. and Ballard, Andrew J. and Cowie, Andrew and Romera-Paredes, Bernardino and Nikolov, Stanislav and Jain, Rishub and Adler, Jonas and Back, Trevor and Petersen, Stig and Reiman, David and Clancy, Ellen and Zielinski, Michal and Steinegger, Martin and Pacholska, Michalina and Berghammer, Tamas and Bodenstein, Sebastian and Silver, David and Vinyals, Oriol and Senior, Andrew W. and Kavukcuoglu, Koray and Kohli, Pushmeet and Hassabis, Demis},
	month = aug,
	year = {2021},
	note = {Number: 7873
Publisher: Nature Publishing Group},
	keywords = {Computational biophysics, Machine learning, Protein structure predictions, Structural biology},
	pages = {583--589},
}

@inproceedings{brown_language_2020,
	title = {Language {Models} are {Few}-{Shot} {Learners}},
	volume = {33},
	url = {https://papers.nips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html},
	abstract = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting.  For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model.  GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
	urldate = {2023-11-27},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	year = {2020},
	pages = {1877--1901},
}

@inproceedings{kunegis_konect_2013,
	title = {{KONECT} – {The} {Koblenz} {Network} {Collection}},
	url = {http://dl.acm.org/citation.cfm?id=2488173},
	booktitle = {Proc. {Int}. {Conf}. on {World} {Wide} {Web} {Companion}},
	author = {Kunegis, Jérôme},
	year = {2013},
	pages = {1343--1350},
}

@article{pennebaker_linguistic_2001,
	title = {Linguistic inquiry and word count: {LIWC} 2001},
	volume = {71},
	journal = {Mahway: Lawrence Erlbaum Associates},
	author = {Pennebaker, James W and Francis, Martha E and Booth, Roger J},
	year = {2001},
}

@misc{noauthor_notitle_nodate,
	url = {https://scholar.googleusercontent.com/scholar.bib?q=info:2URvpYrce9YJ:scholar.google.com/&output=citation&scisdr=ClE9XR4EENiOhfM4NhM:AFWwaeYAAAAAZVo-LhM-sW4SLZzM1_MObyrfrnI&scisig=AFWwaeYAAAAAZVo-LoDA3MWQB0-3RDTGU582CSY&scisf=4&ct=citation&cd=-1&hl=en},
	urldate = {2023-11-19},
}

@inproceedings{wang_inductive_2021,
	title = {Inductive {Representation} {Learning} in {Temporal} {Networks} via {Causal} {Anonymous} {Walks}},
	url = {http://arxiv.org/abs/2101.05974},
	abstract = {Temporal networks serve as abstractions of many real-world dynamic systems. These networks typically evolve according to certain laws, such as the law of triadic closure, which is universal in social networks. Inductive representation learning of temporal networks should be able to capture such laws and further be applied to systems that follow the same laws but have not been unseen during the training stage. Previous works in this area depend on either network node identities or rich edge attributes and typically fail to extract these laws. Here, we propose Causal Anonymous Walks (CAWs) to inductively represent a temporal network. CAWs are extracted by temporal random walks and work as automatic retrieval of temporal network motifs to represent network dynamics while avoiding the time-consuming selection and counting of those motifs. CAWs adopt a novel anonymization strategy that replaces node identities with the hitting counts of the nodes based on a set of sampled walks to keep the method inductive, and simultaneously establish the correlation between motifs. We further propose a neural-network model CAW-N to encode CAWs, and pair it with a CAW sampling strategy with constant memory and time cost to support online training and inference. CAW-N is evaluated to predict links over 6 real temporal networks and outperforms previous SOTA methods in the inductive setting. CAW-N also outperforms previous methods in 4 out of the 6 networks in the transductive setting.},
	language = {en},
	urldate = {2023-11-12},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Wang, Yanbang and Chang, Yen-Yu and Liu, Yunyu and Leskovec, Jure and Li, Pan},
	year = {2021},
	note = {arXiv:2101.05974 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks, Statistics - Machine Learning},
}

@inproceedings{bajaj_robust_2021,
	title = {Robust {Counterfactual} {Explanations} on {Graph} {Neural} {Networks}},
	abstract = {Massive deployment of Graph Neural Networks (GNNs) in high-stake applications generates a strong demand for explanations that are robust to noise and align well with human intuition. Most existing methods generate explanations by identifying a subgraph of an input graph that has a strong correlation with the prediction. These explanations are not robust to noise because independently optimizing the correlation for a single input can easily overﬁt noise. Moreover, they are not counterfactual because removing an identiﬁed subgraph from an input graph does not necessarily change the prediction result. In this paper, we propose a novel method to generate robust counterfactual explanations on GNNs by explicitly modelling the common decision logic of GNNs on similar input graphs. Our explanations are naturally robust to noise because they are produced from the common decision boundaries of a GNN that govern the predictions of many similar input graphs. The explanations are also counterfactual because removing the set of edges identiﬁed by an explanation from the input graph changes the prediction signiﬁcantly. Exhaustive experiments on many public datasets demonstrate the superior performance of our method.},
	language = {en},
	booktitle = {35th {Conference} on {Neural} {Information} {Processing} {System}},
	author = {Bajaj, Mohit and Chu, Lingyang and Xue, Zi Yu and Pei, Jian and Wang, Lanjun and Lam, Peter Cho-Ho and Zhang, Yong},
	year = {2021},
	keywords = {Dataset: BA-2motifs, Dataset: BA-Community, Dataset: BA-Shapes, Dataset: Mutagenicity, Dataset: NCI1, Dataset: Tree-Cycles, Dataset: Tree-Grid, Model: RCExplainer},
}

@article{auer_finite-time_2002,
	title = {Finite-time {Analysis} of the {Multiarmed} {Bandit} {Problem}},
	volume = {47},
	issn = {1573-0565},
	url = {https://doi.org/10.1023/A:1013689704352},
	doi = {10.1023/A:1013689704352},
	abstract = {Reinforcement learning policies face the exploration versus exploitation dilemma, i.e. the search for a balance between exploring the environment to find profitable actions while taking the empirically best action as often as possible. A popular measure of a policy's success in addressing this dilemma is the regret, that is the loss due to the fact that the globally optimal policy is not followed all the times. One of the simplest examples of the exploration/exploitation dilemma is the multi-armed bandit problem. Lai and Robbins were the first ones to show that the regret for this problem has to grow at least logarithmically in the number of plays. Since then, policies which asymptotically achieve this regret have been devised by Lai and Robbins and many others. In this work we show that the optimal logarithmic regret is also achievable uniformly over time, with simple and efficient policies, and for all reward distributions with bounded support.},
	language = {en},
	number = {2},
	urldate = {2023-11-07},
	journal = {Machine Learning},
	author = {Auer, Peter and Cesa-Bianchi, Nicolò and Fischer, Paul},
	month = may,
	year = {2002},
	keywords = {adaptive allocation rules, bandit problems, finite horizon regret},
	pages = {235--256},
}

@inproceedings{zhang_gstarx_2022,
	title = {{GStarX}: {Explaining} {Graph} {Neural} {Networks} with {Structure}-{Aware} {Cooperative} {Games}},
	language = {en},
	booktitle = {36th {Conference} on {Neural} {Information} {Processing} {Systems}},
	author = {Zhang, Shichang and Liu, Yozen and Shah, Neil and Sun, Yizhou},
	year = {2022},
}

@article{browne_survey_2012,
	title = {A {Survey} of {Monte} {Carlo} {Tree} {Search} {Methods}},
	volume = {4},
	issn = {1943-0698},
	url = {https://ieeexplore.ieee.org/document/6145622},
	doi = {10.1109/TCIAIG.2012.2186810},
	abstract = {Monte Carlo tree search (MCTS) is a recently proposed search method that combines the precision of tree search with the generality of random sampling. It has received considerable interest due to its spectacular success in the difficult problem of computer Go, but has also proved beneficial in a range of other domains. This paper is a survey of the literature to date, intended to provide a snapshot of the state of the art after the first five years of MCTS research. We outline the core algorithm's derivation, impart some structure on the many variations and enhancements that have been proposed, and summarize the results from the key game and nongame domains to which MCTS methods have been applied. A number of open research questions indicate that the field is ripe for future work.},
	number = {1},
	urldate = {2023-11-05},
	journal = {IEEE Transactions on Computational Intelligence and AI in Games},
	author = {Browne, Cameron B. and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M. and Cowling, Peter I. and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
	month = mar,
	year = {2012},
	note = {Conference Name: IEEE Transactions on Computational Intelligence and AI in Games},
	pages = {1--43},
}

@article{silver_mastering_2017,
	title = {Mastering the game of {Go} without human knowledge},
	volume = {550},
	copyright = {2017 Macmillan Publishers Limited, part of Springer Nature. All rights reserved.},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/nature24270},
	doi = {10.1038/nature24270},
	abstract = {A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo’s own move selections and also the winner of AlphaGo’s games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100–0 against the previously published, champion-defeating AlphaGo.},
	language = {en},
	number = {7676},
	urldate = {2023-11-04},
	journal = {Nature},
	author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
	month = oct,
	year = {2017},
	note = {Number: 7676
Publisher: Nature Publishing Group},
	keywords = {Computational science, Computer science, Reward},
	pages = {354--359},
}

@inproceedings{kocsis_bandit_2006,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Bandit {Based} {Monte}-{Carlo} {Planning}},
	isbn = {978-3-540-46056-5},
	doi = {10.1007/11871842_29},
	abstract = {For large state-space Markovian Decision Problems Monte-Carlo planning is one of the few viable approaches to find near-optimal solutions. In this paper we introduce a new algorithm, UCT, that applies bandit ideas to guide Monte-Carlo planning. In finite-horizon or discounted MDPs the algorithm is shown to be consistent and finite sample bounds are derived on the estimation error due to sampling. Experimental results show that in several domains, UCT is significantly more efficient than its alternatives.},
	language = {en},
	booktitle = {Machine {Learning}: {ECML} 2006},
	publisher = {Springer},
	author = {Kocsis, Levente and Szepesvári, Csaba},
	editor = {Fürnkranz, Johannes and Scheffer, Tobias and Spiliopoulou, Myra},
	year = {2006},
	keywords = {Bandit Problem, Drift Condition, Failure Probability, Multiarmed Bandit, Multiarmed Bandit Problem},
	pages = {282--293},
}

@book{stanley_enumerative_1986,
	address = {Boston, MA},
	title = {Enumerative {Combinatorics}},
	isbn = {978-1-4615-9765-0 978-1-4615-9763-6},
	url = {http://link.springer.com/10.1007/978-1-4615-9763-6},
	language = {en},
	urldate = {2023-11-04},
	publisher = {Springer US},
	author = {Stanley, Richard P.},
	year = {1986},
	doi = {10.1007/978-1-4615-9763-6},
	keywords = {Combinatorics, enumerative combinatorics},
}

@inproceedings{vu_pgm-explainer_2020,
	title = {{PGM}-{Explainer}: {Probabilistic} {Graphical} {Model} {Explanations} for {Graph} {Neural} {Networks}},
	shorttitle = {{PGM}-{Explainer}},
	url = {http://arxiv.org/abs/2010.05788},
	abstract = {In Graph Neural Networks (GNNs), the graph structure is incorporated into the learning of node representations. This complex structure makes explaining GNNs’ predictions become much more challenging. In this paper, we propose PGMExplainer, a Probabilistic Graphical Model (PGM) model-agnostic explainer for GNNs. Given a prediction to be explained, PGM-Explainer identiﬁes crucial graph components and generates an explanation in form of a PGM approximating that prediction. Different from existing explainers for GNNs where the explanations are drawn from a set of linear functions of explained features, PGM-Explainer is able to demonstrate the dependencies of explained features in form of conditional probabilities. Our theoretical analysis shows that the PGM generated by PGMExplainer includes the Markov-blanket of the target prediction, i.e. including all its statistical information. We also show that the explanation returned by PGMExplainer contains the same set of independence statements in the perfect map. Our experiments on both synthetic and real-world datasets show that PGM-Explainer achieves better performance than existing explainers in many benchmark tasks.},
	language = {en},
	urldate = {2023-05-21},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {arXiv},
	author = {Vu, Minh N. and Thai, My T.},
	month = oct,
	year = {2020},
	note = {arXiv:2010.05788 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{verma_counterfactual_2020,
	title = {Counterfactual {Explanations} for {Machine} {Learning}: {A} {Review}},
	abstract = {Machine learning plays a role in many deployed decision systems, often in ways that are difﬁcult or impossible to understand by human stakeholders. Explaining, in a human-understandable way, the relationship between the input and output of machine learning models is essential to the development of trustworthy machinelearning-based systems. A burgeoning body of research seeks to deﬁne the goals and methods of explainability in machine learning. In this paper, we seek to review and categorize research on counterfactual explanations, a speciﬁc class of explanation that provides a link between what could have happened had input to a model been changed in a particular way. Modern approaches to counterfactual explainability in machine learning draw connections to the established legal doctrine in many countries, making them appealing to ﬁelded systems in high-impact areas such as ﬁnance and healthcare. Thus, we design a rubric with desirable properties of counterfactual explanation algorithms and comprehensively evaluate all currently-proposed algorithms against that rubric. Our rubric provides easy comparison and comprehension of the advantages and disadvantages of different approaches and serves as an introduction to major research themes in this ﬁeld. We also identify gaps and discuss promising research directions in the space of counterfactual explainability.},
	language = {en},
	booktitle = {{NeurIPS} 2020 {Workshop}: {ML} {Retrospectives}, {Surveys} \& {Meta}-{Analyses} ({ML}-{RSA})},
	author = {Verma, Sahil and Dickerson, John and Hines, Keegan},
	year = {2020},
}

@inproceedings{ma_clear_2022,
	title = {{CLEAR}: {Generative} {Counterfactual} {Explanations} on {Graphs}},
	shorttitle = {{CLEAR}},
	url = {http://arxiv.org/abs/2210.08443},
	abstract = {Counterfactual explanations promote explainability in machine learning models by answering the question “how should an input instance be perturbed to obtain a desired predicted label?". The comparison of this instance before and after perturbation can enhance human interpretation. Most existing studies on counterfactual explanations are limited in tabular data or image data. In this work, we study the problem of counterfactual explanation generation on graphs. A few studies have explored counterfactual explanations on graphs, but many challenges of this problem are still not well-addressed: 1) optimizing in the discrete and disorganized space of graphs; 2) generalizing on unseen graphs; and 3) maintaining the causality in the generated counterfactuals without prior knowledge of the causal model. To tackle these challenges, we propose a novel framework CLEAR which aims to generate counterfactual explanations on graphs for graph-level prediction models. Speciﬁcally, CLEAR leverages a graph variational autoencoder based mechanism to facilitate its optimization and generalization, and promotes causality by leveraging an auxiliary variable to better identify the underlying causal model. Extensive experiments on both synthetic and real-world graphs validate the superiority of CLEAR over the state-of-the-art methods in different aspects.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {36th {Conference} on {Neural} {Information} {Processing} {Systems}},
	author = {Ma, Jing and Guo, Ruocheng and Mishra, Saumitra and Zhang, Aidong and Li, Jundong},
	month = nov,
	year = {2022},
	note = {arXiv:2210.08443 [cs]},
	keywords = {Computer Science - Machine Learning, Impact 1*, Relevance 5*},
}

@article{kakkad_survey_2023,
	title = {A {Survey} on {Explainability} of {Graph} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2306.01958},
	abstract = {Graph neural networks (GNNs) are powerful graph-based deep-learning models that have gained significant attention and demonstrated remarkable performance in various domains, including natural language processing, drug discovery, and recommendation systems. However, combining feature information and combinatorial graph structures has led to complex non-linear GNN models. Consequently, this has increased the challenges of understanding the workings of GNNs and the underlying reasons behind their predictions. To address this, numerous explainability methods have been proposed to shed light on the inner mechanism of the GNNs. Explainable GNNs improve their security and enhance trust in their recommendations. This survey aims to provide a comprehensive overview of the existing explainability techniques for GNNs. We create a novel taxonomy and hierarchy to categorize these methods based on their objective and methodology. We also discuss the strengths, limitations, and application scenarios of each category. Furthermore, we highlight the key evaluation metrics and datasets commonly used to assess the explainability of GNNs. This survey aims to assist researchers and practitioners in understanding the existing landscape of explainability methods, identifying gaps, and fostering further advancements in interpretable graph-based machine learning.},
	language = {en},
	urldate = {2023-10-13},
	journal = {IEEE Data Engineering Bulletin},
	author = {Kakkad, Jaykumar and Jannu, Jaspal and Sharma, Kartik and Aggarwal, Charu and Medya, Sourav},
	month = jun,
	year = {2023},
	note = {arXiv:2306.01958 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@inproceedings{faber_contrastive_2020,
	title = {Contrastive {Graph} {Neural} {Network} {Explanation}},
	url = {http://arxiv.org/abs/2010.13663},
	abstract = {Graph Neural Networks achieve remarkable results on problems with structured data but come as black-box predictors. Transferring existing explanation techniques, such as occlusion, fails as even removing a single node or edge can lead to drastic changes in the graph. The resulting graphs can differ from all training examples, causing model confusion and wrong explanations. Thus, we argue that explicability must use graphs compliant with the distribution underlying the training data. We coin this property Distribution Compliant Explanation (DCE) and present a novel Contrastive GNN Explanation (CoGE) technique following this paradigm. An experimental study supports the efﬁcacy of CoGE.},
	language = {en},
	urldate = {2023-10-30},
	booktitle = {Proceedings of the 37 th {Graph} {Representation} {Learning} and {Be}- yond {Workshop} at {ICML} 2020},
	publisher = {arXiv},
	author = {Faber, Lukas and Moghaddam, Amin K. and Wattenhofer, Roger},
	month = oct,
	year = {2020},
	note = {arXiv:2010.13663 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{quelhas_relation_2018,
	title = {The {Relation} {Between} {Factual} and {Counterfactual} {Conditionals}},
	volume = {42},
	copyright = {© 2018 Cognitive Science Society, Inc.},
	issn = {1551-6709},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cogs.12663},
	doi = {10.1111/cogs.12663},
	abstract = {What is the relation between factual conditionals: If A happened then B happened, and counterfactual conditionals: If A had happened then B would have happened? Some theorists propose quite different semantics for the two. In contrast, the theory of mental models and its computer implementation interrelates them. It postulates that both can have a priori truth values, and that the semantic bases of both are possibilities: states that are possible for factual conditionals, and that were once possible but that did not happen for counterfactual conditionals. Two experiments supported these relations. Experiment 1 showed that, like factual conditionals, certain counterfactuals are true a priori, and others are false a priori. Experiment 2 replicated this result and showed that participants selected appropriate paraphrases, referring, respectively, to real and to counterfactual possibilities, for the two sorts of conditional. These results are contrary to alternative accounts of conditionals.},
	language = {en},
	number = {7},
	urldate = {2023-10-30},
	journal = {Cognitive Science},
	author = {Quelhas, Ana Cristina and Rasga, Célia and Johnson-Laird, P. N.},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12663},
	keywords = {Conditionals, Counterfactual conditionals, Mental models, Possibilities, Probabilities},
	pages = {2205--2228},
}

@misc{lam_graphcast_2022,
	title = {{GraphCast}: {Learning} skillful medium-range global weather forecasting},
	copyright = {Creative Commons Attribution 4.0 International},
	shorttitle = {{GraphCast}},
	url = {https://arxiv.org/abs/2212.12794},
	doi = {10.48550/ARXIV.2212.12794},
	abstract = {Global medium-range weather forecasting is critical to decision-making across many social and economic domains. Traditional numerical weather prediction uses increased compute resources to improve forecast accuracy, but cannot directly use historical weather data to improve the underlying model. We introduce a machine learning-based method called "GraphCast", which can be trained directly from reanalysis data. It predicts hundreds of weather variables, over 10 days at 0.25 degree resolution globally, in under one minute. We show that GraphCast significantly outperforms the most accurate operational deterministic systems on 90\% of 1380 verification targets, and its forecasts support better severe event prediction, including tropical cyclones, atmospheric rivers, and extreme temperatures. GraphCast is a key advance in accurate and efficient weather forecasting, and helps realize the promise of machine learning for modeling complex dynamical systems.},
	urldate = {2023-10-27},
	author = {Lam, Remi and Sanchez-Gonzalez, Alvaro and Willson, Matthew and Wirnsberger, Peter and Fortunato, Meire and Alet, Ferran and Ravuri, Suman and Ewalds, Timo and Eaton-Rosen, Zach and Hu, Weihua and Merose, Alexander and Hoyer, Stephan and Holland, George and Vinyals, Oriol and Stott, Jacklynn and Pritzel, Alexander and Mohamed, Shakir and Battaglia, Peter},
	year = {2022},
	note = {Publisher: arXiv
Version Number: 2},
	keywords = {Atmospheric and Oceanic Physics (physics.ao-ph), FOS: Computer and information sciences, FOS: Physical sciences, Machine Learning (cs.LG)},
}

@inproceedings{huang_few-shot_2022,
	title = {Few-shot {Relational} {Reasoning} via {Connection} {Subgraph} {Pretraining}},
	url = {https://openreview.net/forum?id=LvW71lgly25},
	abstract = {Few-shot knowledge graph (KG) completion task aims to perform inductive reasoning over the KG: given only a few support triplets of a new relation \${\textbackslash}bowtie\$ (e.g., (chop,\${\textbackslash}bowtie\$,kitchen), (read,\${\textbackslash}bowtie\$,library), the goal is to predict the query triplets of the same unseen relation \${\textbackslash}bowtie\$, e.g., (sleep,\${\textbackslash}bowtie\$,?). Current approaches cast the problem in a meta-learning framework, where the model needs to be first jointly trained over many training few-shot tasks, each being defined by its own relation, so that learning/prediction on the target few-shot task can be effective. However, in real-world KGs, curating many training tasks is a challenging ad hoc process. Here we propose Connection Subgraph Reasoner (CSR), which can make predictions for the target few-shot task directly without the need for pre-training on the human curated set of training tasks. The key to CSR is that we explicitly model a shared connection subgraph between support and query triplets, as inspired by the principle of eliminative induction. To adapt to specific KG, we design a corresponding self-supervised pretraining scheme with the objective of reconstructing automatically sampled connection subgraphs. Our pretrained model can then be directly applied to target few-shot tasks on without the need for training few-shot tasks. Extensive experiments on real KGs, including NELL, FB15K-237, and ConceptNet, demonstrate the effectiveness of our framework: we show that even a learning-free implementation of CSR can already perform competitively to existing methods on target few-shot tasks; with pretraining, CSR can achieve significant gains of up to 52\% on the more challenging inductive few-shot tasks where the entities are also unseen during (pre)training.},
	language = {en},
	urldate = {2023-10-27},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Huang, Qian and Ren, Hongyu and Leskovec, Jure},
	month = may,
	year = {2022},
}

@inproceedings{rossi_temporal_2020,
	title = {Temporal {Graph} {Networks} for {Deep} {Learning} on {Dynamic} {Graphs}},
	url = {http://arxiv.org/abs/2006.10637},
	abstract = {Graph Neural Networks (GNNs) have recently become increasingly popular due to their ability to learn complex systems of relations or interactions. These arise in a broad spectrum of problems ranging from biology and particle physics to social networks and recommendation systems. Despite the plethora of different models for deep learning on graphs, few approaches have been proposed for dealing with graphs that are dynamic in nature (e.g. evolving features or connectivity over time). We present Temporal Graph Networks (TGNs), a generic, efﬁcient framework for deep learning on dynamic graphs represented as sequences of timed events. Thanks to a novel combination of memory modules and graph-based operators, TGNs signiﬁcantly outperform previous approaches while being more computationally efﬁcient. We furthermore show that several previous models for learning on dynamic graphs can be cast as speciﬁc instances of our framework. We perform a detailed ablation study of different components of our framework and devise the best conﬁguration that achieves state-of-the-art performance on several transductive and inductive prediction tasks for dynamic graphs.},
	language = {en},
	urldate = {2023-04-21},
	booktitle = {Proceedings of the 37 th {International} {Conference} on {Machine} {Learning}},
	author = {Rossi, Emanuele and Chamberlain, Ben and Frasca, Fabrizio and Eynard, Davide and Monti, Federico and Bronstein, Michael},
	month = oct,
	year = {2020},
	note = {arXiv:2006.10637 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{dauparas_robust_2022,
	title = {Robust deep learning–based protein sequence design using {ProteinMPNN}},
	volume = {378},
	url = {https://www.science.org/doi/full/10.1126/science.add2187},
	doi = {10.1126/science.add2187},
	abstract = {Although deep learning has revolutionized protein structure prediction, almost all experimentally characterized de novo protein designs have been generated using physically based approaches such as Rosetta. Here, we describe a deep learning–based protein sequence design method, ProteinMPNN, that has outstanding performance in both in silico and experimental tests. On native protein backbones, ProteinMPNN has a sequence recovery of 52.4\% compared with 32.9\% for Rosetta. The amino acid sequence at different positions can be coupled between single or multiple chains, enabling application to a wide range of current protein design challenges. We demonstrate the broad utility and high accuracy of ProteinMPNN using x-ray crystallography, cryo–electron microscopy, and functional studies by rescuing previously failed designs, which were made using Rosetta or AlphaFold, of protein monomers, cyclic homo-oligomers, tetrahedral nanoparticles, and target-binding proteins.},
	number = {6615},
	urldate = {2023-10-27},
	journal = {Science},
	author = {Dauparas, J. and Anishchenko, I. and Bennett, N. and Bai, H. and Ragotte, R. J. and Milles, L. F. and Wicky, B. I. M. and Courbet, A. and de Haas, R. J. and Bethel, N. and Leung, P. J. Y. and Huddy, T. F. and Pellock, S. and Tischer, D. and Chan, F. and Koepnick, B. and Nguyen, H. and Kang, A. and Sankaran, B. and Bera, A. K. and King, N. P. and Baker, D.},
	month = oct,
	year = {2022},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {49--56},
}

@article{longa_graph_2023,
	title = {Graph {Neural} {Networks} for {Temporal} {Graphs}: {State} of the {Art}, {Open} {Challenges}, and {Opportunities}},
	issn = {2835-8856},
	url = {https://openreview.net/forum?id=pHCdMat0gI},
	journal = {Transactions on Machine Learning Research},
	author = {Longa, Antonio and Lachi, Veronica and Santin, Gabriele and Bianchini, Monica and Lepri, Bruno and Lio, Pietro and scarselli, franco and Passerini, Andrea},
	year = {2023},
}

@misc{noauthor_transactions_nodate,
	title = {Transactions on {Machine} {Learning} {Research}},
	url = {https://jmlr.org/tmlr/papers/},
	urldate = {2023-10-26},
}

@article{bellman_dynamic_1966,
	title = {Dynamic {Programming}},
	volume = {153},
	url = {https://www.science.org/doi/abs/10.1126/science.153.3731.34},
	doi = {10.1126/science.153.3731.34},
	abstract = {Little has been done in the study of these intriguing questions, and I do not wish to give the impression that any extensive set of ideas exists that could be called a "theory." What is quite surprising, as far as the histories of science and philosophy are concerned, is that the major impetus for the fantastic growth of interest in brain processes, both psychological and physiological, has come from a device, a machine, the digital computer. In dealing with a human being and a human society, we enjoy the luxury of being irrational, illogical, inconsistent, and incomplete, and yet of coping. In operating a computer, we must meet the rigorous requirements for detailed instructions and absolute precision. If we understood the ability of the human mind to make effective decisions when confronted by complexity, uncertainty, and irrationality, then we could use computers a million times more effectively than we do. Recognition of this fact has been a motivation for the spurt of research in the field of neurophysiology.
The more we study the information-processing aspects of the mind, the more perplexed and impressed we become. It will be a very long time before we understand these processes sufficiently to reproduce them.
In any case, the mathematician sees hundreds and thousands of formidable new problems in dozens of blossoming areas, puzzles galore, and challenges to his heart's content. He may never resolve some of these, but he will never be bored. What more can he ask?},
	number = {3731},
	urldate = {2023-10-26},
	journal = {Science},
	author = {Bellman, Richard},
	month = jul,
	year = {1966},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {34--37},
}

@article{wachter_counterfactual_2018,
	title = {Counterfactual explanations without opening the black box: automated decisions and the {GDPR}},
	volume = {31},
	number = {2},
	journal = {Harvard Journal of Law and Technology},
	author = {Wachter, S and Mittelstadt, B and Russell, C},
	year = {2018},
	note = {Publisher: Harvard Law School},
	pages = {841--887},
}

@inproceedings{liu_differential_2023,
	title = {A {Differential} {Geometric} {View} and {Explainability} of {GNN} on {Evolving} {Graphs}},
	url = {https://www.semanticscholar.org/paper/A-Differential-Geometric-View-and-Explainability-of-Liu-Zhang/a7921d1a3687ec2077d13bcbee08ee44a32195fc},
	abstract = {Semantic Scholar extracted view of "A Differential Geometric View and Explainability of GNN on Evolving Graphs" by Yazheng Liu et al.},
	urldate = {2023-10-24},
	booktitle = {The {Eleventh} {International} {Conference} on {Learning} {Representations} ({ICLR}) 2023},
	author = {Liu, Yazheng and Zhang, Xi and Xie, Sihong},
	year = {2023},
}

@inproceedings{fan_gcn-se_2021,
	title = {{GCN}-{SE}: {Attention} as {Explainability} for {Node} {Classification} in {Dynamic} {Graphs}},
	shorttitle = {{GCN}-{SE}},
	url = {https://ieeexplore.ieee.org/document/9679020},
	doi = {10.1109/ICDM51629.2021.00123},
	abstract = {Graph Convolutional Networks (GCNs) are a popular method from graph representation learning that have proved effective for tasks like node classification. Recent variants on traditional GCN models aim to classify nodes in dynamic graphs whose topologies and node attributes change over time, e.g., social networks with dynamic relationships. These works, however, do not fully address the challenge of flexibly assigning different importance to snapshots of the graph at different times, which depending on the graph dynamics may have more or less predictive power on the labels. We address this challenge by proposing a new method, GCN-SE, that attaches a set of learnable attention weights to graph snapshots at different times, inspired by Squeeze and Excitation Net (SE-Net). We show that GCNSE outperforms previously proposed node classification methods on a variety of graph datasets. To verify the effectiveness of the attention weight in determining the importance of different graph snapshots, we adapt perturbation-based methods from the field of explainable machine learning to graphical settings and evaluate the correlation between the attention weights learned by GCN-SE and the importance of different snapshots over time.},
	urldate = {2023-10-24},
	booktitle = {2021 {IEEE} {International} {Conference} on {Data} {Mining} ({ICDM})},
	author = {Fan, Yucai and Yao, Yuhang and Joe-Wong, Carlee},
	month = dec,
	year = {2021},
	note = {ISSN: 2374-8486},
	pages = {1060--1065},
}

@inproceedings{duval_graphsvx_2021,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{GraphSVX}: {Shapley} {Value} {Explanations} for {Graph} {Neural} {Networks}},
	isbn = {978-3-030-86520-7},
	shorttitle = {{GraphSVX}},
	doi = {10.1007/978-3-030-86520-7_19},
	abstract = {Graph Neural Networks (GNNs) achieve significant performance for various learning tasks on geometric data due to the incorporation of graph structure into the learning of node representations, which renders their comprehension challenging. In this paper, we first propose a unified framework satisfied by most existing GNN explainers. Then, we introduce GraphSVX, a post hoc local model-agnostic explanation method specifically designed for GNNs. GraphSVX is a decomposition technique that captures the “fair” contribution of each feature and node towards the explained prediction by constructing a surrogate model on a perturbed dataset. It extends to graphs and ultimately provides as explanation the Shapley Values from game theory. Experiments on real-world and synthetic datasets demonstrate that GraphSVX achieves state-of-the-art performance compared to baseline models while presenting core theoretical and human-centric properties.},
	language = {en},
	booktitle = {Machine {Learning} and {Knowledge} {Discovery} in {Databases}. {Research} {Track}},
	publisher = {Springer International Publishing},
	author = {Duval, Alexandre and Malliaros, Fragkiskos D.},
	editor = {Oliver, Nuria and Pérez-Cruz, Fernando and Kramer, Stefan and Read, Jesse and Lozano, Jose A.},
	year = {2021},
	pages = {302--318},
}

@article{barredo_arrieta_explainable_2020,
	title = {Explainable {Artificial} {Intelligence} ({XAI}): {Concepts}, taxonomies, opportunities and challenges toward responsible {AI}},
	volume = {58},
	issn = {1566-2535},
	shorttitle = {Explainable {Artificial} {Intelligence} ({XAI})},
	url = {https://www.sciencedirect.com/science/article/pii/S1566253519308103},
	doi = {10.1016/j.inffus.2019.12.012},
	abstract = {In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.},
	urldate = {2023-10-22},
	journal = {Information Fusion},
	author = {Barredo Arrieta, Alejandro and Díaz-Rodríguez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garcia, Salvador and Gil-Lopez, Sergio and Molina, Daniel and Benjamins, Richard and Chatila, Raja and Herrera, Francisco},
	month = jun,
	year = {2020},
	keywords = {Accountability, Comprehensibility, Data Fusion, Deep Learning, Explainable Artificial Intelligence, Fairness, Interpretability, Machine Learning, Privacy, Responsible Artificial Intelligence, Transparency},
	pages = {82--115},
}

@misc{arrieta_explainable_2019,
	title = {Explainable {Artificial} {Intelligence} ({XAI}): {Concepts}, {Taxonomies}, {Opportunities} and {Challenges} toward {Responsible} {AI}},
	shorttitle = {Explainable {Artificial} {Intelligence} ({XAI})},
	url = {http://arxiv.org/abs/1910.10045},
	abstract = {In the last few years, Artiﬁcial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the ﬁeld. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) ﬁeld, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the ﬁeld of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to deﬁne explainability in Machine Learning, establishing a novel deﬁnition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this deﬁnition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artiﬁcial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the ﬁeld of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the beneﬁts of AI in their activity sectors, without any prior bias for its lack of interpretability.},
	language = {en},
	urldate = {2023-10-22},
	publisher = {arXiv},
	author = {Arrieta, Alejandro Barredo and Díaz-Rodríguez, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and García, Salvador and Gil-López, Sergio and Molina, Daniel and Benjamins, Richard and Chatila, Raja and Herrera, Francisco},
	month = dec,
	year = {2019},
	note = {arXiv:1910.10045 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{adadi_peeking_2018,
	title = {Peeking {Inside} the {Black}-{Box}: {A} {Survey} on {Explainable} {Artificial} {Intelligence} ({XAI})},
	volume = {6},
	issn = {2169-3536},
	shorttitle = {Peeking {Inside} the {Black}-{Box}},
	url = {https://ieeexplore.ieee.org/document/8466590/},
	doi = {10.1109/ACCESS.2018.2870052},
	abstract = {At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artiﬁcial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research ﬁeld holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the existing approaches regarding the topic, discuss trends surrounding its sphere, and present major research trajectories.},
	language = {en},
	urldate = {2023-10-22},
	journal = {IEEE Access},
	author = {Adadi, Amina and Berrada, Mohammed},
	year = {2018},
	pages = {52138--52160},
}

@article{prado-romero_survey_2023,
	title = {A {Survey} on {Graph} {Counterfactual} {Explanations}: {Definitions}, {Methods}, {Evaluation}},
	issn = {0360-0300},
	shorttitle = {A {Survey} on {Graph} {Counterfactual} {Explanations}},
	url = {http://arxiv.org/abs/2210.12089},
	doi = {10.1145/3618105},
	abstract = {In recent years, Graph Neural Networks have reported outstanding performance in tasks like community detection, molecule classiﬁcation and link prediction. However, the black-box nature of these models prevents their application in domains like health and ﬁnance, where understanding the models’ decisions is essential. Counterfactual Explanations (CE) provide these understandings through examples. Moreover, the literature on CE is ﬂourishing with novel explanation methods which are tailored to graph learning.},
	language = {en},
	urldate = {2023-03-28},
	journal = {ACM Comput. Surv.},
	author = {Prado-Romero, Mario Alfonso and Prenkaj, Bardh and Stilo, Giovanni and Giannotti, Fosca},
	month = sep,
	year = {2023},
	note = {arXiv:2210.12089 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Impact 3*, Relevance 5*},
}

@inproceedings{xu_inductive_2020,
	title = {Inductive {Representation} {Learning} on {Temporal} {Graphs}},
	url = {http://arxiv.org/abs/2002.07962},
	abstract = {Inductive representation learning on temporal graphs is an important step toward salable machine learning on real-world dynamic networks. The evolving nature of temporal dynamic graphs requires handling new nodes as well as capturing temporal patterns. The node embeddings, which are now functions of time, should represent both the static node features and the evolving topological structures. Moreover, node and topological features can be temporal as well, whose patterns the node embeddings should also capture. We propose the temporal graph attention (TGAT) layer to efﬁciently aggregate temporal-topological neighborhood features as well as to learn the time-feature interactions. For TGAT, we use the self-attention mechanism as building block and develop a novel functional time encoding technique based on the classical Bochner’s theorem from harmonic alaysis. By stacking TGAT layers, the network recognizes the node embeddings as functions of time and is able to inductively infer embeddings for both new and observed nodes as the graph evolves. The proposed approach handles both node classiﬁcation and link prediction task, and can be naturally extended to include the temporal edge features. We evaluate our method with transductive and inductive tasks under temporal settings with two benchmark and one industrial dataset. Our TGAT model compares favorably to state-of-the-art baselines as well as the previous temporal graph embedding approaches.},
	language = {en},
	urldate = {2023-05-26},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Xu, Da and Ruan, Chuanwei and Korpeoglu, Evren and Kumar, Sushant and Achan, Kannan},
	month = feb,
	year = {2020},
	note = {arXiv:2002.07962 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{kratsios_non-euclidean_2020,
	address = {Vancouver, BC, Canada},
	series = {{NIPS}'20},
	title = {Non-{Euclidean} {Universal} {Approximation}},
	isbn = {978-1-71382-954-6},
	abstract = {Modiﬁcations to a neural network’s input and output layers are often required to accommodate the speciﬁcities of most practical learning tasks. However, the impact of such changes on architecture’s approximation capabilities is largely not understood. We present general conditions describing feature and readout maps that preserve an architecture’s ability to approximate any continuous functions uniformly on compacts. As an application, we show that if an architecture is capable of universal approximation, then modifying its ﬁnal layer to produce binary values creates a new architecture capable of deterministically approximating any classiﬁer. In particular, we obtain guarantees for deep CNNs and deep feed-forward networks. Our results also have consequences within the scope of geometric deep learning. Speciﬁcally, when the input and output spaces are Cartan-Hadamard manifolds, we obtain geometrically meaningful feature and readout maps satisfying our criteria. Consequently, commonly used non-Euclidean regression models between spaces of symmetric positive deﬁnite matrices are extended to universal DNNs. The same result allows us to show that the hyperbolic feed-forward networks, used for hierarchical learning, are universal. Our result is also used to show that the common practice of randomizing all but the last two layers of a DNN produces a universal family of functions with probability one. We also provide conditions on a DNN’s ﬁrst (resp. last) few layer’s connections and activation function which guarantee that these layer’s can have a width equal to the input (resp. output) space’s dimension while not negatively effecting the architecture’s approximation capabilities.},
	language = {en},
	booktitle = {Proceedings of the 34th {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	author = {Kratsios, Anastasis and Bilokopytov, Eugene},
	year = {2020},
}

@article{kratsios_non-euclidean_2020-1,
	title = {Non-{Euclidean} {Universal} {Approximation}},
	url = {https://www.semanticscholar.org/paper/Non-Euclidean-Universal-Approximation-Kratsios-Bilokopytov/5efcae68320ab6287fdaf680ac29a1397951dc48},
	abstract = {Modifications to a neural network's input and output layers are often required to accommodate the specificities of most practical learning tasks. However, the impact of such changes on architecture's approximation capabilities is largely not understood. We present general conditions describing feature and readout maps that preserve an architecture's ability to approximate any continuous functions uniformly on compacts. As an application, we show that if an architecture is capable of universal approximation, then modifying its final layer to produce binary values creates a new architecture capable of deterministically approximating any classifier. In particular, we obtain guarantees for deep CNNs, deep ffNN, and universal Gaussian processes. Our results also have consequences within the scope of geometric deep learning. Specifically, when the input and output spaces are Hadamard manifolds, we obtain geometrically meaningful feature and readout maps satisfying our criteria. Consequently, commonly used non-Euclidean regression models between spaces of symmetric positive definite matrices are extended to universal DNNs. The same result allows us to show that the hyperbolic feed-forward networks, used for hierarchical learning, are universal. Our result is also used to show that the common practice of randomizing all but the last two layers of a DNN produces a universal family of functions with probability one.},
	urldate = {2023-10-11},
	journal = {ArXiv},
	author = {Kratsios, Anastasis and Bilokopytov, Ievgen},
	month = jun,
	year = {2020},
}

@article{hornik_multilayer_1989,
	title = {Multilayer feedforward networks are universal approximators},
	volume = {2},
	issn = {08936080},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0893608089900208},
	doi = {10.1016/0893-6080(89)90020-8},
	abstract = {This paper rigorously establishes thut standard rnultiluyer feedforward networks with as f\&v us one hidden layer using arbitrary squashing functions ure capable of upproximating uny Bore1 measurable function from one finite dimensional space to another to any desired degree of uccuracy, provided sujficirntly muny hidden units are available. In this sense, multilayer feedforward networks are u class of universul rlpproximators.},
	language = {en},
	number = {5},
	urldate = {2023-10-11},
	journal = {Neural Networks},
	author = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	month = jan,
	year = {1989},
	pages = {359--366},
}

@book{diestel_graph_2017,
	address = {Berlin, Heidelberg},
	series = {Graduate {Texts} in {Mathematics}},
	title = {Graph {Theory}},
	volume = {173},
	isbn = {978-3-662-53621-6 978-3-662-53622-3},
	url = {http://link.springer.com/10.1007/978-3-662-53622-3},
	language = {en},
	urldate = {2023-10-07},
	publisher = {Springer Berlin Heidelberg},
	author = {Diestel, Reinhard},
	year = {2017},
	doi = {10.1007/978-3-662-53622-3},
}

@article{yuan_explainability_2020,
	title = {Explainability in {Graph} {Neural} {Networks}: {A} {Taxonomic} {Survey}},
	shorttitle = {Explainability in {Graph} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2012.15445},
	abstract = {Deep learning methods are achieving ever-increasing performance on many artiﬁcial intelligence tasks. A major limitation of deep models is that they are not amenable to interpretability. This limitation can be circumvented by developing post hoc techniques to explain predictions, giving rise to the area of explainability. Recently, explainability of deep models on images and texts has achieved signiﬁcant progress. In the area of graph data, graph neural networks (GNNs) and their explainability are experiencing rapid developments. However, there is neither a uniﬁed treatment of GNN explainability methods, nor a standard benchmark and testbed for evaluations. In this survey, we provide a uniﬁed and taxonomic view of current GNN explainability methods. Our uniﬁed and taxonomic treatments of this subject shed lights on the commonalities and differences of existing methods and set the stage for further methodological developments. To facilitate evaluations, we provide a testbed for GNN explainability, including datasets, common algorithms and evaluation metrics. Furthermore, we conduct comprehensive experiments to compare and analyze the performance of many techniques. Altogether, this work provides a uniﬁed methodological treatment of GNN explainability and a standardized testbed for evaluations.},
	language = {en},
	urldate = {2023-03-28},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Yuan, Hao and Yu, Haiyang and Gui, Shurui and Ji, Shuiwang},
	year = {2020},
	note = {arXiv:2012.15445 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Impact 5*, Relevance 4*},
}

@article{zhou_graph_2020,
	title = {Graph neural networks: {A} review of methods and applications},
	volume = {1},
	issn = {26666510},
	shorttitle = {Graph neural networks},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2666651021000012},
	doi = {10.1016/j.aiopen.2021.01.001},
	abstract = {Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics systems, learning molecular ﬁngerprints, predicting protein interface, and classifying diseases demand a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures (like the dependency trees of sentences and the scene graphs of images) is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are neural models that capture the dependence of graphs via message passing between the nodes of graphs. In recent years, variants of GNNs such as graph convolutional network (GCN), graph attention network (GAT), graph recurrent network (GRN) have demonstrated ground-breaking performances on many deep learning tasks. In this survey, we propose a general design pipeline for GNN models and discuss the variants of each component, systematically categorize the applications, and propose four open problems for future research.},
	language = {en},
	urldate = {2023-07-16},
	journal = {AI Open},
	author = {Zhou, Jie and Cui, Ganqu and Hu, Shengding and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
	year = {2020},
	pages = {57--81},
}

@article{goyal_graph_2018,
	title = {Graph {Embedding} {Techniques}, {Applications}, and {Performance}: {A} {Survey}},
	volume = {151},
	issn = {09507051},
	shorttitle = {Graph {Embedding} {Techniques}, {Applications}, and {Performance}},
	url = {http://arxiv.org/abs/1705.02801},
	doi = {10.1016/j.knosys.2018.03.022},
	abstract = {Graphs, such as social networks, word co-occurrence networks, and communication networks, occur naturally in various real-world applications. Analyzing them yields insight into the structure of society, language, and diﬀerent patterns of communication. Many approaches have been proposed to perform the analysis. Recently, methods which use the representation of graph nodes in vector space have gained traction from the research community. In this survey, we provide a comprehensive and structured analysis of various graph embedding techniques proposed in the literature. We ﬁrst introduce the embedding task and its challenges such as scalability, choice of dimensionality, and features to be preserved, and their possible solutions. We then present three categories of approaches based on factorization methods, random walks, and deep learning, with examples of representative algorithms in each category and analysis of their performance on various tasks. We evaluate these state-of-the-art methods on a few common datasets and compare their performance against one another. Our analysis concludes by suggesting some potential applications and future directions. We ﬁnally present the open-source Python library we developed, named GEM (Graph Embedding Methods, available at https://github.com/palash1992/GEM), which provides all presented algorithms within a uniﬁed interface to foster and facilitate research on the topic.},
	language = {en},
	urldate = {2023-07-16},
	journal = {Knowledge-Based Systems},
	author = {Goyal, Palash and Ferrara, Emilio},
	month = jul,
	year = {2018},
	note = {arXiv:1705.02801 [physics]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks, Physics - Data Analysis, Statistics and Probability},
	pages = {78--94},
}

@article{cai_comprehensive_2018,
	title = {A {Comprehensive} {Survey} of {Graph} {Embedding}: {Problems}, {Techniques}, and {Applications}},
	volume = {30},
	issn = {1041-4347, 1558-2191, 2326-3865},
	shorttitle = {A {Comprehensive} {Survey} of {Graph} {Embedding}},
	url = {https://ieeexplore.ieee.org/document/8294302/},
	doi = {10.1109/TKDE.2018.2807452},
	abstract = {Graph is an important data representation which appears in a wide diversity of real-world scenarios. Effective graph analytics provides users a deeper understanding of what is behind the data, and thus can beneﬁt a lot of useful applications such as node classiﬁcation, node recommendation, link prediction, etc. However, most graph analytics methods suffer the high computation and space cost. Graph embedding is an effective yet efﬁcient way to solve the graph analytics problem. It converts the graph data into a low dimensional space in which the graph structural information and graph properties are maximumly preserved. In this survey, we conduct a comprehensive review of the literature in graph embedding. We ﬁrst introduce the formal deﬁnition of graph embedding as well as the related concepts. After that, we propose two taxonomies of graph embedding which correspond to what challenges exist in different graph embedding problem settings and how the existing work addresses these challenges in their solutions. Finally, we summarize the applications that graph embedding enables and suggest four promising future research directions in terms of computation efﬁciency, problem settings, techniques, and application scenarios.},
	language = {en},
	number = {9},
	urldate = {2023-07-16},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	author = {Cai, Hongyun and Zheng, Vincent W. and Chang, Kevin Chen-Chuan},
	month = sep,
	year = {2018},
	pages = {1616--1637},
}

@article{barros_survey_2023,
	title = {A {Survey} on {Embedding} {Dynamic} {Graphs}},
	volume = {55},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3483595},
	doi = {10.1145/3483595},
	abstract = {Embedding static graphs in low-dimensional vector spaces plays a key role in network analytics and inference, supporting applications like node classification, link prediction, and graph visualization. However, many real-world networks present dynamic behavior, including topological evolution, feature evolution, and diffusion. Therefore, several methods for embedding dynamic graphs have been proposed to learn network representations over time, facing novel challenges, such as time-domain modeling, temporal features to be captured, and the temporal granularity to be embedded. In this survey, we overview dynamic graph embedding, discussing its fundamentals and the recent advances developed so far. We introduce the formal definition of dynamic graph embedding, focusing on the problem setting and introducing a novel taxonomy for dynamic graph embedding input and output. We further explore different dynamic behaviors that may be encompassed by embeddings, classifying by topological evolution, feature evolution, and processes on networks. Afterward, we describe existing techniques and propose a taxonomy for dynamic graph embedding techniques based on algorithmic approaches, from matrix and tensor factorization to deep learning, random walks, and temporal point processes. We also elucidate main applications, including dynamic link prediction, anomaly detection, and diffusion prediction, and we further state some promising research directions in the area.},
	language = {en},
	number = {1},
	urldate = {2023-07-16},
	journal = {ACM Computing Surveys},
	author = {Barros, Claudio D. T. and Mendonça, Matheus R. F. and Vieira, Alex B. and Ziviani, Artur},
	month = jan,
	year = {2023},
	pages = {1--37},
}

@article{liben-nowell_link-prediction_2007,
	title = {The {Link}-{Prediction} {Problem} for {Social} {Networks}},
	volume = {58},
	abstract = {Given a snapshot of a social network, can we infer which new interactions among its members are likely to occur in the near future? We formalize this question as the link-prediction problem, and we develop approaches to link prediction based on measures for analyzing the “proximity” of nodes in a network. Experiments on large co-authorship networks suggest that information about future interactions can be extracted from network topology alone, and that fairly subtle measures for detecting node proximity can outperform more direct measures.},
	language = {en},
	number = {7},
	journal = {Journal of the American society for information science and technology},
	author = {Liben-Nowell, David and Kleinberg, Jon},
	year = {2007},
	pages = {1019--1031},
}

@inproceedings{kipf_semi-supervised_2017,
	title = {Semi-{Supervised} {Classification} with {Graph} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1609.02907},
	abstract = {We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efﬁcient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized ﬁrst-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a signiﬁcant margin.},
	language = {en},
	urldate = {2023-07-16},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Kipf, Thomas N. and Welling, Max},
	month = feb,
	year = {2017},
	note = {arXiv:1609.02907 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{ying_hierarchical_2018,
	title = {Hierarchical {Graph} {Representation} {Learning} with {Differentiable} {Pooling}},
	abstract = {Recently, graph neural networks (GNNs) have revolutionized the ﬁeld of graph representation learning through effectively learned node embeddings, and achieved state-of-the-art results in tasks such as node classiﬁcation and link prediction. However, current GNN methods are inherently ﬂat and do not learn hierarchical representations of graphs—a limitation that is especially problematic for the task of graph classiﬁcation, where the goal is to predict the label associated with an entire graph. Here we propose DIFFPOOL, a differentiable graph pooling module that can generate hierarchical representations of graphs and can be combined with various graph neural network architectures in an end-to-end fashion. DIFFPOOL learns a differentiable soft cluster assignment for nodes at each layer of a deep GNN, mapping nodes to a set of clusters, which then form the coarsened input for the next GNN layer. Our experimental results show that combining existing GNN methods with DIFFPOOL yields an average improvement of 5–10\% accuracy on graph classiﬁcation benchmarks, compared to all existing pooling approaches, achieving a new state-of-the-art on four out of ﬁve benchmark data sets.},
	language = {en},
	booktitle = {Neural {Information} {Processing}},
	author = {Ying, Zhitao and You, Jiaxuan and Morris, Christopher and Ren, Xiang and Hamilton, Will and Leskovec, Jure},
	year = {2018},
}

@article{hamilton_representation_2017,
	title = {Representation {Learning} on {Graphs}: {Methods} and {Applications}},
	volume = {40},
	shorttitle = {Representation {Learning} on {Graphs}},
	url = {http://arxiv.org/abs/1709.05584},
	abstract = {Machine learning on graphs is an important and ubiquitous task with applications ranging from drug design to friendship recommendation in social networks. The primary challenge in this domain is ﬁnding a way to represent, or encode, graph structure so that it can be easily exploited by machine learning models. Traditionally, machine learning approaches relied on user-deﬁned heuristics to extract features encoding structural information about a graph (e.g., degree statistics or kernel functions). However, recent years have seen a surge in approaches that automatically learn to encode graph structure into low-dimensional embeddings, using techniques based on deep learning and nonlinear dimensionality reduction. Here we provide a conceptual review of key advancements in this area of representation learning on graphs, including matrix factorization-based methods, random-walk based algorithms, and graph convolutional networks. We review methods to embed individual nodes as well as approaches to embed entire (sub)graphs. In doing so, we develop a uniﬁed framework to describe these recent approaches, and we highlight a number of important applications and directions for future work.},
	language = {en},
	urldate = {2023-07-16},
	journal = {IEEE Data Engineering Bulletin},
	author = {Hamilton, William L. and Ying, Rex and Leskovec, Jure},
	year = {2017},
	note = {arXiv:1709.05584 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks},
	pages = {52 -- 74},
}

@misc{bronstein_geometric_2021,
	title = {Geometric {Deep} {Learning}: {Grids}, {Groups}, {Graphs}, {Geodesics}, and {Gauges}},
	shorttitle = {Geometric {Deep} {Learning}},
	url = {http://arxiv.org/abs/2104.13478},
	abstract = {The last decade has witnessed an experimental revolution in data science and machine learning, epitomised by deep learning methods. Indeed, many high-dimensional learning tasks previously thought to be beyond reach -- such as computer vision, playing Go, or protein folding -- are in fact feasible with appropriate computational scale. Remarkably, the essence of deep learning is built from two simple algorithmic principles: first, the notion of representation or feature learning, whereby adapted, often hierarchical, features capture the appropriate notion of regularity for each task, and second, learning by local gradient-descent type methods, typically implemented as backpropagation. While learning generic functions in high dimensions is a cursed estimation problem, most tasks of interest are not generic, and come with essential pre-defined regularities arising from the underlying low-dimensionality and structure of the physical world. This text is concerned with exposing these regularities through unified geometric principles that can be applied throughout a wide spectrum of applications. Such a 'geometric unification' endeavour, in the spirit of Felix Klein's Erlangen Program, serves a dual purpose: on one hand, it provides a common mathematical framework to study the most successful neural network architectures, such as CNNs, RNNs, GNNs, and Transformers. On the other hand, it gives a constructive procedure to incorporate prior physical knowledge into neural architectures and provide principled way to build future architectures yet to be invented.},
	language = {en},
	urldate = {2023-07-04},
	publisher = {arXiv},
	author = {Bronstein, Michael M. and Bruna, Joan and Cohen, Taco and Veličković, Petar},
	month = may,
	year = {2021},
	note = {arXiv:2104.13478 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computational Geometry, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{liang_survey_2022,
	title = {Survey of {Graph} {Neural} {Networks} and {Applications}},
	volume = {2022},
	issn = {1530-8677, 1530-8669},
	url = {https://www.hindawi.com/journals/wcmc/2022/9261537/},
	doi = {10.1155/2022/9261537},
	abstract = {The advance of deep learning has shown great potential in applications (speech, image, and video classification). In these applications, deep learning models are trained by datasets in Euclidean space with fixed dimensions and sequences. Nonetheless, the rapidly increasing demands on analyzing datasets in non-Euclidean space require additional research. Generally speaking, finding the relationships of elements in datasets and representing such relationships as weighted graphs consisting of vertices and edges is a viable way of analyzing datasets in non-Euclidean space. However, analyzing the weighted graph-based dataset is a challenging problem in existing deep learning models. To address this issue, graph neural networks (GNNs) leverage spectral and spatial strategies to extend and implement convolution operations in non-Euclidean space. Based on graph theory, a number of enhanced GNNs are proposed to deal with non-Euclidean datasets. In this study, we first review the artificial neural networks and GNNs. We then present ways to extend deep learning models to deal with datasets in non-Euclidean space and introduce the GNN-based approaches based on spectral and spatial strategies. Furthermore, we discuss some typical Internet of Things (IoT) applications that employ spectral and spatial convolution strategies, followed by the limitations of GNNs in the current stage.},
	language = {en},
	urldate = {2023-07-03},
	journal = {Wireless Communications and Mobile Computing},
	author = {Liang, Fan and Qian, Cheng and Yu, Wei and Griffith, David and Golmie, Nada},
	editor = {Li, Wei},
	month = jul,
	year = {2022},
	pages = {1--18},
}

@article{bronstein_geometric_2017,
	title = {Geometric deep learning: going beyond {Euclidean} data},
	volume = {34},
	issn = {1053-5888, 1558-0792},
	shorttitle = {Geometric deep learning},
	url = {http://arxiv.org/abs/1611.08097},
	doi = {10.1109/MSP.2017.2693418},
	abstract = {Many scientific fields study data with an underlying structure that is a non-Euclidean space. Some examples include social networks in computational social sciences, sensor networks in communications, functional networks in brain imaging, regulatory networks in genetics, and meshed surfaces in computer graphics. In many applications, such geometric data are large and complex (in the case of social networks, on the scale of billions), and are natural targets for machine learning techniques. In particular, we would like to use deep neural networks, which have recently proven to be powerful tools for a broad range of problems from computer vision, natural language processing, and audio analysis. However, these tools have been most successful on data with an underlying Euclidean or grid-like structure, and in cases where the invariances of these structures are built into networks used to model them. Geometric deep learning is an umbrella term for emerging techniques attempting to generalize (structured) deep neural models to non-Euclidean domains such as graphs and manifolds. The purpose of this paper is to overview different examples of geometric deep learning problems and present available solutions, key difficulties, applications, and future research directions in this nascent field.},
	language = {en},
	number = {4},
	urldate = {2023-07-03},
	journal = {IEEE Signal Processing Magazine},
	author = {Bronstein, Michael M. and Bruna, Joan and LeCun, Yann and Szlam, Arthur and Vandergheynst, Pierre},
	month = jul,
	year = {2017},
	note = {arXiv:1611.08097 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {18--42},
}

@inproceedings{lucic_cf-gnnexplainer_2022,
	title = {{CF}-{GNNExplainer}: {Counterfactual} {Explanations} for {Graph} {Neural} {Networks}},
	shorttitle = {{CF}-{GNNExplainer}},
	url = {http://arxiv.org/abs/2102.03322},
	abstract = {Given the increasing promise of graph neural networks (GNNs) in real-world applications, several methods have been developed for explaining their predictions. Existing methods for interpreting predictions from GNNs have primarily focused on generating subgraphs that are especially relevant for a particular prediction. However, such methods are not counterfactual (CF) in nature: given a prediction, we want to understand how the prediction can be changed in order to achieve an alternative outcome. In this work, we propose a method for generating CF explanations for GNNs: the minimal perturbation to the input (graph) data such that the prediction changes. Using only edge deletions, we ﬁnd that our method, CF-GNNExplainer, can generate CF explanations for the majority of instances across three widely used datasets for GNN explanations, while removing less than 3 edges on average, with at least 94\% accuracy. This indicates that CF-GNNExplainer primarily removes edges that are crucial for the original predictions, resulting in minimal CF explanations.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {International {Conference} on {Artificial} {Intelligence} and {Statistics}},
	publisher = {arXiv},
	author = {Lucic, Ana and ter Hoeve, Maartje and Tolomei, Gabriele and de Rijke, Maarten and Silvestri, Fabrizio},
	month = feb,
	year = {2022},
	note = {arXiv:2102.03322 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Dataset: BA-Shapes, Dataset: Tree-Cycles, Dataset: Tree-Grid, Impact 4*, Metric: Accuracy, Metric: Explanation Size, Metric: Fidelity, Metric: Sparsity, Relevance 5*, Task: Node Classification},
}

@inproceedings{li_temporal_2021,
	title = {Temporal {Knowledge} {Graph} {Reasoning} {Based} on {Evolutional} {Representation} {Learning}},
	url = {http://arxiv.org/abs/2104.10353},
	abstract = {Knowledge Graph (KG) reasoning that predicts missing facts for incomplete KGs has been widely explored. However, reasoning over Temporal KG (TKG) that predicts facts in the future is still far from resolved. The key to predict future facts is to thoroughly understand the historical facts. A TKG is actually a sequence of KGs corresponding to different timestamps, where all concurrent facts in each KG exhibit structural dependencies and temporally adjacent facts carry informative sequential patterns. To capture these properties effectively and efficiently, we propose a novel Recurrent Evolution network based on Graph Convolution Network (GCN), called RE-GCN, which learns the evolutional representations of entities and relations at each timestamp by modeling the KG sequence recurrently. Specifically, for the evolution unit, a relation-aware GCN is leveraged to capture the structural dependencies within the KG at each timestamp. In order to capture the sequential patterns of all facts in parallel, the historical KG sequence is modeled auto-regressively by the gate recurrent components. Moreover, the static properties of entities such as entity types, are also incorporated via a static graph constraint component to obtain better entity representations. Fact prediction at future timestamps can then be realized based on the evolutional entity and relation representations. Extensive experiments demonstrate that the RE-GCN model obtains substantial performance and efficiency improvement for the temporal reasoning tasks on six benchmark datasets. Especially, it achieves up to 11.46\% improvement in MRR for entity prediction with up to 82 times speedup comparing to the state-of-the-art baseline.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {Proceedings of the 44th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {arXiv},
	author = {Li, Zixuan and Jin, Xiaolong and Li, Wei and Guan, Saiping and Guo, Jiafeng and Shen, Huawei and Wang, Yuanzhuo and Cheng, Xueqi},
	month = apr,
	year = {2021},
	note = {arXiv:2104.10353 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Dataset: GDELT, Dataset: ICEWS, Dataset: WIKI, Dataset: YAGO, Impact 4*, Relevance 4*, Task: Extrapolation},
}

@article{ji_perturb_2020,
	title = {Perturb {More}, {Trap} {More}: {Understanding} {Behaviors} of {Graph} {Neural} {Networks}},
	volume = {493},
	shorttitle = {Perturb {More}, {Trap} {More}},
	url = {http://arxiv.org/abs/2004.09808},
	abstract = {While graph neural networks (GNNs) have shown a great potential in various tasks on graph, the lack of transparency has hindered understanding how GNNs arrived at its predictions. Although few explainers for GNNs are explored, the consideration of local ﬁdelity, indicating how the model behaves around an instance should be predicted, is neglected. In this paper, we ﬁrst propose a novel post-hoc framework based on local ﬁdelity for any trained GNNs - TraP2, which can generate a high-ﬁdelity explanation. Considering that both relevant graph structure and important features inside each node need to be highlighted, a three-layer architecture in TraP2 is designed: i) interpretation domain are deﬁned by Translation layer in advance; ii) local predictive behavior of GNNs being explained are probed and monitored by Perturbation layer, in which multiple perturbations for graph structure and feature-level are conducted in interpretation domain; iii) high faithful explanations are generated by ﬁtting the local decision boundary through Paraphrase layer. Finally, TraP2 is evaluated on six benchmark datasets based on ﬁve desired attributions: accuracy, ﬁdelity, decisiveness, insight and inspiration, which achieves 10.2\% higher explanation accuracy than the state-of-the-art methods.},
	language = {en},
	urldate = {2023-03-28},
	journal = {Neurocomputing},
	author = {Ji, Chaojie and Wang, Ruxin and Wu, Hongyan},
	month = apr,
	year = {2020},
	note = {arXiv:2004.09808 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Impact 1*, Relevance 3*, Statistics - Machine Learning},
	pages = {59--75},
}

@inproceedings{himmelhuber_demystifying_2021,
	title = {Demystifying {Graph} {Neural} {Network} {Explanations}},
	url = {http://arxiv.org/abs/2111.12984},
	abstract = {Graph neural networks (GNNs) are quickly becoming the standard approach for learning on graph structured data across several domains, but they lack transparency in their decision-making. Several perturbation-based approaches have been developed to provide insights into the decision making process of GNNs. As this is an early research area, the methods and data used to evaluate the generated explanations lack maturity. We explore these existing approaches and identify common pitfalls in three main areas: (1) synthetic data generation process, (2) evaluation metrics, and (3) the ﬁnal presentation of the explanation. For this purpose, we perform an empirical study to explore these pitfalls along with their unintended consequences and propose remedies to mitigate their eﬀects.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {Joint {European} {Conference} on {Machine} {Learning} and {Knowledge} {Discovery} in {Databases}},
	publisher = {arXiv},
	author = {Himmelhuber, Anna and Joblin, Mitchell and Ringsquandl, Martin and Runkler, Thomas},
	month = nov,
	year = {2021},
	note = {arXiv:2111.12984 [cs]},
	keywords = {Computer Science - Machine Learning, Impact 1*, Relevance 2*},
}

@inproceedings{zhu_learning_2021,
	title = {Learning from {History}: {Modeling} {Temporal} {Knowledge} {Graphs} with {Sequential} {Copy}-{Generation} {Networks}},
	shorttitle = {Learning from {History}},
	url = {http://arxiv.org/abs/2012.08492},
	abstract = {Large knowledge graphs often grow to store temporal facts that model the dynamic relations or interactions of entities along the timeline. Since such temporal knowledge graphs often suffer from incompleteness, it is important to develop time-aware representation learning models that help to infer the missing temporal facts. While the temporal facts are typically evolving, it is observed that many facts often show a repeated pattern along the timeline, such as economic crises and diplomatic activities. This observation indicates that a model could potentially learn much from the known facts appeared in history. To this end, we propose a new representation learning model for temporal knowledge graphs, namely CyGNet , based on a novel timeaware copy-generation mechanism. CyGNet is not only able to predict future facts from the whole entity vocabulary, but also capable of identifying facts with repetition and accordingly predicting such future facts with reference to the known facts in the past. We evaluate the proposed method on the knowledge graph completion task using ﬁve benchmark datasets. Extensive experiments demonstrate the effectiveness of CyGNet for predicting future facts with repetition as well as de novo fact prediction.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {Proceedings of the {AAAI} {Conference} on {Artificial} {Intelligence}},
	publisher = {arXiv},
	author = {Zhu, Cunchao and Chen, Muhao and Fan, Changjun and Cheng, Guangquan and Zhan, Yan},
	month = mar,
	year = {2021},
	note = {arXiv:2012.08492 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, Impact 4*, Relevance 2*},
}

@inproceedings{yuan_explainability_2021,
	title = {On {Explainability} of {Graph} {Neural} {Networks} via {Subgraph} {Explorations}},
	url = {http://arxiv.org/abs/2102.05152},
	abstract = {We consider the problem of explaining the predictions of graph neural networks (GNNs), which otherwise are considered as black boxes. Existing methods invariably focus on explaining the importance of graph nodes or edges but ignore the substructures of graphs, which are more intuitive and human-intelligible. In this work, we propose a novel method, known as SubgraphX, to explain GNNs by identifying important subgraphs. Given a trained GNN model and an input graph, our SubgraphX explains its predictions by efﬁciently exploring different subgraphs with Monte Carlo tree search. To make the tree search more effective, we propose to use Shapley values as a measure of subgraph importance, which can also capture the interactions among different subgraphs. To expedite computations, we propose efﬁcient approximation schemes to compute Shapley values for graph data. Our work represents the ﬁrst attempt to explain GNNs via identifying subgraphs explicitly and directly. Experimental results show that our SubgraphX achieves signiﬁcantly improved explanations, while keeping computations at a reasonable level.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {arXiv},
	author = {Yuan, Hao and Yu, Haiyang and Wang, Jie and Li, Kang and Ji, Shuiwang},
	month = may,
	year = {2021},
	note = {arXiv:2102.05152 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Impact 5*, Model: SubgraphX, Relevance 3*},
}

@inproceedings{you_roland_2022,
	title = {{ROLAND}: {Graph} {Learning} {Framework} for {Dynamic} {Graphs}},
	shorttitle = {{ROLAND}},
	url = {http://arxiv.org/abs/2208.07239},
	abstract = {Graph Neural Networks (GNNs) have been successfully applied to many real-world static graphs. However, the success of static graphs has not fully translated to dynamic graphs due to the limitations in model design, evaluation settings, and training strategies. Concretely, existing dynamic GNNs do not incorporate state-of-the-art designs from static GNNs, which limits their performance. Current evaluation settings for dynamic GNNs do not fully reflect the evolving nature of dynamic graphs. Finally, commonly used training methods for dynamic GNNs are not scalable. Here we propose ROLAND, an effective graph representation learning framework for real-world dynamic graphs. At its core, the ROLAND framework can help researchers easily repurpose any static GNN to dynamic graphs. Our insight is to view the node embeddings at different GNN layers as hierarchical node states and then recurrently update them over time. We then introduce a live-update evaluation setting for dynamic graphs that mimics real-world use cases, where GNNs are making predictions and being updated on a rolling basis. Finally, we propose a scalable and efficient training approach for dynamic GNNs via incremental training and meta-learning. We conduct experiments over eight different dynamic graph datasets on future link prediction tasks. Models built using the ROLAND framework achieve on average 62.7\% relative mean reciprocal rank (MRR) improvement over state-of-the-art baselines under the standard evaluation settings on three datasets. We find state-of-the-art baselines experience out-of-memory errors for larger datasets, while ROLAND can easily scale to dynamic graphs with 56 million edges. After re-implementing these baselines using the ROLAND training strategy, ROLAND models still achieve on average 15.5\% relative MRR improvement over the baselines.},
	language = {en},
	urldate = {2023-04-09},
	booktitle = {Proceedings of the 28th {ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} and {Data} {Mining}},
	publisher = {arXiv},
	author = {You, Jiaxuan and Du, Tianyu and Leskovec, Jure},
	month = aug,
	year = {2022},
	note = {arXiv:2208.07239 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Social and Information Networks, Dataset: AS-733, Dataset: BSI-ZK, Dataset: BSI:SVT, Dataset: Bitcoin-OTC, Dataset: Reddit},
}

@inproceedings{ying_gnnexplainer_2019,
	title = {{GNNExplainer}: {Generating} {Explanations} for {Graph} {Neural} {Networks}},
	shorttitle = {{GNNExplainer}},
	url = {http://arxiv.org/abs/1903.03894},
	abstract = {Graph Neural Networks (GNNs) are a powerful tool for machine learning on graphs. GNNs combine node feature information with the graph structure by recursively passing neural messages along edges of the input graph. However, incorporating both graph structure and feature information leads to complex models and explaining predictions made by GNNs remains unsolved. Here we propose GNNEXPLAINER, the ﬁrst general, model-agnostic approach for providing interpretable explanations for predictions of any GNN-based model on any graph-based machine learning task. Given an instance, GNNEXPLAINER identiﬁes a compact subgraph structure and a small subset of node features that have a crucial role in GNN’s prediction. Further, GNNEXPLAINER can generate consistent and concise explanations for an entire class of instances. We formulate GNNEXPLAINER as an optimization task that maximizes the mutual information between a GNN’s prediction and distribution of possible subgraph structures. Experiments on synthetic and real-world graphs show that our approach can identify important graph structures as well as node features, and outperforms alternative baseline approaches by up to 43.0\% in explanation accuracy. GNNEXPLAINER provides a variety of beneﬁts, from the ability to visualize semantically relevant structures to interpretability, to giving insights into errors of faulty GNNs.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {Advances in neural information processing systems},
	publisher = {arXiv},
	author = {Ying, Rex and Bourgeois, Dylan and You, Jiaxuan and Zitnik, Marinka and Leskovec, Jure},
	month = nov,
	year = {2019},
	note = {arXiv:1903.03894 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Impact 5*, Relevance 3*, Statistics - Machine Learning},
}

@inproceedings{trivedi_know-evolve_2017,
	title = {Know-{Evolve}: {Deep} {Temporal} {Reasoning} for {Dynamic} {Knowledge} {Graphs}},
	shorttitle = {Know-{Evolve}},
	url = {http://arxiv.org/abs/1705.05742},
	abstract = {The availability of large scale event data with time stamps has given rise to dynamically evolving knowledge graphs that contain temporal information for each edge. Reasoning over time in such dynamic knowledge graphs is not yet well understood. To this end, we present Know-Evolve, a novel deep evolutionary knowledge network that learns non-linearly evolving entity representations over time. The occurrence of a fact (edge) is modeled as a multivariate point process whose intensity function is modulated by the score for that fact computed based on the learned entity embeddings. We demonstrate signiﬁcantly improved performance over various relational learning approaches on two large scale real-world datasets. Further, our method effectively predicts occurrence or recurrence time of a fact which is novel compared to prior reasoning approaches in multirelational setting.},
	language = {en},
	urldate = {2023-05-04},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {arXiv},
	author = {Trivedi, Rakshit and Dai, Hanjun and Wang, Yichen and Song, Le},
	month = jun,
	year = {2017},
	note = {arXiv:1705.05742 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@inproceedings{souza_provably_2022,
	title = {Provably expressive temporal graph networks},
	url = {http://arxiv.org/abs/2209.15059},
	abstract = {Temporal graph networks (TGNs) have gained prominence as models for embedding dynamic interactions, but little is known about their theoretical underpinnings. We establish fundamental results about the representational power and limits of the two main categories of TGNs: those that aggregate temporal walks (WA-TGNs), and those that augment local message passing with recurrent memory modules (MP-TGNs). Speciﬁcally, novel constructions reveal the inadequacy of MP-TGNs and WA-TGNs, proving that neither category subsumes the other. We extend the 1-WL (Weisfeiler-Leman) test to temporal graphs, and show that the most powerful MP-TGNs should use injective updates, as in this case they become as expressive as the temporal WL. Also, we show that sufﬁciently deep MP-TGNs cannot beneﬁt from memory, and MP/WA-TGNs fail to compute graph properties such as girth.},
	language = {en},
	urldate = {2023-05-03},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {arXiv},
	author = {Souza, Amauri H. and Mesquita, Diego and Kaski, Samuel and Garg, Vikas},
	month = sep,
	year = {2022},
	note = {arXiv:2209.15059 [cs]},
	keywords = {Computer Science - Machine Learning, Venue: A},
}

@inproceedings{seo_structured_2016,
	title = {Structured {Sequence} {Modeling} with {Graph} {Convolutional} {Recurrent} {Networks}},
	url = {http://arxiv.org/abs/1612.07659},
	abstract = {This paper introduces Graph Convolutional Recurrent Network (GCRN), a deep learning model able to predict structured sequences of data. Precisely, GCRN is a generalization of classical recurrent neural networks (RNN) to data structured by an arbitrary graph. Such structured sequences can represent series of frames in videos, spatio-temporal measurements on a network of sensors, or random walks on a vocabulary graph for natural language modeling. The proposed model combines convolutional neural networks (CNN) on graphs to identify spatial structures and RNN to ﬁnd dynamic patterns. We study two possible architectures of GCRN, and apply the models to two practical problems: predicting moving MNIST data, and modeling natural language with the Penn Treebank dataset. Experiments show that exploiting simultaneously graph spatial and dynamic information about data can improve both precision and learning speed.},
	language = {en},
	urldate = {2023-05-03},
	booktitle = {Neural {Information} {Processing}: 25th {International} {Conference}},
	publisher = {arXiv},
	author = {Seo, Youngjoo and Defferrard, Michaël and Vandergheynst, Pierre and Bresson, Xavier},
	month = dec,
	year = {2016},
	note = {arXiv:1612.07659 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{numeroso_meg_2021,
	title = {{MEG}: {Generating} {Molecular} {Counterfactual} {Explanations} for {Deep} {Graph} {Networks}},
	shorttitle = {{MEG}},
	url = {http://arxiv.org/abs/2104.08060},
	abstract = {Explainable AI (XAI) is a research area whose objective is to increase trustworthiness and to enlighten the hidden mechanism of opaque machine learning techniques. This becomes increasingly important in case such models are applied to the chemistry domain, for its potential impact on humans’ health, e.g, toxicity analysis in pharmacology. In this paper, we present a novel approach to tackle explainability of deep graph networks in the context of molecule property prediction t asks, named MEG (Molecular Explanation Generator). We generate informative counterfactual explanations for a speciﬁc prediction under the form of (valid) compounds with high structural similarity and different predicted properties. Given a trained DGN, we train a reinforcement learning based generator to output counterfactual explanations. At each step, MEG feeds the current candidate counterfactual into the DGN, collects the prediction and uses it to reward the RL agent to guide the exploration. Furthermore, we restrict the action space of the agent in order to only keep actions that maintain the molecule in a valid state. We discuss the results showing how the model can convey non-ML experts with key insights into the learning model focus in the neighbourhood of a molecule.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {2021 {International} {Joint} {Conference} on {Neural} {Networks}},
	publisher = {arXiv},
	author = {Numeroso, Danilo and Bacciu, Davide},
	month = apr,
	year = {2021},
	note = {arXiv:2104.08060 [cs]},
	keywords = {Computer Science - Machine Learning, Impact 3*, Relevance 4*},
}

@inproceedings{ning_staple_2018,
	address = {Philadelphia, PA},
	title = {{STAPLE}: {Spatio}-{Temporal} {Precursor} {Learning} for {Event} {Forecasting}},
	isbn = {978-1-61197-532-1},
	url = {https://epubs.siam.org/doi/book/10.1137/1.9781611975321},
	doi = {10.1137/1.9781611975321},
	abstract = {Large-scale societal events such as civil unrest movements occur due to a variety of factors including economics, politics, and security. Societal event detection can be modeled as a system of inter-connected locations, where each location is recording a set of time-dependent observations. In order to detect event occurrence and automatically reconstruct the precursors and signals, it is essential to model relationships between the diﬀerent locations w.r.t. how events evolve over time. However, existing methods for precursor discovery do not capture or exploit spatial and temporal correlations inherent in event occurrences. The absence of such modeling not only creates shortcomings in the quality of inference but also curtails interpretation by human analysts. Furthermore, forecasting is inhibited when training data is sparse. In this paper, we develop a novel multi-task model with dynamic graph constraints within a multiinstance learning framework. Our model tackles the problem of scarce data distribution and reinforces cooccurring location-speciﬁc precursors with augmented representations. Through studies on civil unrest movements in numerous countries, we demonstrate the eﬀectiveness of the proposed method for precursor discovery and event forecasting.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {Proceedings of the 2018 {SIAM} {International} {Conference} on {Data} {Mining}},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Ning, Yue and Tao, Rongrong and Reddy, C. and Rangwala, H. and Starz, James and Ramakrishnan, Naren},
	month = may,
	year = {2018},
	keywords = {Impact 3*, Relevance 2*},
}

@inproceedings{ma_streaming_2018,
	title = {Streaming {Graph} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1810.10627},
	abstract = {Graphs are essential representations of many real-world data such as social networks. Recent years have witnessed the increasing efforts made to extend the neural network models to graph-structured data. These methods, which are usually known as the graph neural networks, have been applied to advance many graphs related tasks such as reasoning dynamics of the physical system, graph classification, and node classification. Most of the existing graph neural network models have been designed for static graphs, while many real-world graphs are inherently dynamic. For example, social networks are naturally evolving as new users joining and new relations being created. Current graph neural network models cannot utilize the dynamic information in dynamic graphs. However, the dynamic information has been proven to enhance the performance of many graph analytic tasks such as community detection and link prediction. Hence, it is necessary to design dedicated graph neural networks for dynamic graphs. In this paper, we propose DGNN, a new \{{\textbackslash}bf D\}ynamic \{{\textbackslash}bf G\}raph \{{\textbackslash}bf N\}eural \{{\textbackslash}bf N\}etwork model, which can model the dynamic information as the graph evolving. In particular, the proposed framework can keep updating node information by capturing the sequential information of edges (interactions), the time intervals between edges and information propagation coherently. Experimental results on various dynamic graphs demonstrate the effectiveness of the proposed framework.},
	language = {en},
	urldate = {2023-05-10},
	booktitle = {Proceedings of the 43rd {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {arXiv},
	author = {Ma, Yao and Guo, Ziyi and Ren, Zhaochun and Zhao, Eric and Tang, Jiliang and Yin, Dawei},
	month = nov,
	year = {2018},
	note = {arXiv:1810.10627 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{luo_parameterized_2020,
	title = {Parameterized {Explainer} for {Graph} {Neural} {Network}},
	url = {http://arxiv.org/abs/2011.04573},
	abstract = {Despite recent progress in Graph Neural Networks (GNNs), explaining predictions made by GNNs remains a challenging open problem. The leading method independently addresses the local explanations (i.e., important subgraph structure and node features) to interpret why a GNN model makes the prediction for a single instance, e.g. a node or a graph. As a result, the explanation generated is painstakingly customized for each instance. The unique explanation interpreting each instance independently is not sufﬁcient to provide a global understanding of the learned GNN model, leading to the lack of generalizability and hindering it from being used in the inductive setting. Besides, as it is designed for explaining a single instance, it is challenging to explain a set of instances naturally (e.g., graphs of a given class). In this study, we address these key challenges and propose PGExplainer, a parameterized explainer for GNNs. PGExplainer adopts a deep neural network to parameterize the generation process of explanations, which enables PGExplainer a natural approach to explaining multiple instances collectively. Compared to the existing work, PGExplainer has better generalization ability and can be utilized in an inductive setting easily. Experiments on both synthetic and real-life datasets show highly competitive performance with up to 24.7\% relative improvement in AUC on explaining graph classiﬁcation over the leading baseline.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {Proceedings of the 34th {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {arXiv},
	author = {Luo, Dongsheng and Cheng, Wei and Xu, Dongkuan and Yu, Wenchao and Zong, Bo and Chen, Haifeng and Zhang, Xiang},
	month = nov,
	year = {2020},
	note = {arXiv:2011.04573 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Impact 5*, Model: PGExplainer, Relevance 3*},
}

@inproceedings{lin_generative_2021,
	title = {Generative {Causal} {Explanations} for {Graph} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2104.06643},
	abstract = {This paper presents Gem, a model-agnostic approach for providing interpretable explanations for any GNNs on various graph learning tasks. Speciﬁcally, we formulate the problem of providing explanations for the decisions of GNNs as a causal learning task. Then we train a causal explanation model equipped with a loss function based on Granger causality. Different from existing explainers for GNNs, Gem explains GNNs on graph-structured data from a causal perspective. It has better generalization ability as it has no requirements on the internal structure of the GNNs or prior knowledge on the graph learning tasks. In addition, Gem, once trained, can be used to explain the target GNN very quickly. Our theoretical analysis shows that several recent explainers fall into a uniﬁed framework of additive feature attribution methods. Experimental results on synthetic and real-world datasets show that Gem achieves a relative increase of the explanation accuracy by up to 30\% and speeds up the explanation process by up to 110× as compared to its state-of-the-art alternatives.},
	language = {en},
	urldate = {2023-03-30},
	booktitle = {International {Conference} on {Machine} {Learning}},
	publisher = {arXiv},
	author = {Lin, Wanyu and Lan, Hao and Li, Baochun},
	month = jun,
	year = {2021},
	note = {arXiv:2104.06643 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{kazemi_representation_2019,
	title = {Representation {Learning} for {Dynamic} {Graphs}: {A} {Survey}},
	volume = {21},
	shorttitle = {Representation {Learning} for {Dynamic} {Graphs}},
	url = {http://arxiv.org/abs/1905.11485},
	abstract = {Graphs arise naturally in many real-world applications including social networks, recommender systems, ontologies, biology, and computational ﬁnance. Traditionally, machine learning models for graphs have been mostly designed for static graphs. However, many applications involve evolving graphs. This introduces important challenges for learning and inference since nodes, attributes, and edges change over time. In this survey, we review the recent advances in representation learning for dynamic graphs, including dynamic knowledge graphs. We describe existing models from an encoder-decoder perspective, categorize these encoders and decoders based on the techniques they employ, and analyze the approaches in each category. We also review several prominent applications and widely used datasets and highlight directions for future research.},
	language = {en},
	urldate = {2023-05-04},
	journal = {Journal of Machine Learning Research},
	author = {Kazemi, Seyed Mehran and Goel, Rishab and Jain, Kshitij and Kobyzev, Ivan and Sethi, Akshay and Forsyth, Peter and Poupart, Pascal},
	year = {2019},
	note = {arXiv:1905.11485 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {70:1--70:73},
}

@inproceedings{feng_towards_2023,
	title = {Towards open temporal graph neural networks},
	abstract = {Graph neural networks (GNNs) for temporal graphs have recently attracted increasing attentions, where a common assumption is that the class set for nodes is closed. However, in real-world scenarios, it often faces the open set problem with the dynamically increased class set as the time passes by. This will bring two big challenges to the existing temporal GNN methods: (i) How to dynamically propagate appropriate information in an open temporal graph, where new class nodes are often linked to old class nodes. This case will lead to a sharp contradiction. This is because typical GNNs are prone to make the embeddings of connected nodes become similar, while we expect the embeddings of these two interactive nodes to be distinguishable since they belong to different classes. (ii) How to avoid catastrophic knowledge forgetting over old classes when learning new classes occurred in temporal graphs. In this paper, we propose a general and principled learning approach for open temporal graphs, called OTGNet, with the goal of addressing the above two challenges. We assume the knowledge of a node can be disentangled into class-relevant and class-agnostic one, and thus explore a new message passing mechanism by extending the information bottleneck principle to only propagate class-agnostic knowledge between nodes of different classes, avoiding aggregating conflictive information. Moreover, we devise a strategy to select both important and diverse triad sub-graph structures for effective class-incremental learning. Extensive experiments on three real-world datasets of different domains demonstrate the superiority of our method, compared to the baselines.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Feng, Kaituo and Li, Changsheng and Zhang, Xiaolu and Zhou, Jun},
	year = {2023},
	keywords = {Dataset: Reddit, Dataset: Taobao, Dataset: Yelp},
}

@inproceedings{dabkowski_real_2017,
	title = {Real {Time} {Image} {Saliency} for {Black} {Box} {Classifiers}},
	url = {http://arxiv.org/abs/1705.07857},
	abstract = {In this work we develop a fast saliency detection method that can be applied to any differentiable image classiﬁer. We train a masking model to manipulate the scores of the classiﬁer by masking salient parts of the input image. Our model generalises well to unseen images and requires a single forward pass to perform saliency detection, therefore suitable for use in real-time systems. We test our approach on CIFAR-10 and ImageNet datasets and show that the produced saliency maps are easily interpretable, sharp, and free of artifacts. We suggest a new metric for saliency and test our method on the ImageNet object localisation task. We achieve results outperforming other weakly supervised methods.},
	language = {en},
	urldate = {2023-05-08},
	booktitle = {{NIPS}},
	publisher = {arXiv},
	author = {Dabkowski, Piotr and Gal, Yarin},
	month = may,
	year = {2017},
	note = {arXiv:1705.07857 [stat]},
	keywords = {Statistics - Machine Learning},
}

@inproceedings{abrate_counterfactual_2021,
	title = {Counterfactual {Graphs} for {Explainable} {Classification} of {Brain} {Networks}},
	url = {http://arxiv.org/abs/2106.08640},
	abstract = {Training graph classifiers able to distinguish between healthy brains and dysfunctional ones, can help identifying substructures associated to specific cognitive phenotypes. However, the mere predictive power of the graph classifier is of limited interest to the neuroscientists, which have plenty of tools for the diagnosis of specific mental disorders. What matters is the interpretation of the model, as it can provide novel insights and new hypotheses.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {{ACM} {SIGKDD} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {arXiv},
	author = {Abrate, Carlo and Bonchi, Francesco},
	month = jun,
	year = {2021},
	note = {arXiv:2106.08640 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks, Impact 3*, Relevance 4*},
}

@inproceedings{vaswani_attention_2017,
	title = {Attention is {All} you {Need}},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
	language = {en},
	booktitle = {{NIPS}},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
	year = {2017},
}

@inproceedings{trivedi_dyrep_2019,
	title = {{DyRep}: {Learning} {Representations} over {Dynamic} {Graphs}},
	abstract = {Representation Learning over graph structured data has received signiﬁcant attention recently due to its ubiquitous applicability. However, most advancements have been made in static graph settings while efforts for jointly learning dynamic of the graph and dynamic on the graph are still in an infant stage. Two fundamental questions arise in learning over dynamic graphs: (i) How to elegantly model dynamical processes over graphs? (ii) How to leverage such a model to effectively encode evolving graph information into low-dimensional representations? We present DyRep - a novel modeling framework for dynamic graphs that posits representation learning as a latent mediation process bridging two observed processes namely – dynamics of the network (realized as topological evolution) and dynamics on the network (realized as activities between nodes). Concretely, we propose a two-time scale deep temporal point process model that captures the interleaved dynamics of the observed processes. This model is further parameterized by a temporal-attentive representation network that encodes temporally evolving structural information into node representations which in turn drives the nonlinear evolution of the observed graph dynamics. Our uniﬁed framework is trained using an efﬁcient unsupervised procedure and has capability to generalize over unseen nodes. We demonstrate that DyRep outperforms state-of-the-art baselines for dynamic link prediction and time prediction tasks and present extensive qualitative insights into our framework.},
	language = {en},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Trivedi, Rakshit and Farajtabar, Mehrdad and Biswal, Prasenjeet and Zha, Hongyuan},
	year = {2019},
}

@inproceedings{xia_explaining_2023,
	title = {Explaining {Temporal} {Graph} {Models} {Through} {An} {Explorer}-{Navigator} {Framework}},
	abstract = {While Graph Neural Network (GNN) explanation has recently received signiﬁcant attention, existing works are generally designed for static graphs. Due to the prevalence of temporal graphs, many temporal graph models have been proposed, but explaining their predictions still remains to be explored. To bridge the gap, in this paper, we propose a Temporal GNN Explainer (T-GNNExplainer) method. Speciﬁcally, we regard a temporal graph as a sequence of temporal events between nodes. Given a temporal prediction of a model, our task is to ﬁnd a subset of historical events that lead to the prediction. To handle this combinatorial optimization problem, T-GNNExplainer includes an explorer to ﬁnd the event subsets with Monte Carlo Tree Search (MCTS), and a navigator that learns the correlations between events and helps reduce the search space. In particular, the navigator is trained in advance and then integrated with the explorer to speed up searching and achieve better results. To the best of our knowledge, T-GNNExplainer is the ﬁrst explainer tailored for temporal graph models. We conduct extensive experiments to evaluate the performance of T-GNNExplainer. Experimental results demonstrate that T-GNNExplainer can achieve superior performance with up to ⇠50\% improvement in Area under Fidelity-Sparsity Curve.},
	language = {en},
	booktitle = {The {Eleventh} {International} {Conference} on {Learning} {Representations}},
	author = {Xia, Wenwen and Lai, Mincai and Shan, Caihua and Zhang, Yao and Dai, Xinnan and Li, Xiang and Li, Dongsheng},
	year = {2023},
}

@article{panzarasa_patterns_2009,
	title = {Patterns and dynamics of users' behavior and interaction: {Network} analysis of an online community},
	volume = {60},
	issn = {15322882, 15322890},
	shorttitle = {Patterns and dynamics of users' behavior and interaction},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/asi.21015},
	doi = {10.1002/asi.21015},
	language = {en},
	number = {5},
	urldate = {2023-05-30},
	journal = {Journal of the American Society for Information Science and Technology},
	author = {Panzarasa, Pietro and Opsahl, Tore and Carley, Kathleen M.},
	month = may,
	year = {2009},
	pages = {911--932},
}

@article{shetty_enron_nodate,
	title = {The {Enron} {Email} {Dataset} {Database} {Schema} and {Brief} {Statistical} {Report}},
	language = {en},
	author = {Shetty, Jitesh and Adibi, Jafar},
}

@misc{xie_explaining_2022,
	title = {Explaining {Dynamic} {Graph} {Neural} {Networks} via {Relevance} {Back}-propagation},
	url = {http://arxiv.org/abs/2207.11175},
	abstract = {Graph Neural Networks (GNNs) have shown remarkable effectiveness in capturing abundant information in graph-structured data. However, the black-box nature of GNNs hinders users from understanding and trusting the models, thus leading to difﬁculties in their applications. While recent years witness the prosperity of the studies on explaining GNNs, most of them focus on static graphs, leaving the explanation of dynamic GNNs nearly unexplored. It is challenging to explain dynamic GNNs, due to their unique characteristic of time-varying graph structures. Directly using existing models designed for static graphs on dynamic graphs is not feasible because they ignore temporal dependencies among the snapshots. In this work, we propose DGExplainer to provide reliable explanation on dynamic GNNs. DGExplainer redistributes the output activation score of a dynamic GNN to the relevances of the neurons of its previous layer, which iterates until the relevance scores of the input neuron are obtained. We conduct quantitative and qualitative experiments on real-world datasets to demonstrate the effectiveness of the proposed framework for identifying important nodes for link prediction and node regression for dynamic GNNs.},
	language = {en},
	urldate = {2023-05-21},
	publisher = {arXiv},
	author = {Xie, Jiaxuan and Liu, Yezi and Shen, Yanning},
	month = jul,
	year = {2022},
	note = {arXiv:2207.11175 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{he_explainer_2022,
	address = {Rio de Janeiro, Brazil},
	title = {An {Explainer} for {Temporal} {Graph} {Neural} {Networks}},
	isbn = {978-1-66543-540-6},
	url = {https://ieeexplore.ieee.org/document/10001619/},
	doi = {10.1109/GLOBECOM48099.2022.10001619},
	abstract = {Temporal graph neural networks (TGNNs) have been widely used for modeling time-evolving graph-related tasks due to their ability to capture both graph topology dependency and non-linear temporal dynamic. The explanation of TGNNs is of vital importance for a transparent and trustworthy model. However, the complex topology structure and temporal dependency make explaining TGNN models very challenging. In this paper, we propose a novel explainer framework for TGNN models. Given a time series on a graph to be explained, the framework can identify dominant explanations in the form of a probabilistic graphical model in a time period. Case studies on the transportation domain demonstrate that the proposed approach can discover dynamic dependency structures in a road network for a time period.},
	language = {en},
	urldate = {2023-05-19},
	booktitle = {{GLOBECOM} 2022 - 2022 {IEEE} {Global} {Communications} {Conference}},
	publisher = {IEEE},
	author = {He, Wenchong and Vu, Minh N. and Jiang, Zhe and Thai, My T.},
	month = dec,
	year = {2022},
	pages = {6384--6389},
}

@misc{velickovic_graph_2018,
	title = {Graph {Attention} {Networks}},
	url = {http://arxiv.org/abs/1710.10903},
	abstract = {We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods’ features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).},
	language = {en},
	urldate = {2023-05-15},
	publisher = {arXiv},
	author = {Veličković, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Liò, Pietro and Bengio, Yoshua},
	month = feb,
	year = {2018},
	note = {arXiv:1710.10903 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Social and Information Networks, Statistics - Machine Learning},
}

@inproceedings{robnik-sikonja_perturbation-based_2018,
	title = {Perturbation-{Based} {Explanations} of {Prediction} {Models}},
	booktitle = {Human and {Machine} {Learning}},
	author = {Robnik-Sikonja, M. and Bohanec, Marko},
	year = {2018},
}

@inproceedings{kumar_predicting_2019,
	address = {Anchorage AK USA},
	title = {Predicting {Dynamic} {Embedding} {Trajectory} in {Temporal} {Interaction} {Networks}},
	isbn = {978-1-4503-6201-6},
	url = {https://dl.acm.org/doi/10.1145/3292500.3330895},
	doi = {10.1145/3292500.3330895},
	abstract = {Modeling sequential interactions between users and items/products is crucial in domains such as ecommerce, social networking, and education. Representation learning presents an attractive opportunity to model the dynamic evolution of users and items, where each user/item can be embedded in a Euclidean space and its evolution can be modeled by an embedding trajectory in this space. However, existing dynamic embedding methods generate embeddings only when users take actions and do not explicitly model the future trajectory of the user/item in the embedding space. Here we propose JODIE, a coupled recurrent neural network model that learns the embedding trajectories of users and items. JODIE employs two recurrent neural networks to update the embedding of a user and an item at every interaction. Crucially, JODIE also models the future embedding trajectory of a user/item. To this end, it introduces a novel projection operator that learns to estimate the embedding of the user at any time in the future. These estimated embeddings are then used to predict future user-item interactions. To make the method scalable, we develop a t-Batch algorithm that creates time-consistent batches and leads to 9× faster training. We conduct six experiments to validate JODIE on two prediction tasks— future interaction prediction and state change prediction—using four real-world datasets. We show that JODIE outperforms six state-of-the-art algorithms in these tasks by at least 20\% in predicting future interactions and 12\% in state change prediction.},
	language = {en},
	urldate = {2023-05-11},
	booktitle = {Proceedings of the 25th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Kumar, Srijan and Zhang, Xikun and Leskovec, Jure},
	month = jul,
	year = {2019},
	pages = {1269--1278},
}

@misc{poursafaei_towards_2022,
	title = {Towards {Better} {Evaluation} for {Dynamic} {Link} {Prediction}},
	url = {http://arxiv.org/abs/2207.10128},
	abstract = {Despite the prevalence of recent success in learning from static graphs, learning from time-evolving graphs remains an open challenge. In this work, we design new, more stringent evaluation procedures for link prediction speciﬁc to dynamic graphs, which reﬂect real-world considerations, to better compare the strengths and weaknesses of methods. First, we create two visualization techniques to understand the reoccurring patterns of edges over time and show that many edges reoccur at later time steps. Based on this observation, we propose a pure memorization baseline called EdgeBank. EdgeBank achieves surprisingly strong performance across multiple settings because easy negative edges are often used in current evaluation setting. To evaluate against more difﬁcult negative edges, we introduce two more challenging negative sampling strategies that improve robustness and better match real-world applications. Lastly, we introduce six new dynamic graph datasets from a diverse set of domains missing from current benchmarks, providing new challenges and opportunities for future research. Our code repository is accessible at https://github.com/fpour/DGB.git.},
	language = {en},
	urldate = {2023-05-11},
	publisher = {arXiv},
	author = {Poursafaei, Farimah and Huang, Shenyang and Pelrine, Kellin and Rabbany, Reihaneh},
	month = sep,
	year = {2022},
	note = {arXiv:2207.10128 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks},
}

@article{sanchez-lengeling_evaluating_nodate,
	title = {Evaluating {Attribution} for {Graph} {Neural} {Networks}},
	abstract = {Interpretability of machine learning models is critical to scientiﬁc understanding, AI safety, and debugging. Attribution is one approach to interpretability, which highlights input dimensions that are inﬂuential to a neural network’s prediction. Evaluation of these methods is largely qualitative for image and text models, because acquiring ground truth attributions requires expensive and unreliable human judgment. Attribution has been comparatively understudied for graph neural networks (GNNs), a model class of growing importance that makes predictions on arbitrarily-sized graphs. Graph-valued data offer an opportunity to quantitatively benchmark attribution methods, because challenging synthetic graph problems have computable ground-truth attributions. In this work we adapt commonly-used attribution methods for GNNs and quantitatively evaluate them using the axes of attribution accuracy, stability, faithfulness and consistency. We make concrete recommendations for which attribution methods to use, and provide the data and code for our benchmarking suite. Rigorous and open source benchmarking of attribution methods in graphs could enable new methods development and broader use of attribution in real-world ML tasks.},
	language = {en},
	author = {Sanchez-Lengeling, Benjamin and Wei, Jennifer and Lee, Brian and Reif, Emily and Wang, Peter Y and Qian, Wei and McCloskey, Kevin and Colwell, Lucy and Wiltschko, Alexander},
}

@misc{makarov_temporal_2021,
	title = {Temporal {Graph} {Network} {Embedding} with {Causal} {Anonymous} {Walks} {Representations}},
	url = {http://arxiv.org/abs/2108.08754},
	abstract = {Many tasks in graph machine learning, such as link prediction and node classification, are typically solved by using representation learning, in which each node or edge in the network is encoded via an embedding. Though there exists a lot of network embeddings for static graphs, the task becomes much more complicated when the dynamic (i.e. temporal) network is analyzed. In this paper, we propose a novel approach for dynamic network representation learning based on Temporal Graph Network by using a highly custom message generating function by extracting Causal Anonymous Walks. For evaluation, we provide a benchmark pipeline for the evaluation of temporal network embeddings. This work provides the first comprehensive comparison framework for temporal network representation learning in every available setting for graph machine learning problems involving node classification and link prediction. The proposed model outperforms state-of-the-art baseline models. The work also justifies the difference between them based on evaluation in various transductive/inductive edge/node classification tasks. In addition, we show the applicability and superior performance of our model in the real-world downstream graph machine learning task provided by one of the top European banks, involving credit scoring based on transaction data.},
	language = {en},
	urldate = {2023-05-10},
	publisher = {arXiv},
	author = {Makarov, Ilya and Savchenko, Andrey and Korovko, Arseny and Sherstyuk, Leonid and Severin, Nikita and Mikheev, Aleksandr and Babaev, Dmitrii},
	month = aug,
	year = {2021},
	note = {arXiv:2108.08754 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@inproceedings{sankar_dysat_2020,
	address = {Houston TX USA},
	title = {{DySAT}: {Deep} {Neural} {Representation} {Learning} on {Dynamic} {Graphs} via {Self}-{Attention} {Networks}},
	isbn = {978-1-4503-6822-3},
	shorttitle = {{DySAT}},
	url = {https://dl.acm.org/doi/10.1145/3336191.3371845},
	doi = {10.1145/3336191.3371845},
	language = {en},
	urldate = {2023-05-04},
	booktitle = {Proceedings of the 13th {International} {Conference} on {Web} {Search} and {Data} {Mining}},
	publisher = {ACM},
	author = {Sankar, Aravind and Wu, Yanhong and Gou, Liang and Zhang, Wei and Yang, Hao},
	month = jan,
	year = {2020},
	pages = {519--527},
}

@article{manessi_dynamic_2020,
	title = {Dynamic {Graph} {Convolutional} {Networks}},
	volume = {97},
	issn = {00313203},
	url = {http://arxiv.org/abs/1704.06199},
	doi = {10.1016/j.patcog.2019.107000},
	abstract = {Many diﬀerent classiﬁcation tasks need to manage structured data, which are usually modeled as graphs. Moreover, these graphs can be dynamic, meaning that the vertices/edges of each graph may change during time. Our goal is to jointly exploit structured data and temporal information through the use of a neural network model. To the best of our knowledge, this task has not been addressed using these kind of architectures. For this reason, we propose two novel approaches, which combine Long Short-Term Memory networks and Graph Convolutional Networks to learn long short-term dependencies together with graph structure. The quality of our methods is conﬁrmed by the promising results achieved.},
	language = {en},
	urldate = {2023-05-03},
	journal = {Pattern Recognition},
	author = {Manessi, Franco and Rozza, Alessandro and Manzo, Mario},
	month = jan,
	year = {2020},
	note = {arXiv:1704.06199 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {107000},
}

@misc{thomas_graph_2023,
	title = {Graph {Neural} {Networks} {Designed} for {Different} {Graph} {Types}: {A} {Survey}},
	shorttitle = {Graph {Neural} {Networks} {Designed} for {Different} {Graph} {Types}},
	url = {http://arxiv.org/abs/2204.03080},
	abstract = {Graphs are ubiquitous in nature and can therefore serve as models for many practical but also theoretical problems. For this purpose, they can be deﬁned as many diﬀerent types which suitably reﬂect the individual contexts of the represented problem. To address cutting-edge problems based on graph data, the research ﬁeld of Graph Neural Networks (GNNs) has emerged. Despite the ﬁeld’s youth and the speed at which new models are developed, many recent surveys have been published to keep track of them. Nevertheless, it has not yet been gathered which GNN can process what kind of graph types. In this survey, we give a detailed overview of already existing GNNs and, unlike previous surveys, categorize them according to their ability to handle diﬀerent graph types and properties. We consider GNNs operating on static and dynamic graphs of diﬀerent structural constitutions, with or without node or edge attributes. Moreover, we distinguish between GNN models for discrete-time or continuous-time dynamic graphs and group the models according to their architecture. We ﬁnd that there are still graph types that are not or only rarely covered by existing GNN models. We point out where models are missing and give potential reasons for their absence.},
	language = {en},
	urldate = {2023-05-02},
	publisher = {arXiv},
	author = {Thomas, Josephine M. and Moallemy-Oureh, Alice and Beddar-Wiesing, Silvia and Holzhüter, Clara},
	month = apr,
	year = {2023},
	note = {arXiv:2204.03080 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{european_parliament_regulation_2016,
	title = {Regulation ({EU}) 2016/679 of the {European} {Parliament} and of the {Council}},
	url = {https://data.europa.eu/eli/reg/2016/679/oj},
	abstract = {The General Data Protection Regulation (2016/679, "GDPR") is a Regulation in European Union (EU) law on data protection and privacy in the EU and the European Economic Area (EEA).},
	urldate = {2023-04-13},
	author = {{European Parliament} and {Council of the European Union}},
	month = may,
	year = {2016},
	note = {Place: OJ L 119, 4.5.2016, p. 1–88},
	keywords = {access consumer data data-processing freedom gdpr information justice law personal privacy protection security verification},
}

@article{european_parliament_consolidated_2016,
	title = {Consolidated text: {Regulation} ({EU}) 2016/679 of the {European} {Parliament} and of the {Council} of 27 {April} 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing {Directive} 95/46/{EC} ({General} {Data} {Protection} {Regulation})},
	journal = {OJ L 119},
	author = {European Parliament and Council of the European Union},
	month = may,
	year = {2016},
	pages = {1--88},
}

@book{radley-gardner_fundamental_2016,
	title = {Fundamental {Texts} {On} {European} {Private} {Law}},
	isbn = {978-1-78225-864-3 978-1-78225-865-0 978-1-78225-866-7 978-1-78225-867-4},
	url = {http://www.bloomsburycollections.com/book/fundamental-texts-on-european-private-law-1},
	language = {en},
	urldate = {2023-04-24},
	publisher = {Hart Publishing},
	editor = {Radley-Gardner, Oliver and Beale, Hugh and Zimmermann, Reinhard},
	year = {2016},
	doi = {10.5040/9781782258674},
}

@inproceedings{rozemberczki_pytorch_2021,
	address = {Virtual Event Queensland Australia},
	title = {{PyTorch} {Geometric} {Temporal}: {Spatiotemporal} {Signal} {Processing} with {Neural} {Machine} {Learning} {Models}},
	isbn = {978-1-4503-8446-9},
	shorttitle = {{PyTorch} {Geometric} {Temporal}},
	url = {https://dl.acm.org/doi/10.1145/3459637.3482014},
	doi = {10.1145/3459637.3482014},
	abstract = {We present PyTorch Geometric Temporal, a deep learning framework combining state-of-the-art machine learning algorithms for neural spatiotemporal signal processing. The main goal of the library is to make temporal geometric deep learning available for researchers and machine learning practitioners in a unified easyto-use framework. PyTorch Geometric Temporal was created with foundations on existing libraries in the PyTorch eco-system, streamlined neural network layer definitions, temporal snapshot generators for batching, and integrated benchmark datasets. These features are illustrated with a tutorial-like case study. Experiments demonstrate the predictive performance of the models implemented in the library on real-world problems such as epidemiological forecasting, ride-hail demand prediction, and web traffic management. Our sensitivity analysis of runtime shows that the framework can potentially operate on web-scale datasets with rich temporal features and spatial structure.},
	language = {en},
	urldate = {2023-04-21},
	booktitle = {Proceedings of the 30th {ACM} {International} {Conference} on {Information} \& {Knowledge} {Management}},
	publisher = {ACM},
	author = {Rozemberczki, Benedek and Scherer, Paul and He, Yixuan and Panagopoulos, George and Riedel, Alexander and Astefanoaei, Maria and Kiss, Oliver and Beres, Ferenc and López, Guzmán and Collignon, Nicolas and Sarkar, Rik},
	month = oct,
	year = {2021},
	pages = {4564--4573},
}

@misc{noauthor_vl_nodate,
	title = {{VL} 1: {Lineare} aktoren},
}

@misc{cai_temporal_2022,
	title = {Temporal {Knowledge} {Graph} {Completion}: {A} {Survey}},
	shorttitle = {Temporal {Knowledge} {Graph} {Completion}},
	url = {http://arxiv.org/abs/2201.08236},
	abstract = {Knowledge graph completion (KGC) can predict missing links and is crucial for real-world knowledge graphs, which widely suffer from incompleteness. KGC methods assume a knowledge graph is static, but that may lead to inaccurate prediction results because many facts in the knowledge graphs change over time. Recently, emerging methods have shown improved predictive results by further incorporating the timestamps of facts; namely, temporal knowledge graph completion (TKGC). With this temporal information, TKGC methods can learn the dynamic evolution of the knowledge graph that KGC methods fail to capture. In this paper, for the ﬁrst time, we summarize the recent advances in TKGC research. First, we detail the background of TKGC, including the problem deﬁnition, benchmark datasets, and evaluation metrics. Then, we summarize existing TKGC methods based on how timestamps of facts are used to capture the temporal dynamics. Finally, we conclude the paper and present future research directions of TKGC.},
	language = {en},
	urldate = {2023-04-06},
	publisher = {arXiv},
	author = {Cai, Borui and Xiang, Yong and Gao, Longxiang and Zhang, He and Li, Yunfeng and Li, Jianxin},
	month = jan,
	year = {2022},
	note = {arXiv:2201.08236 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{hogan_knowledge_2022,
	title = {Knowledge {Graphs}},
	volume = {54},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3447772},
	doi = {10.1145/3447772},
	abstract = {In this article, we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After some opening remarks, we motivate and contrast various graph-based data models, as well as languages used to query and validate knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We conclude with high-level future research directions for knowledge graphs.},
	language = {en},
	number = {4},
	urldate = {2023-04-05},
	journal = {ACM Computing Surveys},
	author = {Hogan, Aidan and Blomqvist, Eva and Cochez, Michael and D’amato, Claudia and Melo, Gerard De and Gutierrez, Claudio and Kirrane, Sabrina and Gayo, José Emilio Labra and Navigli, Roberto and Neumaier, Sebastian and Ngomo, Axel-Cyrille Ngonga and Polleres, Axel and Rashid, Sabbir M. and Rula, Anisa and Schmelzeisen, Lukas and Sequeda, Juan and Staab, Steffen and Zimmermann, Antoine},
	month = may,
	year = {2022},
	pages = {1--37},
}

@article{wu_comprehensive_2021,
	title = {A {Comprehensive} {Survey} on {Graph} {Neural} {Networks}},
	volume = {32},
	issn = {2162-237X, 2162-2388},
	url = {https://ieeexplore.ieee.org/document/9046288/},
	doi = {10.1109/TNNLS.2020.2978386},
	abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classiﬁcation and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed signiﬁcant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning ﬁelds. We propose a new taxonomy to divide the state-of-the-art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial–temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes, benchmark data sets, and model evaluation of GNNs. Finally, we propose potential research directions in this rapidly growing ﬁeld.},
	language = {en},
	number = {1},
	urldate = {2023-04-05},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
	month = jan,
	year = {2021},
	pages = {4--24},
}

@inproceedings{szegedy_going_2015,
	address = {Boston, MA, USA},
	title = {Going deeper with convolutions},
	isbn = {978-1-4673-6964-0},
	url = {http://ieeexplore.ieee.org/document/7298594/},
	doi = {10.1109/CVPR.2015.7298594},
	abstract = {We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classiﬁcation and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classiﬁcation and detection.},
	language = {en},
	urldate = {2023-04-05},
	booktitle = {2015 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Szegedy, Christian and {Wei Liu} and {Yangqing Jia} and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	month = jun,
	year = {2015},
	pages = {1--9},
}

@inproceedings{deng_learning_2019,
	address = {Anchorage AK USA},
	title = {Learning {Dynamic} {Context} {Graphs} for {Predicting} {Social} {Events}},
	isbn = {978-1-4503-6201-6},
	url = {https://dl.acm.org/doi/10.1145/3292500.3330919},
	doi = {10.1145/3292500.3330919},
	abstract = {Event forecasting with an aim at modeling contextual information is an important task for applications such as automated analysis generation and resource allocation. Captured contextual information for an event of interest can aid human analysts in understanding the factors associated with that event. However, capturing contextual information within event forecasting is challenging due to several factors: (i) uncertainty of context structure and formulation, (ii) high dimensional features, and (iii) adaptation of features over time. Recently, graph representations have demonstrated success in applications such as traffic forecasting, social influence prediction, and visual question answering systems. In this paper, we study graph representations in modeling social events to identify dynamic properties of event contexts as social indicators.},
	language = {en},
	urldate = {2023-03-16},
	booktitle = {Proceedings of the 25th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Deng, Songgaojun and Rangwala, Huzefa and Ning, Yue},
	month = jul,
	year = {2019},
	keywords = {Dataset: ICEWS, Quality 4*, Relevance 5*},
	pages = {1007--1016},
}

@inproceedings{wang_knowledge_2019,
	address = {San Francisco CA USA},
	title = {Knowledge {Graph} {Convolutional} {Networks} for {Recommender} {Systems}},
	isbn = {978-1-4503-6674-8},
	url = {https://dl.acm.org/doi/10.1145/3308558.3313417},
	doi = {10.1145/3308558.3313417},
	abstract = {To alleviate sparsity and cold start problem of collaborative filtering based recommender systems, researchers and engineers usually collect attributes of users and items, and design delicate algorithms to exploit these additional information. In general, the attributes are not isolated but connected with each other, which forms a knowledge graph (KG). In this paper, we propose Knowledge Graph Convolutional Networks (KGCN), an end-to-end framework that captures inter-item relatedness effectively by mining their associated attributes on the KG. To automatically discover both high-order structure information and semantic information of the KG, we sample from the neighbors for each entity in the KG as their receptive field, then combine neighborhood information with bias when calculating the representation of a given entity. The receptive field can be extended to multiple hops away to model high-order proximity information and capture users’ potential long-distance interests. Moreover, we implement the proposed KGCN in a minibatch fashion, which enables our model to operate on large datasets and KGs. We apply the proposed model to three datasets about movie, book, and music recommendation, and experiment results demonstrate that our approach outperforms strong recommender baselines.},
	language = {en},
	urldate = {2023-03-16},
	booktitle = {The {World} {Wide} {Web} {Conference}},
	publisher = {ACM},
	author = {Wang, Hongwei and Zhao, Miao and Xie, Xing and Li, Wenjie and Guo, Minyi},
	month = may,
	year = {2019},
	keywords = {Dataset: Book-Crossing, Dataset: Last.FM, Dataset: MovieLens, Model: KGCN, Quality 4*, Relevance 1*},
	pages = {3307--3313},
}

@misc{vu_limit_2022,
	title = {On the {Limit} of {Explaining} {Black}-box {Temporal} {Graph} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2212.00952},
	abstract = {Temporal Graph Neural Network (TGNN) has been receiving a lot of attention recently due to its capability in modeling time-evolving graph-related tasks. Similar to Graph Neural Networks, it is also non-trivial to interpret predictions made by a TGNN due to its black-box nature. A major approach tackling this problems in GNNs is by analyzing the model’ responses on some perturbations of the model’s inputs, called perturbation-based explanation methods. While these methods are convenient and ﬂexible since they do not need internal access to the model, does this lack of internal access prevent them from revealing some important information of the predictions? Motivated by that question, this work studies the limit of some classes of perturbation-based explanation methods. Particularly, by constructing some speciﬁc instances of TGNNs, we show (i) node-perturbation cannot reliably identify the paths carrying out the prediction, (ii) edgeperturbation is not reliable in determining all nodes contributing to the prediction and (iii) perturbing both nodes and edges does not reliably help us identify the graph’s components carrying out the temporal aggregation in TGNNs.},
	language = {en},
	urldate = {2023-03-28},
	publisher = {arXiv},
	author = {Vu, Minh N. and Thai, My T.},
	month = dec,
	year = {2022},
	note = {arXiv:2212.00952 [cs]},
	keywords = {Computer Science - Machine Learning, Dataset: BA-2motifs, Dataset: Mutagenicity, Dataset: NCI1, Impact 1*, Metric: AUC, Metric: Fidelity, Relevance 5*},
}

@inproceedings{tan_learning_2022,
	title = {Learning and {Evaluating} {Graph} {Neural} {Network} {Explanations} based on {Counterfactual} and {Factual} {Reasoning}},
	url = {http://arxiv.org/abs/2202.08816},
	doi = {10.1145/3485447.3511948},
	abstract = {Structural data well exists in Web applications, such as social networks in social media, citation networks in academic websites, and threads data in online forums. Due to the complex topology, it is difficult to process and make use of the rich information within such data. Graph Neural Networks (GNNs) have shown great advantages on learning representations for structural data. However, the non-transparency of the deep learning models makes it non-trivial to explain and interpret the predictions made by GNNs. Meanwhile, it is also a big challenge to evaluate the GNN explanations, since in many cases, the ground-truth explanations are unavailable.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {Proceedings of the {ACM} {Web} {Conference} 2022},
	author = {Tan, Juntao and Geng, Shijie and Fu, Zuohui and Ge, Yingqiang and Xu, Shuyuan and Li, Yunqi and Zhang, Yongfeng},
	month = apr,
	year = {2022},
	note = {arXiv:2202.08816 [cs]},
	keywords = {Computer Science - Information Retrieval, Computer Science - Machine Learning, Dataset: BA-Shapes, Dataset: CiteSeer, Dataset: Mutag, Dataset: NCI1, Dataset: Tree-Cycles, Impact 4*, Metric: Probability of Necessity, Metric: Probability of Sufficiency, Relevance 5*, Task: Graph Classification, Task: Node Classification},
	pages = {1018--1027},
}

@misc{han_xerte_2021,
	title = {{xERTE}: {Explainable} {Reasoning} on {Temporal} {Knowledge} {Graphs} for {Forecasting} {Future} {Links}},
	shorttitle = {{xERTE}},
	url = {http://arxiv.org/abs/2012.15537},
	abstract = {Modeling time-evolving knowledge graphs (KGs) has recently gained increasing interest. Here, graph representation learning has become the dominant paradigm for link prediction on temporal KGs. However, the embedding-based approaches largely operate in a black-box fashion, lacking the ability to interpret their predictions. This paper provides a link forecasting framework that reasons over queryrelevant subgraphs of temporal KGs and jointly models the structural dependencies and the temporal dynamics. Especially, we propose a temporal relational attention mechanism and a novel reverse representation update scheme to guide the extraction of an enclosing subgraph around the query. The subgraph is expanded by an iterative sampling of temporal neighbors and by attention propagation. Our approach provides human-understandable evidence explaining the forecast. We evaluate our model on four benchmark temporal knowledge graphs for the link forecasting task. While being more explainable, our model obtains a relative improvement of up to 20 \% on Hits@1 compared to the previous best temporal KG forecasting method. We also conduct a survey with 53 respondents, and the results show that the evidence extracted by the model for link forecasting is aligned with human understanding.},
	language = {en},
	urldate = {2023-03-28},
	publisher = {arXiv},
	author = {Han, Zhen and Chen, Peng and Ma, Yunpu and Tresp, Volker},
	month = apr,
	year = {2021},
	note = {arXiv:2012.15537 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Dataset: ICEWS, Dataset: YAGO, Impact 2*, Relevance 5*, Task: Link Prediction},
}

@article{bacciu_explaining_2022,
	title = {Explaining {Deep} {Graph} {Networks} via {Input} {Perturbation}},
	issn = {2162-237X, 2162-2388},
	url = {https://ieeexplore.ieee.org/document/9761788/},
	doi = {10.1109/TNNLS.2022.3165618},
	abstract = {Deep graph networks (DGNs) are a family of machine learning models for structured data which are ﬁnding heavy application in life sciences (drug repurposing, molecular property predictions) and on social network data (recommendation systems). The privacy and safety-critical nature of such domains motivates the need for developing effective explainability methods for this family of models. So far, progress in this ﬁeld has been challenged by the combinatorial nature and complexity of graph structures. In this respect, we present a novel local explanation framework speciﬁcally tailored to graph data and DGNs. Our approach leverages reinforcement learning to generate meaningful local perturbations of the input graph, whose prediction we seek an interpretation for. These perturbed data points are obtained by optimizing a multiobjective score taking into account similarities both at a structural level as well as at the level of the deep model outputs. By this means, we are able to populate a set of informative neighboring samples for the query graph, which is then used to ﬁt an interpretable model for the predictive behavior of the deep network locally to the query graph prediction. We show the effectiveness of the proposed explainer by a qualitative analysis on two chemistry datasets, TOX21 and Estimated SOLubility (ESOL) and by quantitative results on a benchmark dataset for explanations, CYCLIQ.},
	language = {en},
	urldate = {2023-03-28},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Bacciu, Davide and Numeroso, Danilo},
	year = {2022},
	keywords = {Impact 2*, Relevance 3*},
	pages = {1--12},
}

@article{ivanovs_perturbation-based_2021,
	title = {Perturbation-based methods for explaining deep neural networks: {A} survey},
	volume = {150},
	issn = {01678655},
	shorttitle = {Perturbation-based methods for explaining deep neural networks},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167865521002440},
	doi = {10.1016/j.patrec.2021.06.030},
	language = {en},
	urldate = {2023-03-28},
	journal = {Pattern Recognition Letters},
	author = {Ivanovs, Maksims and Kadikis, Roberts and Ozols, Kaspars},
	month = oct,
	year = {2021},
	keywords = {Impact 3*, Relevance 3*},
	pages = {228--234},
}

@inproceedings{pope_explainability_2019,
	address = {Long Beach, CA, USA},
	title = {Explainability {Methods} for {Graph} {Convolutional} {Neural} {Networks}},
	isbn = {978-1-72813-293-8},
	url = {https://ieeexplore.ieee.org/document/8954227/},
	doi = {10.1109/CVPR.2019.01103},
	abstract = {With the growing use of graph convolutional neural networks (GCNNs) comes the need for explainability. In this paper, we introduce explainability methods for GCNNs. We develop the graph analogues of three prominent explainability methods for convolutional neural networks: contrastive gradient-based (CG) saliency maps, Class Activation Mapping (CAM), and Excitation Backpropagation (EB) and their variants, gradient-weighted CAM (Grad-CAM) and contrastive EB (c-EB). We show a proof-of-concept of these methods on classiﬁcation problems in two application domains: visual scene graphs and molecular graphs. To compare the methods, we identify three desirable properties of explanations: (1) their importance to classiﬁcation, as measured by the impact of occlusions, (2) their contrastivity with respect to different classes, and (3) their sparseness on a graph. We call the corresponding quantitative metrics ﬁdelity, contrastivity, and sparsity and evaluate them for each method. Lastly, we analyze the salient subgraphs obtained from explanations and report frequently occurring patterns.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {2019 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Pope, Phillip E. and Kolouri, Soheil and Rostami, Mohammad and Martin, Charles E. and Hoffmann, Heiko},
	month = jun,
	year = {2019},
	keywords = {Impact 5*, Relevance 3*},
	pages = {10764--10773},
}

@inproceedings{yuan_xgnn_2020,
	title = {{XGNN}: {Towards} {Model}-{Level} {Explanations} of {Graph} {Neural} {Networks}},
	shorttitle = {{XGNN}},
	url = {http://arxiv.org/abs/2006.02587},
	doi = {10.1145/3394486.3403085},
	abstract = {Graphs neural networks (GNNs) learn node features by aggregating and combining neighbor information, which have achieved promising performance on many graph tasks. However, GNNs are mostly treated as black-boxes and lack human intelligible explanations. Thus, they cannot be fully trusted and used in certain application domains if GNN models cannot be explained. In this work, we propose a novel approach, known as XGNN, to interpret GNNs at the model-level. Our approach can provide high-level insights and generic understanding of how GNNs work. In particular, we propose to explain GNNs by training a graph generator so that the generated graph patterns maximize a certain prediction of the model. We formulate the graph generation as a reinforcement learning task, where for each step, the graph generator predicts how to add an edge into the current graph. The graph generator is trained via a policy gradient method based on information from the trained GNNs. In addition, we incorporate several graph rules to encourage the generated graphs to be valid. Experimental results on both synthetic and real-world datasets show that our proposed methods help understand and verify the trained GNNs. Furthermore, our experimental results indicate that the generated graphs can provide guidance on how to improve the trained GNNs.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {Proceedings of the 26th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	author = {Yuan, Hao and Tang, Jiliang and Hu, Xia and Ji, Shuiwang},
	month = aug,
	year = {2020},
	note = {arXiv:2006.02587 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Impact 5*, Relevance 4*, Statistics - Machine Learning},
	pages = {430--438},
}

@misc{fan_jointly_2022,
	title = {Jointly {Attacking} {Graph} {Neural} {Network} and its {Explanations}},
	url = {http://arxiv.org/abs/2108.03388},
	abstract = {Graph Neural Networks (GNNs) have boosted the performance for many graphrelated tasks. Despite the great success, recent studies have shown that GNNs are highly vulnerable to adversarial attacks, where adversaries can mislead the GNNs’ prediction by modifying graphs. On the other hand, the explanation of GNNs (GNNEXPLAINER) provides a better understanding of a trained GNN model by generating a small subgraph and features that are most inﬂuential for its prediction. In this paper, we ﬁrst perform empirical studies to validate that GNNEXPLAINER can act as an inspection tool and have the potential to detect the adversarial perturbations for graphs. This ﬁnding motivates us to further initiate a new problem investigation: Whether a graph neural network and its explanations can be jointly attacked by modifying graphs with malicious desires? It is challenging to answer this question since the goals of adversarial attacks and bypassing the GNNEXPLAINER essentially contradict each other. In this work, we give a conﬁrmative answer to this question by proposing a novel attack framework (GEAttack), which can attack both a GNN model and its explanations by simultaneously exploiting their vulnerabilities. Extensive experiments on two explainers (GNNEXPLAINER and PGExplainer) under various real-world datasets demonstrate the effectiveness of the proposed method.},
	language = {en},
	urldate = {2023-03-28},
	publisher = {arXiv},
	author = {Fan, Wenqi and Jin, Wei and Liu, Xiaorui and Xu, Han and Tang, Xianfeng and Wang, Suhang and Li, Qing and Tang, Jiliang and Wang, Jianping and Aggarwal, Charu},
	month = nov,
	year = {2022},
	note = {arXiv:2108.03388 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security, Computer Science - Machine Learning, Computer Science - Social and Information Networks, Impact 3*, Relevance 3*},
}

@misc{li_explainability_2022,
	title = {Explainability in {Graph} {Neural} {Networks}: {An} {Experimental} {Survey}},
	shorttitle = {Explainability in {Graph} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2203.09258},
	abstract = {Graph neural networks (GNNs) have been extensively developed for graph representation learning in various application domains. However, similar to all other neural networks models, GNNs suffer from the black-box problem as people cannot understand the mechanism underlying them. To solve this problem, several GNN explainability methods have been proposed to explain the decisions made by GNNs. In this survey, we give an overview of the state-of-the-art GNN explainability methods and how they are evaluated. Furthermore, we propose a new evaluation metric and conduct thorough experiments to compare GNN explainability methods on real world datasets. We also suggest future directions for GNN explainability.},
	language = {en},
	urldate = {2023-03-28},
	publisher = {arXiv},
	author = {Li, Peibo and Yang, Yixing and Pagnucco, Maurice and Song, Yang},
	month = mar,
	year = {2022},
	note = {arXiv:2203.09258 [cs]},
	keywords = {A.1, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, I.2.0, Impact 3*, Relevance 3*},
}

@misc{jain_temporal_2020,
	title = {Temporal {Knowledge} {Base} {Completion}: {New} {Algorithms} and {Evaluation} {Protocols}},
	shorttitle = {Temporal {Knowledge} {Base} {Completion}},
	url = {http://arxiv.org/abs/2005.05035},
	abstract = {Research on temporal knowledge bases, which associate a relational fact (s, r, o) with a validity time period (or time instant), is in its early days. Our work considers predicting missing entities (link prediction) and missing time intervals (time prediction) as joint Temporal Knowledge Base Completion (TKBC) tasks, and presents TIMEPLEX, a novel TKBC method, in which entities, relations and, time are all embedded in a uniform, compatible space. TIMEPLEX exploits the recurrent nature of some facts/events and temporal interactions between pairs of relations, yielding stateof-the-art results on both prediction tasks.},
	language = {en},
	urldate = {2023-03-28},
	publisher = {arXiv},
	author = {Jain, Prachi and Rathi, Sushant and Mausam and Chakrabarti, Soumen},
	month = oct,
	year = {2020},
	note = {arXiv:2005.05035 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Social and Information Networks, Impact 3*, Relevance 4*},
}

@misc{dikeoulias_temporal_2022,
	title = {Temporal {Knowledge} {Graph} {Reasoning} with {Low}-rank and {Model}-agnostic {Representations}},
	url = {http://arxiv.org/abs/2204.04783},
	abstract = {Temporal knowledge graph completion (TKGC) has become a popular approach for reasoning over the event and temporal knowledge graphs, targeting the completion of knowledge with accurate but missing information. In this context, tensor decomposition has successfully modeled interactions between entities and relations. Their effectiveness in static knowledge graph completion motivates us to introduce Time-LowFER, a family of parameter-efﬁcient and time-aware extensions of the low-rank tensor factorization model LowFER. Noting several limitations in current approaches to represent time, we propose a cycle-aware time-encoding scheme for time features, which is model-agnostic and offers a more generalized representation of time. We implement our methods in a uniﬁed temporal knowledge graph embedding framework, focusing on time-sensitive data processing. The experiments show that our proposed methods perform on par or better than the state-of-the-art semantic matching models on two benchmarks.},
	language = {en},
	urldate = {2023-03-28},
	publisher = {arXiv},
	author = {Dikeoulias, Ioannis and Amin, Saadullah and Neumann, Günter},
	month = apr,
	year = {2022},
	note = {arXiv:2204.04783 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Impact 1*, Relevance 1*},
}

@inproceedings{xu_time-aware_2021,
	title = {Time-aware {Graph} {Neural} {Networks} for {Entity} {Alignment} between {Temporal} {Knowledge} {Graphs}},
	url = {http://arxiv.org/abs/2203.02150},
	doi = {10.18653/v1/2021.emnlp-main.709},
	abstract = {Entity alignment aims to identify equivalent entity pairs between different knowledge graphs (KGs). Recently, the availability of temporal KGs (TKGs) that contain time information created the need for reasoning over time in such TKGs. Existing embedding-based entity alignment approaches disregard time information that commonly exists in many large-scale KGs, leaving much room for improvement. In this paper, we focus on the task of aligning entity pairs between TKGs and propose a novel Time-aware Entity Alignment approach based on Graph Neural Networks (TEA-GNN). We embed entities, relations and timestamps of different KGs into a vector space and use GNNs to learn entity representations. To incorporate both relation and time information into the GNN structure of our model, we use a time-aware attention mechanism which assigns different weights to different nodes with orthogonal transformation matrices computed from embeddings of the relevant relations and timestamps in a neighborhood. Experimental results on multiple real-world TKG datasets show that our method significantly outperforms the state-of-the-art methods due to the inclusion of time information.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {Proceedings of the 2021 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}},
	author = {Xu, Chengjin and Su, Fenglong and Lehmann, Jens},
	year = {2021},
	note = {arXiv:2203.02150 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Impact 3*, Relevance 3*},
	pages = {8999--9010},
}

@inproceedings{jin_recurrent_2020,
	address = {Online},
	title = {Recurrent {Event} {Network}: {Autoregressive} {Structure} {Inferenceover} {Temporal} {Knowledge} {Graphs}},
	shorttitle = {Recurrent {Event} {Network}},
	url = {https://www.aclweb.org/anthology/2020.emnlp-main.541},
	doi = {10.18653/v1/2020.emnlp-main.541},
	abstract = {Knowledge graph reasoning is a critical task in natural language processing. The task becomes more challenging on temporal knowledge graphs, where each fact is associated with a timestamp. Most existing methods focus on reasoning at past timestamps and they are not able to predict facts happening in the future. This paper proposes Recurrent Event Network (RE-NET), a novel autoregressive architecture for predicting future interactions. The occurrence of a fact (event) is modeled as a probability distribution conditioned on temporal sequences of past knowledge graphs. Speciﬁcally, our RE-NET employs a recurrent event encoder to encode past facts, and uses a neighborhood aggregator to model the connection of facts at the same timestamp. Future facts can then be inferred in a sequential manner based on the two modules. We evaluate our proposed method via link prediction at future times on ﬁve public datasets. Through extensive experiments, we demonstrate the strength of RENET, especially on multi-step inference over future timestamps, and achieve state-of-the-art performance on all ﬁve datasets1.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {Proceedings of the 2020 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing} ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Jin, Woojeong and Qu, Meng and Jin, Xisen and Ren, Xiang},
	year = {2020},
	keywords = {Impact 4*, Relevance 2*},
	pages = {6669--6683},
}

@misc{liang_survey_2023,
	title = {A {Survey} of {Knowledge} {Graph} {Reasoning} on {Graph} {Types}: {Static}, {Dynamic}, and {Multimodal}},
	shorttitle = {A {Survey} of {Knowledge} {Graph} {Reasoning} on {Graph} {Types}},
	url = {http://arxiv.org/abs/2212.05767},
	abstract = {Knowledge graph reasoning (KGR), aiming to deduce new facts from existing facts based on mined logic rules underlying knowledge graphs (KGs), has become a fast-growing research direction. It has been proven to signiﬁcantly beneﬁt the usage of KGs in many AI applications, such as question answering and recommendation systems, etc. According to the graph types, the existing KGR models can be roughly divided into three categories, i.e., static models, temporal models, and multi-modal models. The early works in this domain mainly focus on static KGR and tend to directly apply general knowledge graph embedding models to the reasoning task. However, these models are not suitable for more complex but practical tasks, such as inductive static KGR, temporal KGR, and multi-modal KGR. To this end, multiple works have been developed recently, but no survey papers and open-source repositories comprehensively summarize and discuss models in this important direction. To ﬁll the gap, we conduct a survey for knowledge graph reasoning tracing from static to temporal and then to multi-modal KGs. Concretely, the preliminaries, summaries of KGR models, and typical datasets are introduced and discussed consequently. Moreover, we discuss the challenges and potential opportunities. The corresponding open-source repository is shared on GitHub: https://github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning.},
	language = {en},
	urldate = {2023-03-28},
	publisher = {arXiv},
	author = {Liang, Ke and Meng, Lingyuan and Liu, Meng and Liu, Yue and Tu, Wenxuan and Wang, Siwei and Zhou, Sihang and Liu, Xinwang and Sun, Fuchun},
	month = feb,
	year = {2023},
	note = {arXiv:2212.05767 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Information Retrieval, Impact 1*, Relevance 2*},
}

@inproceedings{song_katgcn_2021,
	title = {{KatGCN}: {Knowledge}-{Aware} {Attention} based {Temporal} {Graph} {Convolutional} {Network} for {Multi}-{Event} {Prediction}},
	shorttitle = {{KatGCN}},
	url = {http://ksiresearch.org/seke/seke21paper/paper089.pdf},
	doi = {10.18293/SEKE2021-089},
	language = {en},
	urldate = {2023-03-28},
	author = {Song, Xin},
	month = jul,
	year = {2021},
	keywords = {Impact 1*, Relevance 2*},
	pages = {417--422},
}

@inproceedings{han_text-enhanced_2022,
	address = {Orlando, FL, USA},
	title = {Text-enhanced {Multi}-{Granularity} {Temporal} {Graph} {Learning} for {Event} {Prediction}},
	isbn = {978-1-66545-099-7},
	url = {https://ieeexplore.ieee.org/document/10027692/},
	doi = {10.1109/ICDM54844.2022.00027},
	abstract = {When working with forecasting the future, it is all about learning from the past. However, it is non-trivial to model the past due to the scale and complexity of available data. Recently, Graph Neural Networks (GNNs) have shown ﬂexibility to process different forms of data and learn interactions among entities, giving them advantages in real-life applications. More and more researchers have started to apply GNNs and temporal models for event forecasting because events are formalized in knowledge graphs. However, most of these models are based on the Markov assumption that the probability of a event is only inﬂuenced by the state of its last time step (or recent history). We claim that the occurrence of an event not only has short-term but also long-term dependencies. In this work, we propose a temporal knowledge graph (KG)-based model that considers different granularties of histories when forecasting an event; this method also integrates news texts as auxiliary features during the graph learning process. Extensive experiments on multiple datasets are conducted to examine the effectiveness of the proposed method. Code is available at: https://github.com/yuening-lab/MTG.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {2022 {IEEE} {International} {Conference} on {Data} {Mining} ({ICDM})},
	publisher = {IEEE},
	author = {Han, Xiaoxue and Ning, Yue},
	month = nov,
	year = {2022},
	keywords = {Impact 1*, Relevance 3*},
	pages = {171--180},
}

@article{zhang_predicting_2022,
	title = {Predicting {Social} {Events} with {Multimodal} {Fusion} of {Spatial} and {Temporal} {Dynamic} {Graph} {Representations}},
	volume = {10},
	issn = {2167-6461, 2167-647X},
	url = {https://www.liebertpub.com/doi/10.1089/big.2021.0270},
	doi = {10.1089/big.2021.0270},
	abstract = {Big data has been satisfactorily used to solve social issues in several parts of the word. Social event prediction is related to social stability and sustainable development. However, current research rarely takes into account the dynamic connections between event actors and learning robust feature representations of social events. Inspired by the graph neural network, we propose a novel Siamese Spatial and Temporal Dynamic Network for predicting social events. Speciﬁcally, we use multimodal data containing news articles and global events to construct dynamic graphs based on word co-occurrences and interactions between event actors. Dynamic graphs can model the evolution of social events. By employing the fusion of spatial and temporal dynamic graph representations from heterogeneous historical data, our proposed model predicts the occurrence of future social events for the target country. Qualitative and quantitative analysis of experiment results on multiple real-word datasets shows that our proposed method is competitive against several approaches for social event prediction.},
	language = {en},
	number = {5},
	urldate = {2023-03-28},
	journal = {Big Data},
	author = {Zhang, Guoshuai and Wu, Jiaji and Tan, Mingzhou and Han, Hong},
	month = oct,
	year = {2022},
	keywords = {Impact 1*, Relevance 3*},
	pages = {440--452},
}

@article{zhao_t-gcn_2020,
	title = {T-{GCN}: {A} {Temporal} {Graph} {ConvolutionalNetwork} for {Traffic} {Prediction}},
	volume = {21},
	issn = {1524-9050, 1558-0016},
	shorttitle = {T-{GCN}},
	url = {http://arxiv.org/abs/1811.05320},
	doi = {10.1109/TITS.2019.2935152},
	abstract = {Accurate and real-time trafﬁc forecasting plays an important role in the Intelligent Trafﬁc System and is of great signiﬁcance for urban trafﬁc planning, trafﬁc management, and trafﬁc control. However, trafﬁc forecasting has always been considered an open scientiﬁc issue, owing to the constraints of urban road network topological structure and the law of dynamic change with time, namely, spatial dependence and temporal dependence. To capture the spatial and temporal dependence simultaneously, we propose a novel neural network-based trafﬁc forecasting method, the temporal graph convolutional network (T-GCN) model, which is in combination with the graph convolutional network (GCN) and gated recurrent unit (GRU). Speciﬁcally, the GCN is used to learn complex topological structures to capture spatial dependence and the gated recurrent unit is used to learn dynamic changes of trafﬁc data to capture temporal dependence. Then, the T-GCN model is employed to trafﬁc forecasting based on the urban road network. Experiments demonstrate that our T-GCN model can obtain the spatio-temporal correlation from trafﬁc data and the predictions outperform state-of-art baselines on real-world trafﬁc datasets. Our tensorﬂow implementation of the T-GCN is available at https://github.com/lehaifeng/T-GCN.},
	language = {en},
	number = {9},
	urldate = {2023-03-28},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Zhao, Ling and Song, Yujiao and Zhang, Chao and Liu, Yu and Wang, Pu and Lin, Tao and Deng, Min and Li, Haifeng},
	month = sep,
	year = {2020},
	note = {arXiv:1811.05320 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Impact 5*, Relevance 3*, Statistics - Machine Learning},
	pages = {3848--3858},
}

@misc{han_graph_2020,
	title = {Graph {Hawkes} {Neural} {Network} for {Forecasting} on {Temporal} {Knowledge} {Graphs}},
	url = {http://arxiv.org/abs/2003.13432},
	abstract = {The Hawkes process has become a standard method for modeling self-exciting event sequences with diﬀerent event types. A recent work has generalized the Hawkes process to a neurally self-modulating multivariate point process, which enables the capturing of more complex and realistic impacts of past events on future events. However, this approach is limited by the number of possible event types, making it impossible to model the dynamics of evolving graph sequences, where each possible link between two nodes can be considered as an event type. The number of event types increases even further when links are directional and labeled. To address this issue, we propose the Graph Hawkes Neural Network that can capture the dynamics of evolving graph sequences and can predict the occurrence of a fact in a future time instance. Extensive experiments on large-scale temporal multirelational databases, such as temporal knowledge graphs, demonstrate the eﬀectiveness of our approach.},
	language = {en},
	urldate = {2023-03-28},
	publisher = {arXiv},
	author = {Han, Zhen and Ma, Yunpu and Wang, Yuyi and Günnemann, Stephan and Tresp, Volker},
	month = jun,
	year = {2020},
	note = {arXiv:2003.13432 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Impact 4*, Relevance 3*, Statistics - Machine Learning},
}

@misc{sun_timetraveler_2021,
	title = {{TimeTraveler}: {Reinforcement} {Learning} for {Temporal} {Knowledge} {Graph} {Forecasting}},
	shorttitle = {{TimeTraveler}},
	url = {http://arxiv.org/abs/2109.04101},
	abstract = {Temporal knowledge graph (TKG) reasoning is a crucial task that has gained increasing research interest in recent years. Most existing methods focus on reasoning at past timestamps to complete the missing facts, and there are only a few works of reasoning on known TKGs to forecast future facts. Compared with the completion task, the forecasting task is more difﬁcult and faces two main challenges: (1) how to effectively model the time information to handle future timestamps? (2) how to make inductive inference to handle previously unseen entities that emerge over time? To address these challenges, we propose the ﬁrst reinforcement learning method for forecasting. Speciﬁcally, the agent travels on historical knowledge graph snapshots to search for the answer. Our method deﬁnes a relative time encoding function to capture the timespan information, and we design a novel time-shaped reward based on Dirichlet distribution to guide the model learning. Furthermore, we propose a novel representation method for unseen entities to improve the inductive inference ability of the model. We evaluate our method for this link prediction task at future timestamps. Extensive experiments on four benchmark datasets demonstrate substantial performance improvement meanwhile with higher explainability, less calculation, and fewer parameters when compared with existing stateof-the-art methods.},
	language = {en},
	urldate = {2023-03-28},
	publisher = {arXiv},
	author = {Sun, Haohai and Zhong, Jialun and Ma, Yunpu and Han, Zhen and He, Kun},
	month = sep,
	year = {2021},
	note = {arXiv:2109.04101 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, Impact 4*, Relevance 4*},
}

@misc{li_search_2021,
	title = {Search from {History} and {Reason} for {Future}: {Two}-stage {Reasoning} on {Temporal} {Knowledge} {Graphs}},
	shorttitle = {Search from {History} and {Reason} for {Future}},
	url = {http://arxiv.org/abs/2106.00327},
	abstract = {Temporal Knowledge Graphs (TKGs) have been developed and used in many different areas. Reasoning on TKGs that predicts potential facts (events) in the future brings great challenges to existing models. When facing a prediction task, human beings usually search useful historical information (i.e., clues) in their memories and then reason for future meticulously. Inspired by this mechanism, we propose CluSTeR to predict future facts in a two-stage manner, Clue Searching and Temporal Reasoning, accordingly. Speciﬁcally, at the clue searching stage, CluSTeR learns a beam search policy via reinforcement learning (RL) to induce multiple clues from historical facts. At the temporal reasoning stage, it adopts a graph convolution network based sequence method to deduce answers from clues. Experiments on four datasets demonstrate the substantial advantages of CluSTeR compared with the state-of-the-art methods. Moreover, the clues found by CluSTeR further provide interpretability for the results.},
	language = {en},
	urldate = {2023-03-28},
	publisher = {arXiv},
	author = {Li, Zixuan and Jin, Xiaolong and Guan, Saiping and Li, Wei and Guo, Jiafeng and Wang, Yuanzhuo and Cheng, Xueqi},
	month = jun,
	year = {2021},
	note = {arXiv:2106.00327 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Impact 4*, Relevance 3*},
}

@inproceedings{deng_dynamic_2020,
	address = {Virtual Event CA USA},
	title = {Dynamic {Knowledge} {Graph} based {Multi}-{Event} {Forecasting}},
	isbn = {978-1-4503-7998-4},
	url = {https://dl.acm.org/doi/10.1145/3394486.3403209},
	doi = {10.1145/3394486.3403209},
	abstract = {Modeling concurrent events of multiple types and their involved actors from open-source social sensors is an important task for many domains such as health care, disaster relief, and financial analysis. Forecasting events in the future can help human analysts better understand global social dynamics and make quick and accurate decisions. Anticipating participants or actors who may be involved in these activities can also help stakeholders to better respond to unexpected events. However, achieving these goals is challenging due to several factors: (i) it is hard to filter relevant information from large-scale input, (ii) the input data is usually high dimensional, unstructured, and Non-IID (Non-independent and identically distributed) and (iii) associated text features are dynamic and vary over time. Recently, graph neural networks have demonstrated strengths in learning complex and relational data. In this paper, we study a temporal graph learning method with heterogeneous data fusion for predicting concurrent events of multiple types and inferring multiple candidate actors simultaneously. In order to capture temporal information from historical data, we propose Glean, a graph learning framework based on event knowledge graphs to incorporate both relational and word contexts. We present a context-aware embedding fusion module to enrich hidden features for event actors. We conducted extensive experiments on multiple real-world datasets and show that the proposed method is competitive against various state-of-the-art methods for social event prediction and also provides much-need interpretation capabilities.},
	language = {en},
	urldate = {2023-03-28},
	booktitle = {Proceedings of the 26th {ACM} {SIGKDD} {International} {Conference} on {Knowledge} {Discovery} \& {Data} {Mining}},
	publisher = {ACM},
	author = {Deng, Songgaojun and Rangwala, Huzefa and Ning, Yue},
	month = aug,
	year = {2020},
	keywords = {Impact 4*, Relevance 2*},
	pages = {1585--1595},
}

@book{ester_staple_2018,
	address = {Philadelphia, PA},
	title = {{STAPLE}: {Spatio}-{Temporal} {Precursor} {Learning} for {Event} {Forecasting}},
	isbn = {978-1-61197-532-1},
	url = {https://epubs.siam.org/doi/book/10.1137/1.9781611975321},
	abstract = {Large-scale societal events such as civil unrest movements occur due to a variety of factors including economics, politics, and security. Societal event detection can be modeled as a system of inter-connected locations, where each location is recording a set of time-dependent observations. In order to detect event occurrence and automatically reconstruct the precursors and signals, it is essential to model relationships between the diﬀerent locations w.r.t. how events evolve over time. However, existing methods for precursor discovery do not capture or exploit spatial and temporal correlations inherent in event occurrences. The absence of such modeling not only creates shortcomings in the quality of inference but also curtails interpretation by human analysts. Furthermore, forecasting is inhibited when training data is sparse. In this paper, we develop a novel multi-task model with dynamic graph constraints within a multiinstance learning framework. Our model tackles the problem of scarce data distribution and reinforces cooccurring location-speciﬁc precursors with augmented representations. Through studies on civil unrest movements in numerous countries, we demonstrate the eﬀectiveness of the proposed method for precursor discovery and event forecasting.},
	language = {en},
	urldate = {2023-03-28},
	publisher = {Society for Industrial and Applied Mathematics},
	editor = {Ester, Martin and Pedreschi, Dino},
	month = may,
	year = {2018},
	doi = {10.1137/1.9781611975321},
}

@book{ester_proceedings_2018,
	address = {Philadelphia, PA},
	title = {Proceedings of the 2018 {SIAM} {International} {Conference} on {Data} {Mining}},
	isbn = {978-1-61197-532-1},
	url = {https://epubs.siam.org/doi/book/10.1137/1.9781611975321},
	language = {en},
	urldate = {2023-03-28},
	publisher = {Society for Industrial and Applied Mathematics},
	editor = {Ester, Martin and Pedreschi, Dino},
	month = may,
	year = {2018},
	doi = {10.1137/1.9781611975321},
}

@inproceedings{halliwell_linked_2021,
	address = {ESSENDON VIC Australia},
	title = {Linked {Data} {Ground} {Truth} for {Quantitative} and {Qualitative} {Evaluation} of {Explanations} for {Relational} {Graph} {Convolutional} {Network} {Link} {Prediction} on {Knowledge} {Graphs}},
	isbn = {978-1-4503-9115-3},
	url = {https://dl.acm.org/doi/10.1145/3486622.3493921},
	doi = {10.1145/3486622.3493921},
	abstract = {Relational Graph Convolutional Networks (RGCNs) identify relationships within a Knowledge Graph to learn real-valued embeddings for each node and edge. Recently, researchers have proposed explanation methods to interpret the predictions of these blackbox models. However, comparisons across explanation methods for link prediction remains difficult, as there is neither a method nor dataset to compare explanations against. Furthermore, there exists no standard evaluation metric to identify when one explanation method is preferable to the other. In this paper, we leverage linked data to propose a method, including two datasets (Royalty-20k, and Royalty-30k), to benchmark explanation methods on the task of explainable link prediction using Graph Neural Networks. In particular, we rely on the Semantic Web to construct explanations, ensuring that each predictable triple has an associated set of triples providing a ground truth explanation. Additionally, we propose the use of a scoring metric for empirically evaluating explanation methods, allowing for a quantitative comparison. We benchmark these datasets on state-of-the-art link prediction explanation methods using the defined scoring metric, and quantify the different types of errors made with respect to both data and semantics.},
	language = {en},
	urldate = {2023-02-28},
	booktitle = {{IEEE}/{WIC}/{ACM} {International} {Conference} on {Web} {Intelligence}},
	publisher = {ACM},
	author = {Halliwell, Nicholas and Gandon, Fabien and Lecue, Freddy},
	month = dec,
	year = {2021},
	pages = {178--185},
}

@article{cucala_explainable_2022,
	title = {{EXPLAINABLE} {GNN}-{BASED} {MODELS} {OVER} {KNOWLEDGE} {GRAPHS}},
	abstract = {Graph Neural Networks (GNNs) are often used to learn transformations of graph data. While effective in practice, such approaches make predictions via numeric manipulations so their output cannot be easily explained symbolically. We propose a new family of GNN-based transformations of graph data that can be trained effectively, but where all predictions can be explained symbolically as logical inferences in Datalog—a well-known rule-based formalism. In particular, we show how to encode an input knowledge graph into a graph with numeric feature vectors, process this graph using a GNN, and decode the result into an output knowledge graph. We use a new class of monotonic GNNs (MGNNs) to ensure that this process is equivalent to a round of application of a set of Datalog rules. We also show that, given an arbitrary MGNN, we can automatically extract rules that completely characterise the transformation. We evaluate our approach by applying it to classiﬁcation tasks in knowledge graph completion.},
	language = {en},
	author = {Cucala, David Tena and Kostylev, Egor V and Grau, Bernardo Cuenca and Motik, Boris},
	year = {2022},
}

@article{noauthor_notitle_nodate,
}

@article{yau_clustering_2014,
	title = {Clustering scientific documents with topic modeling},
	volume = {100},
	issn = {0138-9130, 1588-2861},
	url = {http://link.springer.com/10.1007/s11192-014-1321-8},
	doi = {10.1007/s11192-014-1321-8},
	abstract = {Topic modeling is a type of statistical model for discovering the latent ‘‘topics’’ that occur in a collection of documents through machine learning. Currently, latent Dirichlet allocation (LDA) is a popular and common modeling approach. In this paper, we investigate methods, including LDA and its extensions, for separating a set of scientiﬁc publications into several clusters. To evaluate the results, we generate a collection of documents that contain academic papers from several different ﬁelds and see whether papers in the same ﬁeld will be clustered together. We explore potential scientometric applications of such text analysis capabilities.},
	language = {en},
	number = {3},
	urldate = {2022-10-28},
	journal = {Scientometrics},
	author = {Yau, Chyi-Kwei and Porter, Alan and Newman, Nils and Suominen, Arho},
	month = sep,
	year = {2014},
	keywords = {LDA},
	pages = {767--786},
}

@inproceedings{rinartha_rapid_2021,
	address = {Makasar, Indonesia},
	title = {Rapid {Automatic} {Keyword} {Extraction} and {Word} {Frequency} in {Scientific} {Article} {Keywords} {Extraction}},
	isbn = {978-1-66542-580-3},
	url = {https://ieeexplore.ieee.org/document/9649458/},
	doi = {10.1109/ICORIS52787.2021.9649458},
	abstract = {Research is one activity that has to be conducted by lecturers or researchers. In fact, they usually deliver articles regarding the research that has been conducted. Scientific articles that are produced by researchers have keywords to represent their contents. The selection of keywords that have been used in scientific articles sometimes does not match the whole content. Selection of keywords will be easier if assisted by a keyword extraction system. Due to the keywords that can be used in searching articles on search engines as a reference, keywords take an important part in the article. Some methods that can be used to extract keywords from one article are word frequency and RAKE (Rapid Automatic Keyword Extraction). Both methods are combined to get more accurate in extracting keywords from an article. This combination is implemented using python programming language and tested using several articles taken randomly from the internet. The research consists of several processes namely, theoretical analysis, design, implementation, and testing. The program was created in the form of a keyword extraction website and tested from the validity of the resulting keywords. An obtained result from the whole process of the research, that is the application could produce some proper keywords in the form of phrases and words. It is better than the keywords that resulted with one method either word frequency or RAKE.},
	language = {en},
	urldate = {2022-10-28},
	booktitle = {2021 3rd {International} {Conference} on {Cybernetics} and {Intelligent} {System} ({ICORIS})},
	publisher = {IEEE},
	author = {Rinartha, Komang and Kartika, Luh Gede Surya},
	month = oct,
	year = {2021},
	pages = {1--4},
}

@article{kondeti_keyword_2022,
	title = {Keyword {Extraction} – {Comparison} of {Latent} {Dirichlet} {Allocation} and {Latent} {Semantic} {Analysis}},
	volume = {3},
	issn = {2736-5484},
	url = {https://www.ej-math.org/index.php/ejmath/article/view/119},
	doi = {10.24018/ejmath.2022.3.3.119},
	abstract = {The main aim of the present study is to compare the keywords extracted from abstracts and full length text of scientific research papers. In addition to that, here, we compare Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) to identify better performer for keyword extraction. This comparative study is divided into three levels, In the first level, scientific research articles on topics such as Indian Economic growth, GDP, Economic Slowdown etc. were collected and abstracts and full length text was extracted from the sources and pre-processed to remove the words and characters which were not useful to obtain the semantic structures or necessary patterns to make the meaningful corpus. In the second level, the pre-processed data were converted into a bag of words and numerical statistic TF-IDF (Term Frequency – Inverse Document Frequency) is used to assess how relevant a word is to a document in a corpus. In the third level, in order to study the feasibility of the Natural Language Processing (NLP) techniques, Latent Semantic analysis (LSA) and Latent Dirichlet Allocations (LDA) methods were applied over the resultant corpus.},
	language = {en},
	number = {3},
	urldate = {2022-10-28},
	journal = {European Journal of Mathematics and Statistics},
	author = {Kondeti, Bhuvaneshwari and S. A, Jyothirani and V. V, Haragopal},
	month = jun,
	year = {2022},
	pages = {40--47},
}

@article{li_comparative_2021,
	title = {A comparative study of keyword extraction algorithms for {English} texts},
	volume = {30},
	issn = {2191-026X},
	url = {https://www.degruyter.com/document/doi/10.1515/jisys-2021-0040/html},
	doi = {10.1515/jisys-2021-0040},
	abstract = {This study mainly analyzed the keyword extraction of English text. First, two commonly used algorithms, the term frequency–inverse document frequency (TF–IDF) algorithm and the keyphrase extraction algorithm (KEA), were introduced. Then, an improved TF–IDF algorithm was designed, which improved the calculation of word frequency, and it was combined with the position weight to improve the performance of keyword extraction. Finally, 100 English literature was selected from the British Academic Written English Corpus for the analysis experiment. The results showed that the improved TF–IDF algorithm had the shortest running time and took only 4.93 s in processing 100 texts; the precision of the algorithms decreased with the increase of the number of extracted keywords. The comparison between the two algorithms demonstrated that the improved TF–IDF algorithm had the best performance, with a precision rate of 71.2\%, a recall rate of 52.98\%, and an F1 score of 60.75\%, when ﬁve keywords were extracted from each article. The experimental results show that the improved TF–IDF algorithm is eﬀective in extracting English text keywords, which can be further promoted and applied in practice.},
	language = {en},
	number = {1},
	urldate = {2022-10-28},
	journal = {Journal of Intelligent Systems},
	author = {Li, Jinye},
	month = jul,
	year = {2021},
	pages = {808--815},
}
